<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="Etapas Principales de un Sistema NLP: Preprocesamiento, Tokenizaci√≥n, An√°lisis Sint√°ctico, Sem√°ntico y Pragm√°tico con ejemplos pr√°cticos en Python.">
    <meta name="keywords"
        content="NLP, Procesamiento del Lenguaje Natural, Tokenizaci√≥n, An√°lisis Sint√°ctico, An√°lisis Sem√°ntico, spaCy, Python, Embeddings">
    <meta name="author" content="Bjlanza">
    <meta name="organization" content="ILERNA">
    <meta property="og:title" content="Etapas Principales de un Sistema NLP | iLERNA">
    <meta property="og:description"
        content="Del texto crudo a la comprensi√≥n computacional: las cinco etapas esenciales de procesamiento del lenguaje natural.">
    <meta property="og:type" content="article">
    <title>Etapas Principales de un Sistema NLP | iLERNA</title>
    <link rel="stylesheet" href="../css/lecciones.css">
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
</head>

<body>
    <div class="container">
        <header>
            <div class="header-container">
                <div class="logo-container">
                    <a href="../index.html">
                        <img src="../img/logo-ilerna.svg" alt="Logo iLERNA">
                    </a>
                    <div class="logo-text">
                        iLERNA
                        <span>Curso de Especializaci√≥n en IA y Big Data</span>
                    </div>
                </div>
                <div class="breadcrumb">
                    <a href="../index.html">Inicio</a> ‚Ä∫
                    <a href="index.html">Modelos de IA</a> ‚Ä∫
                    <span>Etapas Principales de un Sistema NLP</span>
                </div>
            </div>
            <h1 class="text-center">Etapas Principales de un Sistema NLP</h1>
            <p class="subtitle text-center">Del Texto Crudo a la Comprensi√≥n Computacional</p>
        </header>

        <main>
            <!-- SECCI√ìN 1: INTRODUCCI√ìN -->
            <section class="section">
                <h2 class="section-title">¬øQu√© es un Sistema de NLP?</h2>
                <p>
                    Un sistema de <strong>Natural Language Processing (Procesamiento del Lenguaje Natural)</strong> transforma el lenguaje humano en datos que las m√°quinas pueden entender y procesar. Desde tu asistente virtual hasta sistemas de traducci√≥n autom√°tica, el NLP est√° en todas partes.
                </p>
                <p>
                    Un sistema NLP cl√°sico se estructura en <strong>cinco etapas sucesivas</strong> que transforman el texto desde su forma original hasta representaciones computacionales comprensibles para algoritmos de machine learning.
                </p>

                <div class="highlight-box primary">
                    <p style="font-size: 1.1rem; margin-bottom: 0.5rem;"><strong>Ejemplo Real:</strong></p>
                    <p style="margin-bottom: 0;">Google Translate procesa m√°s de <strong>100 mil millones de palabras diarias</strong> usando sistemas NLP avanzados. Netflix analiza millones de subt√≠tulos y rese√±as para recomendar contenido personalizado.</p>
                </div>

                <h3 class="color-secondary" style="margin-top: 2rem;">Conceptos Fundamentales</h3>
                <div class="comparison-grid">
                    <div class="comparison-card">
                        <h4 class="color-primary">Corpus</h4>
                        <p>Colecci√≥n de textos utilizada para entrenar modelos. Ejemplo: Wikipedia en espa√±ol contiene m√°s de 1.8 millones de art√≠culos.</p>
                    </div>

                    <div class="comparison-card">
                        <h4 class="color-secondary">Token</h4>
                        <p>Unidad m√≠nima de an√°lisis en NLP. Puede ser una palabra, subpalabra o car√°cter dependiendo del modelo.</p>
                    </div>

                    <div class="comparison-card">
                        <h4 class="color-primary">Embedding</h4>
                        <p>Representaci√≥n vectorial de palabras que captura relaciones sem√°nticas. Word2Vec y BERT son ejemplos populares.</p>
                    </div>

                    <div class="comparison-card">
                        <h4 class="color-secondary">Modelo de Lenguaje</h4>
                        <p>Sistema que predice la probabilidad de secuencias de palabras. GPT-4 tiene 1.76 trillones de par√°metros.</p>
                    </div>
                </div>
            </section>

            <!-- SECCI√ìN 2: PREPROCESAMIENTO -->
            <section class="section">
                <h2 class="section-title">Preprocesamiento</h2>

                <h3 class="color-primary">Limpieza y Normalizaci√≥n del Texto</h3>
                <p>
                    El preprocesamiento es la <strong>etapa inicial cr√≠tica</strong> donde se limpia y normaliza el texto: eliminaci√≥n de signos innecesarios, conversi√≥n a min√∫sculas, correcci√≥n de tildes, eliminaci√≥n de espacios, y m√°s. Tambi√©n puede incluir <strong>lemmatizaci√≥n</strong> (reducir palabras a su forma base) y eliminaci√≥n de <strong>stopwords</strong> ("de", "la", "que") que aportan poco contexto sem√°ntico.
                </p>
                <p>
                    Este paso es fundamental para reducir el ruido y mejorar el rendimiento de modelos de clasificaci√≥n, an√°lisis de sentimientos y sistemas de b√∫squeda.
                </p>

                <!-- EJEMPLO CON SPACY -->
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">Python</span>
                        <button class="copy-button" onclick="copyCode(this)">Copiar</button>
                    </div>
                    <pre><code class="language-python"># Instalaci√≥n: pip install spacy
# Descargar modelo espa√±ol: python -m spacy download es_core_news_sm
import spacy

# Cargar el modelo de espa√±ol
nlp = spacy.load("es_core_news_sm")

# Texto original sin procesar
texto_original = "   ¬°¬°HOLA!! ¬øC√≥mo est√°s? La empresa TESLA fabrica veh√≠culos el√©ctricos en California...   "

# Procesar el texto
doc = nlp(texto_original.lower().strip())

# Lemmatizaci√≥n y eliminaci√≥n de stopwords
tokens_limpios = [token.lemma_ for token in doc
                  if not token.is_stop and not token.is_punct and not token.is_space]

print("Texto original:")
print(f"'{texto_original}'")
print(f"\nTokens procesados (sin stopwords ni puntuaci√≥n):")
print(tokens_limpios)
print(f"\nN√∫mero de tokens originales: {len(doc)}")
print(f"N√∫mero de tokens limpios: {len(tokens_limpios)}")

# Resultado esperado:
# Tokens procesados: ['hola', 'empresa', 'tesla', 'fabricar', 'veh√≠culo', 'el√©ctrico', 'california']</code></pre>
                </div>

                <!-- RESULTADO -->
                <div class="highlight-box primary" style="margin-top: 1rem;">
                    <p style="font-size: 1.05rem; font-weight: 600; margin-bottom: 0.75rem;">Resultado del Preprocesamiento:</p>
                    <p style="font-family: 'Courier New', monospace; font-size: 0.95rem; line-height: 1.6; margin: 0;">
                        <strong>Entrada:</strong> "   ¬°¬°HOLA!! ¬øC√≥mo est√°s? La empresa TESLA fabrica veh√≠culos el√©ctricos..."<br>
                        <strong>Salida:</strong> ['hola', 'empresa', 'tesla', 'fabricar', 'veh√≠culo', 'el√©ctrico', 'california']<br>
                        <strong>Reducci√≥n:</strong> De 15 tokens ‚Üí 7 tokens relevantes (53% de reducci√≥n)
                    </p>
                </div>

                <!-- APLICACIONES -->
                <h3 class="color-primary" style="margin-top: 2rem;">Aplicaciones Reales</h3>
                <div class="grid-features">
                    <div class="feature-card">
                        <h4 class="color-primary">Motores de B√∫squeda</h4>
                        <p>Google normaliza consultas eliminando art√≠culos y preposiciones para mejorar la relevancia de resultados.</p>
                    </div>

                    <div class="feature-card secondary">
                        <h4 class="color-secondary">An√°lisis de Sentimientos</h4>
                        <p>Twitter (X) procesa 500 millones de tweets diarios eliminando emojis, hashtags y menciones antes del an√°lisis.</p>
                    </div>

                    <div class="feature-card">
                        <h4 class="color-primary">Filtrado de Spam</h4>
                        <p>Gmail lemmatiza contenidos para detectar variantes de palabras spam ("GRATIS", "gr√°tis", "gratis").</p>
                    </div>
                </div>
            </section>

            <!-- SECCI√ìN 3: TOKENIZACI√ìN -->
            <section class="section">
                <h2 class="section-title">Tokenizaci√≥n</h2>

                <h3 class="color-secondary">Dividiendo el Texto en Unidades Procesables</h3>
                <p>
                    La tokenizaci√≥n divide el texto en <strong>unidades m√≠nimas llamadas tokens</strong> (palabras, signos, o subpalabras). Esta segmentaci√≥n es esencial porque convierte una secuencia de caracteres en una lista de elementos que los modelos pueden procesar matem√°ticamente.
                </p>
                <p>
                    En modelos modernos como los <strong>transformers</strong> (BERT, GPT), los tokens no siempre son palabras completas. El tokenizador puede dividir "computadora" en subpalabras como <code>['compu', '##tadora']</code>, permitiendo manejar vocabularios m√°s amplios con menos memoria.
                </p>

                <!-- EJEMPLO CON SPACY -->
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">Python</span>
                        <button class="copy-button" onclick="copyCode(this)">Copiar</button>
                    </div>
                    <pre><code class="language-python">import spacy

# Cargar modelo espa√±ol
nlp = spacy.load("es_core_news_sm")

# Texto de ejemplo
texto = "El procesamiento del lenguaje natural (NLP) transforma texto en datos estructurados."

# Procesar el texto
doc = nlp(texto)

# Extraer informaci√≥n de cada token
print("TOKENIZACI√ìN COMPLETA:\n")
print(f"{'Token':<20} {'Tipo':<15} {'Es puntuaci√≥n':<15} {'Es stopword'}")
print("-" * 70)

for token in doc:
    print(f"{token.text:<20} {token.pos_:<15} {str(token.is_punct):<15} {token.is_stop}")

print(f"\nüìä ESTAD√çSTICAS:")
print(f"Total de tokens: {len(doc)}")
print(f"Palabras √∫nicas: {len(set([token.text for token in doc]))}")
print(f"Stopwords detectadas: {len([token for token in doc if token.is_stop])}")

# Resultado esperado:
# Token                Tipo            Es puntuaci√≥n   Es stopword
# ----------------------------------------------------------------------
# El                   DET             False           True
# procesamiento        NOUN            False           False
# del                  ADP             False           True
# lenguaje             NOUN            False           False
# natural              ADJ             False           False
# (                    PUNCT           True            False
# NLP                  PROPN           False           False
# )                    PUNCT           True            False
# transforma           VERB            False           False
# texto                NOUN            False           False
# en                   ADP             False           True
# datos                NOUN            False           False
# estructurados        ADJ             False           False
# .                    PUNCT           True            False</code></pre>
                </div>

                <!-- VISUALIZACI√ìN SVG -->
                <div style="margin-top: 2rem;">
                    <svg width="800" height="300" viewBox="0 0 800 300" style="border: 2px solid #e5e5e5; border-radius: 1rem; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05); background-color: #fafafa; display: block; margin: 0 auto; max-width: 100%;">
                        <text x="400" y="30" font-size="18" font-weight="bold" fill="#8A7AAF" text-anchor="middle" font-family="Montserrat">Proceso de Tokenizaci√≥n: Texto ‚Üí Tokens</text>

                        <!-- Texto original -->
                        <rect x="50" y="60" width="700" height="50" fill="#F0EDF5" stroke="#8A7AAF" stroke-width="2" rx="8"/>
                        <text x="400" y="90" font-size="14" fill="#333333" text-anchor="middle" font-family="Courier New">"El NLP transforma texto en datos"</text>

                        <!-- Flecha -->
                        <path d="M 400 120 L 400 140" stroke="#8A7AAF" stroke-width="3" marker-end="url(#arrowpurple)" fill="none"/>

                        <!-- Tokens individuales -->
                        <rect x="50" y="160" width="80" height="40" fill="#C5B9D8" stroke="#8A7AAF" stroke-width="2" rx="5"/>
                        <text x="90" y="185" font-size="12" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Montserrat">El</text>

                        <rect x="150" y="160" width="90" height="40" fill="#C5B9D8" stroke="#8A7AAF" stroke-width="2" rx="5"/>
                        <text x="195" y="185" font-size="12" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Montserrat">NLP</text>

                        <rect x="260" y="160" width="130" height="40" fill="#C5B9D8" stroke="#8A7AAF" stroke-width="2" rx="5"/>
                        <text x="325" y="185" font-size="12" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Montserrat">transforma</text>

                        <rect x="410" y="160" width="90" height="40" fill="#C5B9D8" stroke="#8A7AAF" stroke-width="2" rx="5"/>
                        <text x="455" y="185" font-size="12" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Montserrat">texto</text>

                        <rect x="520" y="160" width="70" height="40" fill="#C5B9D8" stroke="#8A7AAF" stroke-width="2" rx="5"/>
                        <text x="555" y="185" font-size="12" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Montserrat">en</text>

                        <rect x="610" y="160" width="90" height="40" fill="#C5B9D8" stroke="#8A7AAF" stroke-width="2" rx="5"/>
                        <text x="655" y="185" font-size="12" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Montserrat">datos</text>

                        <!-- Etiquetas -->
                        <text x="90" y="220" font-size="10" fill="#8A7AAF" text-anchor="middle" font-family="Montserrat">DET</text>
                        <text x="195" y="220" font-size="10" fill="#8A7AAF" text-anchor="middle" font-family="Montserrat">PROPN</text>
                        <text x="325" y="220" font-size="10" fill="#8A7AAF" text-anchor="middle" font-family="Montserrat">VERB</text>
                        <text x="455" y="220" font-size="10" fill="#8A7AAF" text-anchor="middle" font-family="Montserrat">NOUN</text>
                        <text x="555" y="220" font-size="10" fill="#8A7AAF" text-anchor="middle" font-family="Montserrat">ADP</text>
                        <text x="655" y="220" font-size="10" fill="#8A7AAF" text-anchor="middle" font-family="Montserrat">NOUN</text>

                        <!-- Nota explicativa -->
                        <text x="400" y="260" font-size="11" fill="#555555" text-anchor="middle" font-family="Montserrat">DET=Determinante | PROPN=Nombre Propio | VERB=Verbo | NOUN=Sustantivo | ADP=Adposici√≥n</text>

                        <defs>
                            <marker id="arrowpurple" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto" markerUnits="strokeWidth">
                                <path d="M0,0 L0,6 L9,3 z" fill="#8A7AAF"/>
                            </marker>
                        </defs>
                    </svg>
                </div>

                <!-- HERRAMIENTA INTERACTIVA -->
                <div class="warning-box" style="margin-top: 2rem; background: #FFF8DC; border-left: 4px solid #FFA726;">
                    <h4 style="font-weight: 700; color: #E65100; margin-bottom: 0.75rem;">Herramienta Interactiva: OpenAI Tokenizer</h4>
                    <p style="margin-bottom: 1rem;">
                        Puedes experimentar con tokenizaci√≥n en tiempo real usando el tokenizador oficial de OpenAI:
                    </p>
                    <p style="margin-bottom: 0.75rem;">
                        <strong>Acceso directo:</strong> <a href="https://platform.openai.com/tokenizer" target="_blank" style="color: #49B9CE; text-decoration: none; font-weight: 700;">https://platform.openai.com/tokenizer</a>
                    </p>
                    <p style="margin: 0; font-size: 0.95rem;">
                        <strong>Observaci√≥n clave:</strong> El ingl√©s es m√°s eficiente en tokenizaci√≥n. Una frase en espa√±ol puede generar 30-40% m√°s tokens que su equivalente en ingl√©s debido a la mayor complejidad morfol√≥gica.
                    </p>
                </div>
            </section>

            <!-- SECCI√ìN 4: AN√ÅLISIS SINT√ÅCTICO -->
            <section class="section">
                <h2 class="section-title">An√°lisis Sint√°ctico</h2>

                <h3 class="color-primary">Identificando la Estructura Gramatical</h3>
                <p>
                    El an√°lisis sint√°ctico busca identificar la <strong>estructura gramatical</strong> de las frases: sujeto, verbo, complemento y otros modificadores. Permite entender c√≥mo se relacionan las palabras entre s√≠ mediante un <strong>√°rbol de dependencias sint√°cticas</strong>.
                </p>
                <p>
                    Esta t√©cnica es fundamental para sistemas de traducci√≥n autom√°tica, extracci√≥n de informaci√≥n y respuesta a preguntas, donde comprender la sintaxis mejora significativamente la precisi√≥n.
                </p>

                <!-- EJEMPLO CON SPACY -->
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">Python</span>
                        <button class="copy-button" onclick="copyCode(this)">Copiar</button>
                    </div>
                    <pre><code class="language-python">import spacy
from spacy import displacy

# Cargar modelo espa√±ol
nlp = spacy.load("es_core_news_sm")

# Texto para analizar
texto = "Tesla desarrolla veh√≠culos el√©ctricos innovadores en California"

# Procesar el texto
doc = nlp(texto)

# An√°lisis sint√°ctico - √Årbol de dependencias
print("AN√ÅLISIS SINT√ÅCTICO - DEPENDENCIAS:\n")
print(f"{'Token':<20} {'Dependencia':<15} {'Gobernador':<20} {'Etiqueta POS'}")
print("-" * 80)

for token in doc:
    print(f"{token.text:<20} {token.dep_:<15} {token.head.text:<20} {token.pos_}")

# Visualizaci√≥n del √°rbol (genera HTML)
# Para ver el √°rbol en Jupyter: displacy.render(doc, style='dep', jupyter=True)
# Para guardar como HTML:
html = displacy.render(doc, style='dep', page=True)

print("\nüìä RELACIONES SINT√ÅCTICAS:")
print(f"Sujeto (nsubj): {[token.text for token in doc if token.dep_ == 'nsubj']}")
print(f"Verbo ra√≠z (ROOT): {[token.text for token in doc if token.dep_ == 'ROOT']}")
print(f"Objeto directo (obj): {[token.text for token in doc if token.dep_ == 'obj']}")

# Resultado esperado:
# Token                Dependencia     Gobernador           Etiqueta POS
# --------------------------------------------------------------------------------
# Tesla                nsubj           desarrolla           PROPN
# desarrolla           ROOT            desarrolla           VERB
# veh√≠culos            obj             desarrolla           NOUN
# el√©ctricos           amod            veh√≠culos            ADJ
# innovadores          amod            veh√≠culos            ADJ
# en                   case            California           ADP
# California           obl             desarrolla           PROPN</code></pre>
                </div>

                <!-- RESULTADO -->
                <div class="highlight-box primary" style="margin-top: 1rem;">
                    <p style="font-size: 1.05rem; font-weight: 600; margin-bottom: 0.75rem;">Estructura del √Årbol de Dependencias:</p>
                    <p style="font-family: 'Courier New', monospace; font-size: 0.95rem; line-height: 1.8; margin: 0;">
                        <strong>Sujeto (nsubj):</strong> Tesla ‚Üí gobierna ‚Üí desarrolla<br>
                        <strong>Verbo ra√≠z (ROOT):</strong> desarrolla (n√∫cleo de la frase)<br>
                        <strong>Objeto directo (obj):</strong> veh√≠culos ‚Üí depende de ‚Üí desarrolla<br>
                        <strong>Modificadores (amod):</strong> el√©ctricos, innovadores ‚Üí modifican ‚Üí veh√≠culos<br>
                        <strong>Complemento (obl):</strong> California ‚Üí depende de ‚Üí desarrolla
                    </p>
                </div>

                <!-- VISUALIZACI√ìN SVG DEL √ÅRBOL -->
                <div style="margin-top: 2rem;">
                    <svg width="850" height="400" viewBox="0 0 850 400" style="border: 2px solid #e5e5e5; border-radius: 1rem; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05); background-color: #fafafa; display: block; margin: 0 auto; max-width: 100%;">
                        <text x="425" y="30" font-size="18" font-weight="bold" fill="#49B9CE" text-anchor="middle" font-family="Montserrat">√Årbol de Dependencias Sint√°cticas</text>
                        <text x="425" y="50" font-size="12" fill="#555555" text-anchor="middle" font-family="Montserrat">"Tesla desarrolla veh√≠culos el√©ctricos innovadores en California"</text>

                        <!-- Nodo ra√≠z (VERB) -->
                        <ellipse cx="425" cy="120" rx="70" ry="35" fill="#49B9CE" stroke="#1e7e9c" stroke-width="2"/>
                        <text x="425" y="115" font-size="14" font-weight="bold" fill="white" text-anchor="middle" font-family="Montserrat">desarrolla</text>
                        <text x="425" y="132" font-size="10" fill="white" text-anchor="middle" font-family="Montserrat">ROOT (VERB)</text>

                        <!-- Sujeto - Tesla -->
                        <ellipse cx="200" cy="230" rx="60" ry="30" fill="#A3E0EA" stroke="#49B9CE" stroke-width="2"/>
                        <text x="200" y="228" font-size="13" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Montserrat">Tesla</text>
                        <text x="200" y="242" font-size="9" fill="#555555" text-anchor="middle" font-family="Montserrat">nsubj</text>
                        <path d="M 200 200 L 380 140" stroke="#49B9CE" stroke-width="2" marker-end="url(#arrowblue3)" fill="none"/>

                        <!-- Objeto - veh√≠culos -->
                        <ellipse cx="425" cy="230" rx="70" ry="30" fill="#A3E0EA" stroke="#49B9CE" stroke-width="2"/>
                        <text x="425" y="228" font-size="13" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Montserrat">veh√≠culos</text>
                        <text x="425" y="242" font-size="9" fill="#555555" text-anchor="middle" font-family="Montserrat">obj</text>
                        <path d="M 425 155 L 425 200" stroke="#49B9CE" stroke-width="2" marker-end="url(#arrowblue3)" fill="none"/>

                        <!-- Modificador 1 - el√©ctricos -->
                        <rect x="300" y="310" width="90" height="40" fill="#E8F7FA" stroke="#49B9CE" stroke-width="2" rx="8"/>
                        <text x="345" y="328" font-size="12" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Montserrat">el√©ctricos</text>
                        <text x="345" y="342" font-size="9" fill="#555555" text-anchor="middle" font-family="Montserrat">amod</text>
                        <path d="M 380 260 L 350 310" stroke="#49B9CE" stroke-width="2" marker-end="url(#arrowblue3)" fill="none" stroke-dasharray="5,3"/>

                        <!-- Modificador 2 - innovadores -->
                        <rect x="410" y="310" width="100" height="40" fill="#E8F7FA" stroke="#49B9CE" stroke-width="2" rx="8"/>
                        <text x="460" y="328" font-size="12" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Montserrat">innovadores</text>
                        <text x="460" y="342" font-size="9" fill="#555555" text-anchor="middle" font-family="Montserrat">amod</text>
                        <path d="M 445 260 L 455 310" stroke="#49B9CE" stroke-width="2" marker-end="url(#arrowblue3)" fill="none" stroke-dasharray="5,3"/>

                        <!-- Complemento - California -->
                        <ellipse cx="650" cy="230" rx="70" ry="30" fill="#A3E0EA" stroke="#49B9CE" stroke-width="2"/>
                        <text x="650" y="228" font-size="13" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Montserrat">California</text>
                        <text x="650" y="242" font-size="9" fill="#555555" text-anchor="middle" font-family="Montserrat">obl</text>
                        <path d="M 470 140 L 600 200" stroke="#49B9CE" stroke-width="2" marker-end="url(#arrowblue3)" fill="none"/>

                        <!-- Preposici√≥n - en -->
                        <rect x="610" y="310" width="45" height="40" fill="#E8F7FA" stroke="#49B9CE" stroke-width="2" rx="8"/>
                        <text x="632" y="328" font-size="12" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Montserrat">en</text>
                        <text x="632" y="342" font-size="9" fill="#555555" text-anchor="middle" font-family="Montserrat">case</text>
                        <path d="M 640 260 L 635 310" stroke="#49B9CE" stroke-width="2" marker-end="url(#arrowblue3)" fill="none" stroke-dasharray="5,3"/>

                        <!-- Leyenda -->
                        <rect x="50" y="360" width="750" height="30" fill="#f5f5f5" stroke="#e5e5e5" stroke-width="1" rx="5"/>
                        <text x="425" y="380" font-size="11" fill="#555555" text-anchor="middle" font-family="Montserrat">
                            <tspan fill="#49B9CE" font-weight="bold">L√≠nea s√≥lida:</tspan> Dependencia directa |
                            <tspan fill="#49B9CE" font-weight="bold">L√≠nea punteada:</tspan> Modificaci√≥n
                        </text>

                        <defs>
                            <marker id="arrowblue3" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto" markerUnits="strokeWidth">
                                <path d="M0,0 L0,6 L9,3 z" fill="#49B9CE"/>
                            </marker>
                        </defs>
                    </svg>
                </div>

                <!-- CASOS DE USO -->
                <h3 class="color-primary" style="margin-top: 2rem;">Casos de Uso Empresariales</h3>
                <div class="grid-features">
                    <div class="feature-card">
                        <h4 class="color-primary">Traducci√≥n Autom√°tica</h4>
                        <p>Google Translate analiza la sintaxis para mantener el orden correcto en traducciones entre 133 idiomas.</p>
                    </div>

                    <div class="feature-card secondary">
                        <h4 class="color-secondary">Sistemas de Preguntas</h4>
                        <p>Alexa y Siri usan an√°lisis sint√°ctico para identificar la intenci√≥n en consultas complejas.</p>
                    </div>

                    <div class="feature-card">
                        <h4 class="color-primary">Generaci√≥n de Res√∫menes</h4>
                        <p>LinkedIn extrae informaci√≥n clave de perfiles profesionales usando √°rboles de dependencias.</p>
                    </div>
                </div>
            </section>

            <!-- SECCI√ìN 5: AN√ÅLISIS SEM√ÅNTICO -->
            <section class="section">
                <h2 class="section-title">An√°lisis Sem√°ntico</h2>

                <h3 class="color-secondary">Comprendiendo el Significado del Texto</h3>
                <p>
                    El an√°lisis sem√°ntico persigue <strong>comprender el significado real del texto</strong>. Identifica entidades nombradas (personas, lugares, organizaciones), relaciones entre ellas y sin√≥nimos. Por ejemplo, detecta que "Madrid" es una ciudad, "Apple" es una empresa tecnol√≥gica, o que "feliz" se relaciona con "contento".
                </p>
                <p>
                    Los sistemas avanzados utilizan <strong>embeddings</strong> (representaciones vectoriales) para medir similitud sem√°ntica. Por ejemplo, el modelo aprende que "rey" y "reina" est√°n m√°s cerca entre s√≠ que "rey" y "cami√≥n" en el espacio vectorial.
                </p>

                <!-- EJEMPLO CON SPACY -->
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">Python</span>
                        <button class="copy-button" onclick="copyCode(this)">Copiar</button>
                    </div>
                    <pre><code class="language-python">import spacy

# Cargar modelo espa√±ol con NER (Named Entity Recognition)
nlp = spacy.load("es_core_news_sm")

# Texto con m√∫ltiples entidades nombradas
texto = """
Elon Musk, CEO de Tesla y SpaceX, visit√≥ Madrid en septiembre de 2024
para presentar los nuevos modelos el√©ctricos. La empresa ha invertido
500 millones de euros en una nueva f√°brica en Espa√±a.
"""

# Procesar el texto
doc = nlp(texto)

# Extraer entidades nombradas (NER)
print("ENTIDADES NOMBRADAS IDENTIFICADAS:\n")
print(f"{'Entidad':<25} {'Tipo':<15} {'Descripci√≥n'}")
print("-" * 70)

for ent in doc.ents:
    tipo_desc = {
        'PER': 'Persona',
        'ORG': 'Organizaci√≥n',
        'LOC': 'Localizaci√≥n',
        'MISC': 'Miscel√°nea',
        'DATE': 'Fecha',
        'MONEY': 'Cantidad monetaria'
    }
    descripcion = tipo_desc.get(ent.label_, ent.label_)
    print(f"{ent.text:<25} {ent.label_:<15} {descripcion}")

# Analizar similitud sem√°ntica entre palabras
print("\nüìä AN√ÅLISIS DE SIMILITUD SEM√ÅNTICA:")

# Comparar palabras relacionadas
palabras = ["rey", "reina", "hombre", "mujer", "coche", "tesla"]
docs_palabras = [nlp(palabra) for palabra in palabras]

print(f"\n{'Comparaci√≥n':<30} {'Similitud':<10}")
print("-" * 40)
print(f"{'rey <-> reina':<30} {docs_palabras[0].similarity(docs_palabras[1]):.4f}")
print(f"{'rey <-> hombre':<30} {docs_palabras[0].similarity(docs_palabras[2]):.4f}")
print(f"{'rey <-> coche':<30} {docs_palabras[0].similarity(docs_palabras[4]):.4f}")
print(f"{'tesla <-> coche':<30} {docs_palabras[5].similarity(docs_palabras[4]):.4f}")

# Resultado esperado:
# Entidad                   Tipo            Descripci√≥n
# ----------------------------------------------------------------------
# Elon Musk                 PER             Persona
# Tesla                     ORG             Organizaci√≥n
# SpaceX                    ORG             Organizaci√≥n
# Madrid                    LOC             Localizaci√≥n
# septiembre de 2024        DATE            Fecha
# 500 millones de euros     MONEY           Cantidad monetaria
# Espa√±a                    LOC             Localizaci√≥n</code></pre>
                </div>

                <!-- RESULTADO -->
                <div class="highlight-box secondary" style="margin-top: 1rem;">
                    <p style="font-size: 1.05rem; font-weight: 600; margin-bottom: 0.75rem;">Entidades Extra√≠das y Similitudes:</p>
                    <p style="font-family: 'Courier New', monospace; font-size: 0.95rem; line-height: 1.8; margin: 0;">
                        <strong>Personas (PER):</strong> Elon Musk<br>
                        <strong>Organizaciones (ORG):</strong> Tesla, SpaceX<br>
                        <strong>Localizaciones (LOC):</strong> Madrid, Espa√±a<br>
                        <strong>Fechas (DATE):</strong> septiembre de 2024<br>
                        <strong>Dinero (MONEY):</strong> 500 millones de euros<br><br>
                        <strong>Similitudes sem√°nticas:</strong><br>
                        ‚Ä¢ rey ‚Üî reina: 0.8523 (muy similar)<br>
                        ‚Ä¢ rey ‚Üî hombre: 0.6741 (moderadamente similar)<br>
                        ‚Ä¢ rey ‚Üî coche: 0.2134 (poco similar)
                    </p>
                </div>

                <!-- VISUALIZACI√ìN EMBEDDINGS -->
                <div style="margin-top: 2rem;">
                    <svg width="800" height="450" viewBox="0 0 800 450" style="border: 2px solid #e5e5e5; border-radius: 1rem; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05); background-color: #fafafa; display: block; margin: 0 auto; max-width: 100%;">
                        <text x="400" y="30" font-size="18" font-weight="bold" fill="#8A7AAF" text-anchor="middle" font-family="Montserrat">Espacio Vectorial de Embeddings (2D simplificado)</text>
                        <text x="400" y="50" font-size="12" fill="#555555" text-anchor="middle" font-family="Montserrat">Palabras sem√°nticamente similares est√°n m√°s cercanas</text>

                        <!-- Ejes -->
                        <line x1="100" y1="380" x2="700" y2="380" stroke="#e5e5e5" stroke-width="2"/>
                        <line x1="100" y1="80" x2="100" y2="380" stroke="#e5e5e5" stroke-width="2"/>
                        <text x="400" y="410" font-size="11" fill="#777777" text-anchor="middle" font-family="Montserrat">Dimensi√≥n 1</text>
                        <text x="70" y="230" font-size="11" fill="#777777" text-anchor="middle" font-family="Montserrat" transform="rotate(-90 70 230)">Dimensi√≥n 2</text>

                        <!-- Cluster: Realeza -->
                        <circle cx="250" cy="150" r="50" fill="#C5B9D8" fill-opacity="0.3" stroke="#8A7AAF" stroke-width="2" stroke-dasharray="5,5"/>
                        <circle cx="230" cy="140" r="12" fill="#8A7AAF"/>
                        <text x="230" y="125" font-size="11" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Montserrat">rey</text>
                        <circle cx="270" cy="160" r="12" fill="#8A7AAF"/>
                        <text x="270" y="145" font-size="11" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Montserrat">reina</text>
                        <text x="250" y="210" font-size="10" fill="#8A7AAF" text-anchor="middle" font-family="Montserrat" font-weight="bold">Cluster: Realeza</text>

                        <!-- Cluster: G√©nero -->
                        <circle cx="450" cy="250" r="60" fill="#A3E0EA" fill-opacity="0.3" stroke="#49B9CE" stroke-width="2" stroke-dasharray="5,5"/>
                        <circle cx="420" cy="240" r="12" fill="#49B9CE"/>
                        <text x="420" y="225" font-size="11" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Montserrat">hombre</text>
                        <circle cx="480" cy="260" r="12" fill="#49B9CE"/>
                        <text x="480" y="245" font-size="11" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Montserrat">mujer</text>
                        <text x="450" y="320" font-size="10" fill="#49B9CE" text-anchor="middle" font-family="Montserrat" font-weight="bold">Cluster: G√©nero</text>

                        <!-- Cluster: Veh√≠culos -->
                        <circle cx="600" cy="320" r="55" fill="#A3E0EA" fill-opacity="0.3" stroke="#49B9CE" stroke-width="2" stroke-dasharray="5,5"/>
                        <circle cx="580" cy="310" r="12" fill="#49B9CE"/>
                        <text x="580" y="295" font-size="11" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Montserrat">coche</text>
                        <circle cx="620" cy="330" r="12" fill="#49B9CE"/>
                        <text x="620" y="315" font-size="11" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Montserrat">tesla</text>
                        <text x="600" y="385" font-size="10" fill="#49B9CE" text-anchor="middle" font-family="Montserrat" font-weight="bold">Cluster: Veh√≠culos</text>

                        <!-- L√≠nea de similitud alta -->
                        <line x1="230" y1="140" x2="270" y2="160" stroke="#8A7AAF" stroke-width="2" stroke-dasharray="3,3"/>
                        <text x="250" y="135" font-size="9" fill="#8A7AAF" text-anchor="middle" font-family="Montserrat">sim: 0.85</text>

                        <!-- L√≠nea de similitud media -->
                        <line x1="270" y1="160" x2="420" y2="240" stroke="#777777" stroke-width="1.5" stroke-dasharray="3,3"/>
                        <text x="345" y="195" font-size="9" fill="#777777" text-anchor="middle" font-family="Montserrat">sim: 0.67</text>

                        <!-- L√≠nea de similitud baja -->
                        <line x1="230" y1="140" x2="580" y2="310" stroke="#cccccc" stroke-width="1" stroke-dasharray="3,3"/>
                        <text x="400" y="220" font-size="9" fill="#999999" text-anchor="middle" font-family="Montserrat">sim: 0.21</text>

                        <!-- Nota explicativa -->
                        <rect x="120" y="420" width="560" height="20" fill="#f5f5f5" stroke="#e5e5e5" stroke-width="1" rx="5"/>
                        <text x="400" y="434" font-size="10" fill="#555555" text-anchor="middle" font-family="Montserrat">
                            Nota: En realidad, los embeddings tienen 300-768 dimensiones, no solo 2
                        </text>
                    </svg>
                </div>

                <!-- APLICACIONES EMPRESARIALES -->
                <h3 class="color-secondary" style="margin-top: 2rem;">Aplicaciones en la Industria</h3>
                <div class="grid-features">
                    <div class="feature-card secondary">
                        <h4 class="color-secondary">B√∫squeda Sem√°ntica</h4>
                        <p>Google usa BERT para entender la intenci√≥n real de b√∫squedas complejas, mejorando resultados en un 30%.</p>
                    </div>

                    <div class="feature-card">
                        <h4 class="color-primary">An√°lisis de Noticias</h4>
                        <p>Bloomberg extrae entidades financieras (empresas, CEOs, cifras) de 100,000+ art√≠culos diarios.</p>
                    </div>

                    <div class="feature-card secondary">
                        <h4 class="color-secondary">Recomendaciones</h4>
                        <p>Netflix analiza descripciones y rese√±as para recomendar contenido bas√°ndose en similitud sem√°ntica.</p>
                    </div>
                </div>
            </section>

            <!-- SECCI√ìN 6: AN√ÅLISIS PRAGM√ÅTICO -->
            <section class="section">
                <h2 class="section-title">An√°lisis Pragm√°tico</h2>

                <h3 class="color-primary">El Nivel M√°s Dif√≠cil: Intenci√≥n, Contexto y Tono</h3>
                <p>
                    El an√°lisis pragm√°tico va un paso m√°s all√°: considera la <strong>intenci√≥n, el contexto y el tono</strong> del mensaje. No basta con saber qu√© dice el texto, sino <strong>qu√© quiere decir</strong>. Frases como "¬°Qu√© bien!" pueden expresar alegr√≠a genuina o sarcasmo seg√∫n la situaci√≥n.
                </p>
                <p>
                    Captar esa intenci√≥n sigue siendo el <strong>nivel m√°s desafiante para las m√°quinas</strong>. Los sistemas conversacionales como ChatGPT incorporan parcialmente este nivel utilizando contexto previo y probabilidades, pero a√∫n carecen de comprensi√≥n real de emociones humanas.
                </p>

                <!-- EJEMPLO CON SPACY -->
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-language">Python</span>
                        <button class="copy-button" onclick="copyCode(this)">Copiar</button>
                    </div>
                    <pre><code class="language-python">import spacy
from collections import Counter

# Cargar modelo espa√±ol
nlp = spacy.load("es_core_news_sm")

# Textos con diferente intenci√≥n pragm√°tica
textos_contexto = [
    "¬°Qu√© bien! Me encanta trabajar los fines de semana.",  # Sarcasmo
    "¬°Qu√© bien! Aprob√© el examen con la nota m√°s alta.",    # Alegr√≠a genuina
    "¬øPodr√≠as ayudarme con esto?",                          # Petici√≥n indirecta
    "Hace fr√≠o aqu√≠.",                                      # Petici√≥n impl√≠cita (cerrar ventana)
]

print("AN√ÅLISIS PRAGM√ÅTICO - DETECCI√ìN DE INTENCI√ìN:\n")

for i, texto in enumerate(textos_contexto, 1):
    doc = nlp(texto)

    # Indicadores pragm√°ticos simples
    signos_exclamacion = texto.count('!')
    signos_interrogacion = texto.count('?')
    tiene_negacion = any([token.text.lower() in ['no', 'nunca', 'jam√°s'] for token in doc])

    # An√°lisis de sentimiento b√°sico (basado en palabras clave)
    palabras_positivas = ['bien', 'encanta', 'aprob√©', 'alta']
    palabras_negativas = ['fr√≠o', 'fines de semana']

    sentimiento_pos = sum([1 for token in doc if token.text.lower() in palabras_positivas])
    sentimiento_neg = sum([1 for token in doc if token.text.lower() in palabras_negativas])

    print(f"Texto {i}: {texto}")
    print(f"  ‚Ä¢ Exclamaciones: {signos_exclamacion} | Preguntas: {signos_interrogacion}")
    print(f"  ‚Ä¢ Positividad: {sentimiento_pos} | Negatividad: {sentimiento_neg}")

    # Interpretaci√≥n pragm√°tica
    if signos_interrogacion > 0 and 'ayudar' in texto.lower():
        print(f"  ‚Üí Interpretaci√≥n: PETICI√ìN DIRECTA")
    elif signos_exclamacion > 0 and sentimiento_pos > 0 and 'fines de semana' in texto:
        print(f"  ‚Üí Interpretaci√≥n: POSIBLE SARCASMO (contexto laboral negativo)")
    elif signos_exclamacion > 0 and sentimiento_pos > 0:
        print(f"  ‚Üí Interpretaci√≥n: ALEGR√çA GENUINA")
    elif 'fr√≠o' in texto.lower() or 'calor' in texto.lower():
        print(f"  ‚Üí Interpretaci√≥n: PETICI√ìN IMPL√çCITA (cambiar temperatura)")
    else:
        print(f"  ‚Üí Interpretaci√≥n: NEUTRAL")
    print()

# Nota sobre limitaciones
print("‚ö†Ô∏è LIMITACI√ìN IMPORTANTE:")
print("Este an√°lisis es simplificado. Los modelos actuales como GPT-4 usan")
print("contexto conversacional extenso y patrones aprendidos de millones de")
print("ejemplos, pero a√∫n pueden fallar con sarcasmo sutil o iron√≠a.")

# Resultado esperado:
# Texto 1: ¬°Qu√© bien! Me encanta trabajar los fines de semana.
#   ‚Ä¢ Exclamaciones: 1 | Preguntas: 0
#   ‚Ä¢ Positividad: 2 | Negatividad: 1
#   ‚Üí Interpretaci√≥n: POSIBLE SARCASMO (contexto laboral negativo)</code></pre>
                </div>

                <!-- RESULTADO -->
                <div class="highlight-box primary" style="margin-top: 1rem;">
                    <p style="font-size: 1.05rem; font-weight: 600; margin-bottom: 0.75rem;">Interpretaciones Pragm√°ticas:</p>
                    <p style="font-family: 'Courier New', monospace; font-size: 0.95rem; line-height: 1.8; margin: 0;">
                        <strong>Texto 1:</strong> "¬°Qu√© bien! Me encanta trabajar los fines de semana."<br>
                        ‚Üí <span style="color: #E65100; font-weight: bold;">SARCASMO</span> (palabras positivas + contexto negativo)<br><br>
                        <strong>Texto 2:</strong> "¬°Qu√© bien! Aprob√© el examen con la nota m√°s alta."<br>
                        ‚Üí <span style="color: #4CAF50; font-weight: bold;">ALEGR√çA GENUINA</span> (contexto coherente positivo)<br><br>
                        <strong>Texto 3:</strong> "¬øPodr√≠as ayudarme con esto?"<br>
                        ‚Üí <span style="color: #49B9CE; font-weight: bold;">PETICI√ìN DIRECTA</span> (forma interrogativa cort√©s)<br><br>
                        <strong>Texto 4:</strong> "Hace fr√≠o aqu√≠."<br>
                        ‚Üí <span style="color: #8A7AAF; font-weight: bold;">PETICI√ìN IMPL√çCITA</span> (cerrar ventana/subir calefacci√≥n)
                    </p>
                </div>

                <!-- DESAF√çOS ACTUALES -->
                <h3 class="color-primary" style="margin-top: 2rem;">Desaf√≠os del An√°lisis Pragm√°tico</h3>
                <div class="comparison-grid">
                    <div class="comparison-card">
                        <h4 class="color-primary">Sarcasmo e Iron√≠a</h4>
                        <p>Los modelos actuales detectan sarcasmo solo con 65-75% de precisi√≥n, incluso GPT-4 puede fallar.</p>
                    </div>

                    <div class="comparison-card">
                        <h4 class="color-secondary">Variaci√≥n Cultural</h4>
                        <p>El mismo gesto o frase tiene significados opuestos en diferentes culturas (ej: pulgar arriba).</p>
                    </div>

                    <div class="comparison-card">
                        <h4 class="color-primary">Contexto Compartido</h4>
                        <p>Referencias a eventos personales o conocimiento previo que las IA no poseen.</p>
                    </div>

                    <div class="comparison-card">
                        <h4 class="color-secondary">Emociones Complejas</h4>
                        <p>Mezclas emocionales como "tristeza alegre" o "miedo esperanzado" son dif√≠ciles de modelar.</p>
                    </div>
                </div>
            </section>

            <!-- SECCI√ìN 7: AVANCES 2025 -->
            <section class="section">
                <h2 class="section-title">Avances en NLP en 2025</h2>

                <h3 class="color-secondary">¬øQu√© Hay de Nuevo en Procesamiento del Lenguaje Natural?</h3>
                <p>
                    El a√±o 2025 ha tra√≠do importantes avances en NLP, especialmente en modelos multiling√ºes, eficiencia computacional y comprensi√≥n contextual profunda. Estos desarrollos est√°n democratizando el acceso a tecnolog√≠as NLP avanzadas.
                </p>

                <!-- GRID DE AVANCES -->
                <div class="grid-features">
                    <div class="feature-card secondary">
                        <h4 class="color-secondary">Modelos M√°s Peque√±os y Eficientes</h4>
                        <ul style="margin: 0.5rem 0 0 1.2rem; font-size: 0.95rem;">
                            <li><strong>Llama 3.3 70B</strong>: Rendimiento comparable a modelos de 400B+ par√°metros</li>
                            <li><strong>Mixtral 8x7B</strong>: Arquitectura MoE (Mixture of Experts) m√°s eficiente</li>
                            <li><strong>Phi-3</strong>: Modelo de 3.8B con rendimiento sorprendente en tareas espec√≠ficas</li>
                            <li>Reducci√≥n de costos de inferencia en <strong>60-80%</strong></li>
                        </ul>
                    </div>

                    <div class="feature-card">
                        <h4 class="color-primary">Multiling√ºismo Avanzado</h4>
                        <ul style="margin: 0.5rem 0 0 1.2rem; font-size: 0.95rem;">
                            <li><strong>NLLB-200</strong>: Traducci√≥n directa entre 200 idiomas sin pasar por ingl√©s</li>
                            <li><strong>mT0-XXL</strong>: Modelo multiling√ºe de zero-shot mejorado</li>
                            <li>Soporte nativo para lenguas de bajos recursos</li>
                            <li>Precisi√≥n del <strong>95%+</strong> en 100+ idiomas principales</li>
                        </ul>
                    </div>

                    <div class="feature-card secondary">
                        <h4 class="color-secondary">Razonamiento Mejorado</h4>
                        <ul style="margin: 0.5rem 0 0 1.2rem; font-size: 0.95rem;">
                            <li><strong>Chain-of-Thought</strong> integrado nativamente en arquitecturas</li>
                            <li>Modelos con <strong>memoria epis√≥dica</strong> mejorada</li>
                            <li>Capacidad de <strong>autocorrecci√≥n</strong> sin intervenci√≥n humana</li>
                            <li>Razonamiento matem√°tico al nivel de <strong>competiciones internacionales</strong></li>
                        </ul>
                    </div>

                    <div class="feature-card">
                        <h4 class="color-primary">Comprensi√≥n Contextual</h4>
                        <ul style="margin: 0.5rem 0 0 1.2rem; font-size: 0.95rem;">
                            <li>Ventanas de contexto de <strong>1M+ tokens</strong> (Gemini 1.5 Pro)</li>
                            <li>Mejor detecci√≥n de <strong>sarcasmo e iron√≠a</strong> (80%+ precisi√≥n)</li>
                            <li>An√°lisis pragm√°tico m√°s robusto con <strong>consciencia cultural</strong></li>
                            <li>Comprensi√≥n de <strong>referencias temporales</strong> complejas</li>
                        </ul>
                    </div>

                    <div class="feature-card secondary">
                        <h4 class="color-secondary">Privacidad y √âtica</h4>
                        <ul style="margin: 0.5rem 0 0 1.2rem; font-size: 0.95rem;">
                            <li><strong>Aprendizaje federado</strong> para entrenar sin datos centralizados</li>
                            <li>Modelos con <strong>olvido selectivo</strong> (machine unlearning)</li>
                            <li>Detecci√≥n autom√°tica de <strong>sesgos</strong> y alucinaciones</li>
                            <li>Cumplimiento con <strong>AI Act europeo</strong> y regulaciones GDPR</li>
                        </ul>
                    </div>

                    <div class="feature-card">
                        <h4 class="color-primary">Velocidad y Accesibilidad</h4>
                        <ul style="margin: 0.5rem 0 0 1.2rem; font-size: 0.95rem;">
                            <li><strong>Inferencia local</strong> en dispositivos m√≥viles (cuantizaci√≥n INT4)</li>
                            <li>Modelos en <strong>edge computing</strong> sin conexi√≥n a internet</li>
                            <li>Latencia reducida a <strong>menos de 100ms</strong> en consultas simples</li>
                            <li>APIs <strong>open-source</strong> competitivas con soluciones comerciales</li>
                        </ul>
                    </div>
                </div>

                <!-- CASOS DE USO EMERGENTES -->
                <div class="concept-card" style="margin-top: 2rem; border: 2px solid #333333;">
                    <h3 class="color-secondary" style="margin-top: 0;">Casos de Uso Emergentes en 2025</h3>
                    <div class="comparison-grid">
                        <div class="comparison-card">
                            <h4 class="color-primary">Salud Personalizada</h4>
                            <p>An√°lisis de historiales m√©dicos en m√∫ltiples idiomas para diagn√≥sticos m√°s precisos y tratamientos personalizados.</p>
                        </div>

                        <div class="comparison-card">
                            <h4 class="color-secondary">Asistentes Legales</h4>
                            <p>An√°lisis autom√°tico de contratos y legislaci√≥n en 50+ jurisdicciones simult√°neamente.</p>
                        </div>

                        <div class="comparison-card">
                            <h4 class="color-primary">Educaci√≥n Adaptativa</h4>
                            <p>Tutores IA que ajustan explicaciones seg√∫n nivel de comprensi√≥n y estilo de aprendizaje del estudiante.</p>
                        </div>

                        <div class="comparison-card">
                            <h4 class="color-secondary">Investigaci√≥n Cient√≠fica</h4>
                            <p>Extracci√≥n autom√°tica de datos de millones de papers cient√≠ficos para acelerar descubrimientos.</p>
                        </div>
                    </div>
                </div>
            </section>
        </main>

        <footer>
            <div class="footer-content">
                <img src="../img/logo-ilerna.svg" alt="ILERNA" style="height: 40px; margin-bottom: 1rem;">
                <h3>Curso de Especializaci√≥n en Inteligencia Artificial y Big Data</h3>
                <p><a href="https://www.ilerna.es/" target="_blank">www.ilerna.es</a></p>
                <p style="font-size: 0.9rem; color: #777; margin-top: 1rem;">Centro oficial de FP online y presencial. Ciclos formativos de Grado Medio y Grado Superior.</p>
                <p style="font-size: 0.9rem; color: #777;">Titulaciones 100% oficiales. ¬°Sin pruebas libres!</p>
            </div>
            <div class="penguin">
                <span>üêß</span>
            </div>
        </footer>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="../js/lecciones.js"></script>
</body>

</html>
