<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Integraci√≥n con IA en Rob√≥tica - iLERNA</title>
    <meta name="description"
        content="ILERNA - Curso de Especializaci√≥n de Big Data e Inteligencia Artificial. C√≥mo la IA ampl√≠a la autonom√≠a de los robots mediante visi√≥n, planificaci√≥n y navegaci√≥n inteligente.">
    <meta name="keywords"
        content="Rob√≥tica, Inteligencia Artificial, Visi√≥n por Computador, SLAM, Planificaci√≥n Aut√≥noma, Navegaci√≥n Inteligente, iLERNA">
    <meta name="author" content="Bjlanza">
    <meta name="organization" content="ILERNA">

    <!-- CSS Com√∫n de Lecciones -->
    <link rel="stylesheet" href="../css/lecciones.css">

    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700&display=swap" rel="stylesheet">
</head>

<body>
    <div class="container">

        <!-- Header con logo -->
        <header>
            <div class="header-container">
                <div class="logo-container">
                    <a href="../index.html">
                        <img src="../img/logo-ilerna.svg" alt="Logo iLERNA">
                    </a>
                    <div class="logo-text">
                        iLERNA
                        <span>Curso de Especializaci√≥n en IA y Big Data</span>
                    </div>
                </div>
                <div class="breadcrumb">
                    <a href="../index.html">Inicio</a> ‚Ä∫
                    <a href="index.html">Modelos de IA</a> ‚Ä∫
                    <a href="index.html#seccion-4-3">Programaci√≥n</a> ‚Ä∫
                    <span>Integraci√≥n con IA</span>
                </div>
            </div>
            <h1 class="text-center">Integraci√≥n con IA en Rob√≥tica</h1>
            <p class="subtitle text-center">Ampliando la autonom√≠a a trav√©s de la percepci√≥n y la inteligencia</p>
        </header>

        <!-- INTRODUCCI√ìN -->
        <section>
            <p>
                La integraci√≥n de la Inteligencia Artificial en la rob√≥tica marca la diferencia entre una m√°quina que
                simplemente repite movimientos y un <strong>agente aut√≥nomo</strong> capaz de entender su entorno y
                tomar decisiones racionales. Esta simbiosis se manifiesta principalmente en tres frentes cr√≠ticos.
            </p>
        </section>

        <!-- SECCI√ìN 1: VISI√ìN POR COMPUTADOR -->
        <section>
            <h2>1. Visi√≥n por Computador</h2>
            <div class="highlight-box primary mb-6">
                <h3 class="color-primary">üëÄ Percepci√≥n y Reconocimiento</h3>
                <p class="content">
                    La visi√≥n artificial permite al robot interpretar el mundo visual de la misma forma (o mejor) que un
                    humano. Mediante el uso de Redes Neuronales Convolucionales (CNN) y otros modelos de Deep Learning,
                    el robot adquiere capacidades fundamentales:
                </p>
                <ul class="list-disc-padded">
                    <li><strong>Detecci√≥n y Clasificaci√≥n de Objetos:</strong> Identificar herramientas, obst√°culos o
                        personas en tiempo real para interactuar con seguridad.</li>
                    <li><strong>Reconocimiento Facial:</strong> Crucial en robots de servicio y asistencia para
                        personalizar la interacci√≥n con el usuario.</li>
                    <li><strong>SLAM Visual:</strong> El robot es capaz de construir mapas del entorno mientras se
                        localiza en ellos utilizando √∫nicamente flujos de v√≠deo.</li>
                </ul>
            </div>
        </section>

        <!-- SECCI√ìN 2: PLANIFICACI√ìN AUT√ìNOMA -->
        <section>
            <h2>2. Planificaci√≥n Aut√≥noma</h2>
            <div class="highlight-box secondary mb-6">
                <h2 class="color-secondary">üß© Toma de Decisiones y Secuenciaci√≥n</h2>
                <p class="content">
                    La planificaci√≥n aut√≥noma permite al robot determinar la <strong>mejor secuencia de
                        acciones</strong>
                    para alcanzar un objetivo complejo sin intervenci√≥n humana constante. No se trata solo de moverse,
                    sino de razonar sobre el orden de las tareas.
                </p>
                <div class="scenario-box secondary mt-1">
                    <p><strong>Ejemplo:</strong> Un robot de rescate en una cat√°strofe analiza m√∫ltiples rutas posibles
                        y
                        prioriza aquellas con menor riesgo de colapso, ajustando su plan din√°micamente si detecta que un
                        camino
                        est√° bloqueado gracias a su capacidad de razonamiento l√≥gico aplicado al control.</p>
                </div>
            </div>
        </section>

        <!-- SECCI√ìN 3: NAVEGACI√ìN INTELIGENTE -->
        <section>
            <h2>3. Navegaci√≥n Inteligente y Fusi√≥n Sensorial</h2>
            <p>
                Un robot moderno no depende de un solo sensor. La IA gestiona la <strong>fusi√≥n sensorial</strong>,
                combinando datos de m√∫ltiples fuentes para crear un modelo mental del mundo preciso y robusto.
            </p>

            <!-- LIDAR -->
            <div class="highlight-box primary mb-6">
                <div class="grid-2-cols" style="align-items: center; gap: 3rem;">
                    <div>
                        <h3 class="color-primary">üì° LIDAR (Light Detection and Ranging)</h3>
                        <p class="content">
                            El sistema LIDAR es el "ojo l√°ser" del robot. Funciona emitiendo miles de pulsos de luz
                            infrarroja por segundo que rebotan en los objetos del entorno. Al medir el tiempo que tarda
                            cada pulso en regresar, el robot puede calcular distancias con una precisi√≥n milim√©trica.
                        </p>
                        <p class="content">
                            Esta tecnolog√≠a permite generar <strong>nubes de puntos 3D</strong> de alta fidelidad,
                            fundamentales para que el robot comprenda la geometr√≠a exacta de su alrededor. Es la pieza
                            clave en el mapeo SLAM, permitiendo que un robot cree un plano detallado de una habitaci√≥n
                            mientras se desplaza por ella sin necesidad de informaci√≥n previa.
                        </p>
                    </div>
                    <div class="text-center">
                        <svg width="280" height="280" viewBox="0 0 200 200" xmlns="http://www.w3.org/2000/svg"
                            style="background: rgba(73, 185, 206, 0.05); border-radius: 50%;">
                            <!-- Robot central -->
                            <circle cx="100" cy="100" r="25" fill="#1C3D5A" />
                            <circle cx="100" cy="100" r="18" fill="#49B9CE" />

                            <!-- Rayo de escaneo principal -->
                            <g>
                                <line x1="100" y1="100" x2="190" y2="100" stroke="#49B9CE" stroke-width="3"
                                    stroke-dasharray="5,3">
                                    <animateTransform attributeName="transform" type="rotate" from="0 100 100"
                                        to="360 100 100" dur="3s" repeatCount="indefinite" />
                                </line>
                                <polygon points="100,100 195,85 195,115" fill="rgba(73, 185, 206, 0.15)">
                                    <animateTransform attributeName="transform" type="rotate" from="0 100 100"
                                        to="360 100 100" dur="3s" repeatCount="indefinite" />
                                </polygon>
                            </g>

                            <!-- Puntos detectados din√°micos -->
                            <circle cx="170" cy="60" r="4" fill="#8A7AAF">
                                <animate attributeName="opacity" values="0;1;0" dur="2s" repeatCount="indefinite" />
                            </circle>
                            <circle cx="40" cy="140" r="5" fill="#8A7AAF">
                                <animate attributeName="opacity" values="0;1;0" dur="1.5s" repeatCount="indefinite" />
                            </circle>
                            <circle cx="150" cy="150" r="3" fill="#8A7AAF">
                                <animate attributeName="opacity" values="0;1;0" dur="2.5s" repeatCount="indefinite" />
                            </circle>
                            <circle cx="60" cy="40" r="4" fill="#8A7AAF">
                                <animate attributeName="opacity" values="0;1;0" dur="1.8s" repeatCount="indefinite" />
                            </circle>

                            <!-- Ondas de expansi√≥n -->
                            <circle cx="100" cy="100" r="30" fill="none" stroke="#49B9CE" stroke-width="1"
                                opacity="0.5">
                                <animate attributeName="r" values="30;95" dur="2s" repeatCount="indefinite" />
                                <animate attributeName="opacity" values="0.5;0" dur="2s" repeatCount="indefinite" />
                            </circle>
                        </svg>
                    </div>
                </div>
            </div>

            <!-- C√ÅMARAS RGB-D -->
            <div class="highlight-box secondary mb-6">
                <div class="grid-2-cols" style="align-items: center; gap: 3rem;">
                    <div class="text-center">
                        <svg width="300" height="250" viewBox="0 0 240 200" xmlns="http://www.w3.org/2000/svg">
                            <!-- Cuerpo de la c√°mara -->
                            <rect x="20" y="70" width="100" height="40" rx="4" fill="#1C3D5A" />
                            <circle cx="45" cy="90" r="8" fill="#49B9CE" /> <!-- Lente RGB -->
                            <circle cx="95" cy="90" r="8" fill="#8A7AAF" /> <!-- Lente Profundidad -->

                            <!-- Volumen de visi√≥n (Frustum) -->
                            <path d="M45,90 L200,30 L200,150 Z" fill="rgba(73, 185, 206, 0.1)" stroke="#49B9CE"
                                stroke-width="1" stroke-dasharray="3,2" />
                            <path d="M95,90 L220,50 L220,130 Z" fill="rgba(138, 122, 175, 0.1)" stroke="#8A7AAF"
                                stroke-width="1" stroke-dasharray="3,2" />

                            <!-- Objeto detectado con capas de profundidad -->
                            <g transform="translate(160, 60)">
                                <!-- Capa lejana -->
                                <rect x="0" y="0" width="40" height="60" fill="#1C3D5A" opacity="0.2">
                                    <animate attributeName="opacity" values="0.2;0.5;0.2" dur="3s"
                                        repeatCount="indefinite" />
                                </rect>
                                <!-- Capa media -->
                                <rect x="-10" y="10" width="40" height="60" fill="#8A7AAF" opacity="0.5">
                                    <animate attributeName="opacity" values="0.5;0.8;0.5" dur="3s"
                                        repeatCount="indefinite" />
                                </rect>
                                <!-- Capa cercana (Color) -->
                                <rect x="-20" y="20" width="40" height="60" fill="#49B9CE">
                                    <animate attributeName="x" values="-20;-15;-20" dur="3s" repeatCount="indefinite" />
                                </rect>
                            </g>

                            <text x="60" y="140" font-family="Montserrat" font-size="10" fill="#1C3D5A"
                                font-weight="bold">Fusi√≥n RGB + Depth</text>
                        </svg>
                    </div>
                    <div>
                        <h3 class="color-secondary">üì∑ C√°maras RGB-D</h3>
                        <p class="content">
                            A diferencia de una c√°mara convencional, una c√°mara RGB-D captures tanto el color (RGB) como
                            la <strong>informaci√≥n de profundidad</strong> (Depth) para cada p√≠xel. Esto crea un flujo
                            de datos rico
                            donde cada punto de la imagen tiene coordenadas espaciales reales.
                        </p>
                        <p class="content">
                            Esta informaci√≥n es vital para el reconocimiento de objetos y la interacci√≥n humano-robot.
                            Al combinar la imagen 2D con un mapa de profundidad, la IA puede realizar una
                            <strong>segmentaci√≥n 3D precisa</strong>, permitiendo al robot distinguir objetos
                            superpuestos o calcular la orientaci√≥n exacta de una pieza para ser manipulada con √©xito.
                        </p>
                    </div>
                </div>
            </div>

            <!-- ULTRASONIDOS -->
            <div class="highlight-box primary mb-6">
                <div class="grid-2-cols" style="align-items: center; gap: 3rem;">
                    <div>
                        <h3 class="color-primary">ü¶á Sensores Ultrasonidos (Sonar)</h3>
                        <p class="content">
                            Los sensores de ultrasonidos funcionan de forma similar al radar de los murci√©lagos. Emiten
                            una onda sonora inaudible y miden el eco al rebotar en una superficie. Son extremadamente
                            √∫tiles como <strong>parachoques virtuales</strong> de seguridad debido a su robustez y
                            rapidez.
                        </p>
                        <p class="content">
                            Su principal ventaja en el proceso de fusi√≥n sensorial es su capacidad para detectar objetos
                            "invisibles" para otros sensores, como cristales o espejos. Al integrar estos datos, el
                            robot tiene una <strong>redundancia de seguridad</strong> vital que evita colisiones en
                            situaciones donde los sensores √≥pticos fallar√≠an por iluminaci√≥n o transparencia.
                        </p>
                    </div>
                    <div class="text-center">
                        <svg width="280" height="220" viewBox="0 0 200 160" xmlns="http://www.w3.org/2000/svg">
                            <!-- Sensor -->
                            <rect x="10" y="60" width="40" height="40" rx="4" fill="#1C3D5A" />
                            <circle cx="30" cy="73" r="8" fill="#49B9CE" opacity="0.8" />
                            <circle cx="30" cy="87" r="8" fill="#49B9CE" opacity="0.8" />

                            <!-- Ondas de sonido salientes -->
                            <g stroke="#49B9CE" fill="none" stroke-linecap="round">
                                <path d="M60,60 Q80,80 60,100" stroke-width="2">
                                    <animate attributeName="d" values="M60,70 Q70,80 60,90; M60,40 Q100,80 60,120"
                                        dur="1s" repeatCount="indefinite" />
                                    <animate attributeName="opacity" values="1;0" dur="1s" repeatCount="indefinite" />
                                </path>
                                <path d="M80,50 Q120,80 80,110" stroke-width="3" opacity="0.6">
                                    <animate attributeName="d" values="M80,60 Q100,80 80,100; M80,20 Q160,80 80,140"
                                        dur="1s" begin="0.2s" repeatCount="indefinite" />
                                    <animate attributeName="opacity" values="0.6;0" dur="1s" begin="0.2s"
                                        repeatCount="indefinite" />
                                </path>
                            </g>

                            <!-- Obst√°culo -->
                            <rect x="160" y="40" width="15" height="80" rx="2" fill="#8A7AAF">
                                <animate attributeName="fill" values="#8A7AAF;#49B9CE;#8A7AAF" dur="1s"
                                    repeatCount="indefinite" />
                            </rect>

                            <!-- Eco de retorno -->
                            <path d="M150,70 Q130,80 150,90" stroke="#8A7AAF" stroke-width="2" fill="none">
                                <animate attributeName="d" values="M150,70 Q130,80 150,90; M60,60 Q40,80 60,100"
                                    dur="1s" begin="0.5s" repeatCount="indefinite" />
                                <animate attributeName="opacity" values="0;1;0" dur="1s" begin="0.5s"
                                    repeatCount="indefinite" />
                            </path>
                        </svg>
                    </div>
                </div>
            </div>

            <p class="content mt-2">
                Esa gesti√≥n masiva de datos ruidosos y descriptivos tiene un protagonista matem√°tico fundamental: el
                <strong>Filtro de Kalman</strong>. Junto con las redes neuronales operando en paralelo, este algoritmo
                permite construir mapas din√°micos y ejecutar una evasi√≥n de obst√°culos proactiva, garantizando una
                navegaci√≥n fluida y segura en entornos humanos cambiantes.
            </p>
        </section>

        <!-- SECCI√ìN 4: FILTRO DE KALMAN -->
        <section>
            <h2>4. El Filtro de Kalman: El "Cerebro" de la Estimaci√≥n</h2>
            <p>
                En rob√≥tica, nada es perfecto: los motores no siempre giran exactamente lo que se les pide y los
                sensores
                tienen un margen de error (ruido). El <strong>Filtro de Kalman</strong> es el algoritmo matem√°tico que
                se encarga de obtener la mejor estimaci√≥n posible del estado de un robot (su posici√≥n, velocidad, etc.)
                mezclando informaci√≥n de diversas fuentes.
            </p>

            <div class="strategy-card mt-2">
                <h4 class="strategy-title"><span class="phase-badge phase-1">Funcionamiento</span> ¬øC√≥mo trabaja el
                    Filtro de Kalman?</h4>
                <p>El proceso funciona en un bucle infinito de dos pasos que se repite cientos de veces por segundo:</p>
                <div class="grid-2-cols mt-2">
                    <div class="advantage-box">
                        <h4>1. Predicci√≥n (¬øD√≥nde deber√≠a estar?)</h4>
                        <p class="text-sm">
                            El robot utiliza su modelo f√≠sico interno para predecir su nuevo estado.
                            <em>"Si mis motores han girado 10 veces, deber√≠a haberme movido 1 metro hacia
                                adelante"</em>.
                            A medida que pasa el tiempo sin medir, la incertidumbre sobre esta predicci√≥n crece.
                        </p>
                    </div>
                    <div class="disadvantage-box" style="background: #E8F5E9; border-color: #4CAF50;">
                        <h4 style="color: #2E7D32;">2. Actualizaci√≥n (¬øQu√© dicen los sensores?)</h4>
                        <p class="text-sm" style="color: #333;">
                            El robot toma una medida con sus sensores (LIDAR, GPS, etc.).
                            <em>"Mi sensor dice que me he movido 0.95 metros"</em>. El algoritmo calcula entonces un
                            promedio
                            inteligente ponderado entre la predicci√≥n y la medida para obtener el <strong>estado m√°s
                                probable</strong>.
                        </p>
                    </div>
                </div>
            </div>

            <div class="highlight-box primary mt-2">
                <h3 class="color-primary">La Sinergia Perfecta</h3>
                <p class="content">
                    La magia del Filtro de Kalman es su capacidad de <strong>filtrar el ruido</strong>. Si un sensor da
                    un
                    valor absurdo de repente (por un destello de luz o un error puntual), el algoritmo le dar√° menos
                    peso
                    que a la predicci√≥n basada en el modelo f√≠sico, evitando que el robot realice movimientos bruscos o
                    err√°ticos. Es, en esencia, el algoritmo que aporta <strong>estabilidad y confianza</strong> a la
                    autonom√≠a rob√≥tica.
                </p>
            </div>
        </section>

        <!-- FOOTER -->
        <footer>
            <div class="footer-content">
                <h3>iLERNA</h3>
                <p class="subtitle">Curso de Especializaci√≥n en Inteligencia Artificial y Big Data</p>
                <a href="https://www.ilerna.es/" target="_blank">www.ilerna.es</a>
            </div>
            <p class="description">Centro oficial de FP online y presencial. Ciclos formativos de Grado Medio y Grado
                Superior.</p>
            <p class="description">Titulaciones 100% oficiales. ¬°Sin pruebas libres!</p>

            <div class="penguin">
                <span>üêß</span>
            </div>
        </footer>

    </div>

    <!-- Scripts -->
    <script src="../js/lecciones.js"></script>
</body>

</html>