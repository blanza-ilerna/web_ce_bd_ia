<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="M√≥dulo 5074 - Big Data Aplicado - iLERNA">
    <meta name="keywords" content="Big Data, Cloud Computing, Hadoop, MapReduce, Almacenamiento Distribuido, iLERNA">
    <meta name="author" content="Bjlanza">
    <meta name="organization" content="ILERNA">
    <title>5074. Big Data Aplicado | iLERNA</title>
    <link rel="stylesheet" href="../css/lecciones.css">
    <link rel="stylesheet" href="../css/index-lessons.css">
</head>

<body>
    <header>
        <div class="header-container">
            <div class="logo-container">
                <a href="../index.html">
                    <img src="../img/logo-ilerna.svg" alt="Logo iLERNA">
                </a>
                <div class="logo-text">
                    Curso de Especializaci√≥n
                    <span>Inteligencia Artificial y Big Data</span>
                </div>
            </div>
            <nav class="breadcrumb">
                <a href="../index.html">Inicio</a> ‚Üí
                <span>Big Data Aplicado</span>
            </nav>
        </div>
    </header>

    <main>
        <div class="hero">
            <h1>‚òÅÔ∏è M√≥dulo 5074</h1>
            <h2>Big Data Aplicado</h2>
            <p>99 horas ¬∑ 8 ECTS ¬∑ 6 Resultados de Aprendizaje</p>
        </div>

        <!-- Informaci√≥n del m√≥dulo -->
        <section class="section">
            <div class="info-module-card">
                <h3>üìò Informaci√≥n del M√≥dulo</h3>
                <p>
                    Consulta los resultados de aprendizaje, criterios de evaluaci√≥n y contenidos b√°sicos del m√≥dulo
                    profesional.
                </p>
                <a href="info-modulo.html" class="btn">Ver Informaci√≥n Completa</a>
            </div>

            <div class="info-module-card mt-2">
                <h3>üß† Mapa Mental del M√≥dulo</h3>
                <p>
                    Visualiza de forma interactiva la estructura completa del m√≥dulo: Resultados de Aprendizaje,
                    Contenidos B√°sicos y Criterios de Evaluaci√≥n.
                </p>
                <a href="mindmap.html" class="btn gradient-secondary">Explorar Mapa Mental</a>
            </div>
        </section>

        <!-- Temas del m√≥dulo -->
        <section class="section">
            <h2>üìö Temas del M√≥dulo</h2>

            <div class="lessons-grid">
                <div class="flip-card" onclick="this.classList.toggle('flipped')">
                    <div class="flip-card-inner">
                        <div class="flip-card-front">
                            <h3>Tema 1</h3>
                            <h4>Gesti√≥n de soluciones con sistemas de almacenamiento y herramientas del centro de datos
                            </h4>
                            <p>
                                Evoluci√≥n de los centros de datos hacia entornos definidos por software. Sistemas de
                                almacenamiento masivo y tipolog√≠as empresariales (DAS, NAS, SAN). Escalabilidad,
                                redundancia y t√©cnicas RAID. Monitorizaci√≥n, automatizaci√≥n y recuperaci√≥n ante
                                desastres. Integraci√≥n de anal√≠tica Big Data. Modelos cloud (IaaS, PaaS, SaaS) y
                                principales plataformas (AWS, Azure, GCP).
                            </p>
                            <div class="flip-icon">üîÑ</div>
                        </div>
                        <div class="flip-card-back">
                            <h3>Objetivos del Tema 1</h3>
                            <ul>
                                <li>Comprender la funci√≥n estrat√©gica del almacenamiento en los centros de datos,
                                    analizando su evoluci√≥n hacia entornos definidos por software.</li>
                                <li>Identificar y comparar las principales tipolog√≠as de almacenamiento empresarial
                                    (DAS, NAS, SAN e h√≠bridos).</li>
                                <li>Analizar los principios de escalabilidad y redundancia aplicados al almacenamiento
                                    masivo (RAID, replicaci√≥n, snapshots, erasure coding).</li>
                                <li>Aplicar estrategias de monitorizaci√≥n, automatizaci√≥n y recuperaci√≥n ante desastres
                                    para garantizar la continuidad del negocio.</li>
                                <li>Integrar la anal√≠tica de Big Data en los ecosistemas de almacenamiento.</li>
                                <li>Relacionar los modelos de servicio en la nube (IaaS, PaaS, SaaS) con el
                                    almacenamiento y procesamiento de grandes vol√∫menes de datos.</li>
                                <li>Comparar las principales plataformas cloud para Big Data (AWS, Azure, GCP).</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="flip-card" onclick="this.classList.toggle('flipped')">
                    <div class="flip-card-inner">
                        <div class="flip-card-front">
                            <h3>Tema 2</h3>
                            <h4>Gesti√≥n de sistemas de almacenamiento y ecosistemas Big Data</h4>
                            <p>
                                Computaci√≥n distribuida y paralela: conceptos b√°sicos, principios de paralelizaci√≥n y
                                ley de Amdahl. Sistemas de almacenamiento distribuidos con tolerancia a fallos y teorema
                                CAP. Herramientas del ecosistema Big Data: MapReduce, Pig, Hive, Flume, Sqoop, Oozie,
                                Apache Zookeeper y HBase. Automatizaci√≥n de jobs y consultas en entornos Big Data.
                            </p>
                            <div class="flip-icon">üîÑ</div>
                        </div>
                        <div class="flip-card-back">
                            <h3>Objetivos del Tema 2</h3>
                            <ul>
                                <li>Comprender la funci√≥n estrat√©gica del almacenamiento en los centros de datos y su
                                    evoluci√≥n hacia entornos definidos por software.</li>
                                <li>Identificar y comparar las principales tipolog√≠as de almacenamiento empresarial
                                    (DAS, NAS, SAN e h√≠bridos).</li>
                                <li>Analizar los principios de escalabilidad y redundancia aplicados al almacenamiento
                                    masivo.</li>
                                <li>Aplicar estrategias de monitorizaci√≥n, automatizaci√≥n y recuperaci√≥n ante desastres.
                                </li>
                                <li>Integrar la anal√≠tica de Big Data en los ecosistemas de almacenamiento.</li>
                                <li>Relacionar los modelos de servicio en la nube (IaaS, PaaS, SaaS) con el
                                    procesamiento de grandes vol√∫menes de datos.</li>
                                <li>Comparar las principales plataformas cloud para Big Data (AWS, Azure, GCP).</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="flip-card" onclick="this.classList.toggle('flipped')">
                    <div class="flip-card-inner">
                        <div class="flip-card-front">
                            <h3>Tema 3</h3>
                            <h4>Generaci√≥n de mecanismos de integridad de los datos y comprobaci√≥n de mantenimiento de
                                sistemas de archivos</h4>
                            <p>
                                Calidad de datos en entornos Big Data: detecci√≥n, correcci√≥n, limpieza y normalizaci√≥n.
                                Comprobaci√≥n de integridad mediante algoritmos de verificaci√≥n (hash, checksum) en
                                sistemas distribuidos como HDFS y Ceph. Movimiento de datos entre cl√∫steres,
                                actualizaci√≥n y migraci√≥n. Validaci√≥n autom√°tica, metadatos y trazabilidad. Herramientas
                                como Great Expectations y Apache NiFi.
                            </p>
                            <div class="flip-icon">üîÑ</div>
                        </div>
                        <div class="flip-card-back">
                            <h3>Objetivos del Tema 3</h3>
                            <ul>
                                <li>Comprender los principios de la computaci√≥n distribuida y paralela, analizando sus
                                    diferencias, ventajas y aplicaciones.</li>
                                <li>Identificar los componentes clave del ecosistema Hadoop (HDFS, YARN, MapReduce,
                                    Spark).</li>
                                <li>Analizar las caracter√≠sticas de los sistemas de almacenamiento distribuidos:
                                    escalabilidad, replicaci√≥n, consistencia y tolerancia a fallos.</li>
                                <li>Aplicar el teorema CAP y mecanismos de recuperaci√≥n para dise√±ar sistemas
                                    resilientes.</li>
                                <li>Reconocer las principales herramientas del ecosistema Big Data (Hive, Pig, Sqoop,
                                    Flume, Oozie, Airflow, Kafka, Cassandra, HBase, Ceph).</li>
                                <li>Dise√±ar y automatizar pipelines de procesamiento mediante orquestadores como Airflow
                                    u Oozie.</li>
                                <li>Evaluar casos de uso reales en distintos sectores.</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="flip-card" onclick="this.classList.toggle('flipped')">
                    <div class="flip-card-inner">
                        <div class="flip-card-front">
                            <h3>Tema 4</h3>
                            <h4>Monitorizaci√≥n, optimizaci√≥n y resoluci√≥n de problemas</h4>
                            <p>
                                Herramientas de monitorizaci√≥n: JobTracker, NameNode, m√©tricas de rendimiento y
                                latencia. An√°lisis de hist√≥ricos de ejecuci√≥n, identificaci√≥n de cuellos de botella y
                                patrones de fallo. Monitorizaci√≥n especializada con Ganglia, Nagios, Prometheus y
                                paneles visuales con Grafana. Optimizaci√≥n del cl√∫ster Big Data y queries PromQL.
                            </p>
                            <div class="flip-icon">üîÑ</div>
                        </div>
                        <div class="flip-card-back">
                            <h3>Objetivos del Tema 4</h3>
                            <ul>
                                <li>Comprender la importancia de la calidad e integridad de los datos en entornos Big
                                    Data y su impacto en an√°lisis y decisiones.</li>
                                <li>Identificar las dimensiones clave de la calidad de datos y aplicar m√©tricas (KPIs)
                                    para su evaluaci√≥n.</li>
                                <li>Detectar y corregir errores utilizando reglas de validaci√≥n, modelos estad√≠sticos o
                                    de machine learning.</li>
                                <li>Aplicar t√©cnicas de limpieza y normalizaci√≥n garantizando coherencia en formatos y
                                    escalas.</li>
                                <li>Dise√±ar sistemas de monitoreo continuo con Airflow, Grafana o Great Expectations.
                                </li>
                                <li>Comprender mecanismos de verificaci√≥n de integridad empleando checksums, hash y
                                    recuperaci√≥n autom√°tica.</li>
                                <li>Planificar procesos de migraci√≥n y replicaci√≥n con DistCp, NiFi o AWS DataSync.</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="flip-card" onclick="this.classList.toggle('flipped')">
                    <div class="flip-card-inner">
                        <div class="flip-card-front">
                            <h3>Tema 5</h3>
                            <h4>Validaci√≥n de t√©cnicas Big Data en la toma de decisiones en Inteligencia de Negocios
                                (BI)</h4>
                            <p>
                                Modelos de Inteligencia de Negocios: ETL, Data Warehouse, OLAP. Proceso KDD (Knowledge
                                Discovery in Databases): selecci√≥n, limpieza, transformaci√≥n, miner√≠a e interpretaci√≥n.
                                Implantaci√≥n de modelos BI con Power BI, Tableau, Qlik, Looker. Integraci√≥n con Hadoop,
                                Spark, Presto. T√©cnicas de validaci√≥n estad√≠stica y de negocio.
                            </p>
                            <div class="flip-icon">üîÑ</div>
                        </div>
                        <div class="flip-card-back">
                            <h3>Objetivos del Tema 5</h3>
                            <ul>
                                <li>Comprender la importancia de la monitorizaci√≥n en entornos Big Data identificando
                                    componentes cr√≠ticos.</li>
                                <li>Conocer las principales herramientas de observabilidad: JobTracker, NameNode UI,
                                    Prometheus, Grafana, ELK, Nagios, Ganglia.</li>
                                <li>Analizar m√©tricas de rendimiento y latencia estableciendo umbrales y KPIs.</li>
                                <li>Dise√±ar sistemas de alertas y gesti√≥n de logs centralizados con Elastic Stack o
                                    Alertmanager.</li>
                                <li>Interpretar hist√≥ricos de ejecuci√≥n identificando patrones de fallo y cuellos de
                                    botella.</li>
                                <li>Optimizar el rendimiento del cl√∫ster ajustando configuraciones en Hadoop, Spark,
                                    YARN o Ceph.</li>
                                <li>Implementar soluciones avanzadas integrando Prometheus, Grafana y orquestadores como
                                    Airflow o Kubernetes.</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- √çndice de contenidos -->
        <section class="section">
            <h2>üìë √çndice de contenidos</h2>

            <!-- Leyenda de c√≥digo de colores -->
            <div class="color-legend">
                <div class="legend-item">
                    <div class="legend-color basica"></div>
                    <span>B√°sica</span>
                </div>
                <div class="legend-item">
                    <div class="legend-color intermedia"></div>
                    <span>Ampliaci√≥n</span>
                </div>
                <div class="legend-item">
                    <div class="legend-color opcional"></div>
                    <span>Opcional</span>
                </div>
                <div class="legend-item">
                    <div class="legend-color video"></div>
                    <span>Video</span>
                </div>
            </div>

            <div class="content-index-box">
                <h3 class="content-index-title">Tema 1. Gesti√≥n de soluciones con sistemas de almacenamiento y
                    herramientas del centro de datos para la resoluci√≥n de problemas</h3>

                <div class="content-index-section">
                    <h4 class="content-index-subtitle">1.1 Introducci√≥n a la gesti√≥n de soluciones en entornos de
                        almacenamiento</h4>
                    <ul class="content-index-list">
                        <li>1.1.1 La evoluci√≥n de los Centros de Datos y su impacto en la gesti√≥n de almacenamiento</li>
                        <li>1.1.2 Rol del administrador de almacenamiento</li>
                        <li>1.1.3 Herramientas y tecnolog√≠as emergentes</li>
                    </ul>

                    <h4 class="content-index-subtitle">1.2 Almacenamiento de datos masivo (Mass Storage Systems)</h4>

                    <div class="lesson-links-container">
                        <a href="mass_storage_systems.html" class="lesson-link-card basica">
                            <h5>üíæ Mass Storage Systems</h5>
                            <p>Sistemas de almacenamiento masivo para Big Data: DAS, NAS, SAN, Object Storage. HDFS,
                                Ceph, S3. Escalabilidad, redundancia, throughput y casos de uso en data centers
                                modernos.</p>
                        </a>
                    </div>

                    <ul class="content-index-list">
                        <li>1.2.1 Conceptos fundamentales del almacenamiento masivo</li>
                        <li>1.2.2 Tipolog√≠as de almacenamiento empresarial</li>
                        <li>1.2.3 Escalabilidad y redundancia en infraestructuras de datos masivos</li>
                        <ul>
                            <li>1.2.3.1 Escalabilidad Vertical vs. Horizontal</li>

                            <div class="lesson-links-container">
                                <a href="escalabilidad_bigdata.html" class="lesson-link-card basica">
                                    <h5>üìà Escalabilidad Horizontal y Vertical en Big Data</h5>
                                    <p>Estrategias de escalado para sistemas Big Data: Scale-Up vs Scale-Out.
                                        Comparaci√≥n de costes, complejidad, disponibilidad y consistencia. Casos reales
                                        de Hadoop, Spark, Cassandra y Elasticsearch. √Årbol de decisi√≥n CP vs AP.
                                        Arquitecturas h√≠bridas y mejores pr√°cticas para clusters distribuidos.</p>
                                </a>
                            </div>

                            <li>1.2.3.2 T√©cnicas de redundancia</li>
                            <li>1.2.3.3 Equilibrio entre escalabilidad y redundancia</li>
                        </ul>
                        <li>1.2.4 Casos de uso en empresas de alto volumen de datos</li>
                        <ul>
                            <li>1.2.4.1 Sector financiero</li>
                            <li>1.2.4.2 Telecomunicaciones</li>
                            <li>1.2.4.3 Sanidad</li>
                            <li>1.2.4.4 E-commerce y Retail</li>
                            <li>1.2.4.5 Ciencia e Investigaci√≥n</li>
                        </ul>
                    </ul>

                    <h4 class="content-index-subtitle">1.3 Herramientas y estrategias para la resoluci√≥n de problemas
                    </h4>
                    <ul class="content-index-list">
                        <li>1.3.1 Monitorizaci√≥n y observabilidad</li>
                        <li>1.3.2 Automatizaci√≥n y orquestaci√≥n</li>
                        <li>1.3.3 Estrategias de Recuperaci√≥n ante Desastres</li>
                    </ul>

                    <h4 class="content-index-subtitle">1.4 Anal√≠tica de Big Data en los ecosistemas de almacenamiento
                    </h4>
                    <ul class="content-index-list">
                        <li>1.4.1 Integraci√≥n de la anal√≠tica en la infraestructura de datos</li>
                        <ul>
                            <li>1.4.1.1 Componentes de una arquitectura de Datos Moderna</li>
                            <li>1.4.1.2 Data Lakes y Lakehouses: la nueva generaci√≥n de almacenamiento</li>
                            <li>1.4.1.3 Beneficios de la integraci√≥n</li>
                        </ul>
                        <li>1.4.2 An√°lisis descriptivo, predictivo y prescriptivo</li>
                        <ul>
                            <li>1.4.2.1 An√°lisis descriptivo</li>
                            <li>1.4.2.2 An√°lisis predictivo</li>
                            <li>1.4.2.3 An√°lisis prescriptivo</li>
                            <li>1.4.2.4 Ciclo de madurez anal√≠tica</li>
                        </ul>
                        <li>1.4.3 Herramientas de an√°lisis (Spark, Hadoop, Presto, etc.)</li>
                        <ul>
                            <li>1.4.3.1 Apache Hadoop</li>
                            <li>1.4.3.2 Apache Spark</li>

                            <div class="lesson-links-container">
                                <a href="databricks_spark.html" class="lesson-link-card intermedia">
                                    <h5>‚ö° Databricks Free Edition - Tutorial Apache Spark</h5>
                                    <p>Tutorial completo de Databricks con Apache Spark: arquitectura de clusters,
                                        creaci√≥n de notebooks, DataFrames, operaciones de transformaci√≥n, SQL en Spark,
                                        lectura/escritura de archivos (CSV, Parquet, Delta Lake), visualizaciones y
                                        mejores pr√°cticas. Incluye ejemplos pr√°cticos paso a paso.</p>
                                </a>
                                <a href="dataframes_deltalake.html" class="lesson-link-card intermedia">
                                    <h5>üìä DataFrames y Delta Lake en Databricks</h5>
                                    <p>Procesamiento distribuido con DataFrames de Spark y almacenamiento ACID con Delta
                                        Lake. Operaciones avanzadas: MERGE, UPDATE, DELETE, Time Travel, versionado,
                                        OPTIMIZE y Z-ORDER. Casos reales de Netflix, Visa, Adobe y Shell.</p>
                                </a>
                            </div>

                            <li>1.4.3.3 Presto (Trino)</li>
                            <li>1.4.3.4 Otras herramientas relevantes</li>
                        </ul>
                    </ul>

                    <h4 class="content-index-subtitle">1.5 C√≥digo de ejemplo: pipeline de an√°lisis Predictivo con Spark
                    </h4>

                    <h4 class="content-index-subtitle">1.6 Big Data y Cloud Computing</h4>
                    <ul class="content-index-list">
                        <li>1.6.1 Sinergias entre Big Data y entornos Cloud</li>
                        <ul>
                            <li>1.6.1.1 Escalabilidad din√°mica</li>
                            <li>1.6.1.2 Elasticidad y automatizaci√≥n</li>
                            <li>1.6.1.3 Acceso Global y colaboraci√≥n</li>
                            <li>1.6.1.4 Eficiencia en costes</li>
                            <li>1.6.1.5 Integraci√≥n con IA y Machine learning</li>
                            <li>1.6.1.6 Seguridad y cumplimiento normativo</li>
                        </ul>
                        <li>1.6.2 Modelos de servicio (IaaS, PaaS, SaaS) aplicados al almacenamiento</li>

                        <div class="lesson-links-container">
                            <a href="modelos_servicio_cloud.html" class="lesson-link-card basica">
                                <h5>‚òÅÔ∏è Modelos de Servicio Cloud: IaaS, PaaS, SaaS</h5>
                                <p>Comparativa exhaustiva de los tres modelos de servicio en la nube aplicados a Big
                                    Data e IA. IaaS para clusters Spark y storage masivo (S3, Ceph). PaaS para ML
                                    gestionado (SageMaker, BigQuery). SaaS para analytics (Tableau, Salesforce
                                    Einstein). Casos reales de Spotify, Twitter, Coca-Cola. Criterios de selecci√≥n y
                                    arquitecturas h√≠bridas.</p>
                            </a>
                        </div>

                        <ul>
                            <li>1.6.2.1 Infraestructura como Servicio (IaaS)</li>
                            <li>1.6.2.2 Plataforma como Servicio (PaaS)</li>
                            <li>1.6.2.3 Software como Servicio (SaaS)</li>
                        </ul>
                        <li>1.6.3 Ventajas del despliegue en nube h√≠brida</li>
                        <ul>
                            <li>1.6.3.1 Flexibilidad operativa</li>
                            <li>1.6.3.2 Optimizaci√≥n de costes</li>
                            <li>1.6.3.3 Continuidad del negocio y recuperaci√≥n ante desastres</li>
                            <li>1.6.3.4 Cumplimiento regulatorio</li>
                            <li>1.6.3.5 Integraci√≥n con m√∫ltiples proveedores</li>
                        </ul>
                        <li>1.6.4 Principales plataformas Cloud para Big Data (AWS, Azure, GCP)</li>
                        <ul>
                            <li>1.6.4.1 Amazon Web Services (AWS)</li>
                            <li>1.6.4.2 Microsoft Azure</li>
                            <li>1.6.4.3 Google Cloud Platform (GCP)</li>
                        </ul>
                    </ul>

                    <h4 class="content-index-subtitle">1.7 C√≥digo de ejemplo: pipeline de an√°lisis con AWS SageMaker y
                        S3</h4>
                </div>
            </div>

            <div class="content-index-box">
                <h3 class="content-index-title">Tema 2. Gesti√≥n de sistemas de almacenamiento y ecosistemas Big Data
                </h3>

                <div class="content-index-section">
                    <h4 class="content-index-subtitle">2.1 Computaci√≥n distribuida y paralela</h4>
                    <ul class="content-index-list">
                        <li>2.1.1 Conceptos b√°sicos de computaci√≥n distribuida</li>
                        <li>2.1.2 Principios de paralelizaci√≥n de tareas</li>

                        <ul>
                            <li>a) Limitaciones: ley de Amdahl</li>
                            <div class="lesson-links-container">
                                <a href="ley-amdahl.html" class="lesson-link-card intermedia">
                                    <h5>‚öñÔ∏è Ley de Amdahl</h5>
                                    <p>L√≠mites te√≥ricos de la paralelizaci√≥n. An√°lisis matem√°tico de la aceleraci√≥n
                                        alcanzable al paralelizar un programa. C√°lculo del speedup m√°ximo seg√∫n la
                                        fracci√≥n paralelizable y casos de uso en sistemas distribuidos.</p>
                                </a>
                            </div>
                        </ul>
                        <li>2.1.3 Comparativa entre computaci√≥n paralela y distribuida</li>
                        <li>2.1.4 Ejemplo pr√°ctico de h√≠brido</li>
                        <li>2.1.5 Caso de estudio</li>
                        <li>2.1.6 Ejemplos pr√°cticos en entornos de cl√∫ster Hadoop</li>
                        <li>2.1.7 C√≥digo de ejemplo: job MapReduce en Hadoop</li>
                    </ul>

                    <h4 class="content-index-subtitle">2.2 Sistemas de almacenamiento distribuidos y tolerancia a fallos
                    </h4>
                    <ul class="content-index-list">
                        <li>a) Teorema CAP</li>
                        <li>2.2.1 Caracter√≠sticas y ventajas del almacenamiento distribuido</li>
                        <li>2.2.2 Replicaci√≥n de datos y consistencia</li>
                        <li>2.2.3 Mecanismos de recuperaci√≥n ante fallos</li>
                        <li>2.2.4 C√≥digo de ejemplo: configuraci√≥n de replicaci√≥n en HDFS</li>
                    </ul>

                    <h4 class="content-index-subtitle">2.3 Herramientas del ecosistema Big Data</h4>
                    <ul class="content-index-list">
                        <li>2.3.1 MapReduce</li>
                        <li>2.3.2 Pig, Hive y Flume</li>
                        <div class="lesson-links-container">
                            <a href="pig-hive-flume.html" class="lesson-link-card basica">
                                <h5>üê∑ Pig, Hive y Flume: Herramientas del Ecosistema Hadoop</h5>
                                <p>Apache Pig (Pig Latin): procesamiento batch con abstracciones de alto nivel. Apache Hive
                                    (HiveQL): Data Warehousing con sintaxis SQL sobre Hadoop. Apache Flume: ingesta masiva
                                    de logs y datos streaming. Arquitecturas, casos de uso (Yahoo, LinkedIn, Twitter) y
                                    ejemplos pr√°cticos de ETL, an√°lisis de logs y pipelines de datos.</p>
                            </a>
                        </div>
                        <li>2.3.3 Sqoop y Oozie</li>

                        <div class="lesson-links-container">
                            <a href="sqoop_oozie.html" class="lesson-link-card basica">
                                <h5>üîÑ Sqoop y Oozie: Integraci√≥n y Orquestaci√≥n</h5>
                                <p>Apache Sqoop: puente bidireccional RDBMS ‚ÜîÔ∏è Hadoop (import/export masivo). Apache
                                    Oozie: orquestador de workflows complejos (DAG, coordinadores, bundles). Ejemplos
                                    pr√°cticos: import incremental, export a MySQL, pipelines ETL automatizados. Casos
                                    reales de Walmart (5 TB/d√≠a), LinkedIn (50,000+ workflows diarios) y BBVA (detecci√≥n
                                    fraude). Pipeline E-commerce completo integrando todas las herramientas Hadoop.</p>
                            </a>
                        </div>

                        <li>2.3.4 Automatizaci√≥n de Jobs en entornos Big Data</li>
                        <li>2.3.5 Consultas con Pig y Hive</li>
                        <li>2.3.6 Otras herramientas complementarias</li>
                        <ul>
                            <li>2.3.6.1 Apache Zookeeper</li>
                            <li>2.3.6.2 HBase</li>
                            <li>2.3.6.3 Apache Cassandra</li>
                            <li>2.3.6.4 Apache Kafka</li>

                            <div class="lesson-links-container">
                                <a href="../sist_bigdata/kafka.html" class="lesson-link-card basica">
                                    <h5>üì° Apache Kafka en Big Data</h5>
                                    <p>Plataforma de streaming distribuido para procesamiento de datos en tiempo real.
                                        Arquitectura (topics, particiones, brokers), productores y consumidores en
                                        Python/Java,
                                        Kafka Streams, ksqlDB, casos de uso en Netflix, Uber y LinkedIn.</p>
                                </a>
                            </div>
                        </ul>
                    </ul>

                    <h4 class="content-index-subtitle">2.4 C√≥digo de ejemplo: pipeline Automatizado con Airflow y Hive
                    </h4>
                </div>
            </div>

            <div class="content-index-box">
                <h3 class="content-index-title">Tema 3. Generaci√≥n de mecanismos de integridad de los datos y
                    comprobaci√≥n de mantenimiento de sistemas de archivos</h3>

                <div class="content-index-section">
                    <h4 class="content-index-subtitle">3.1 Calidad de los datos en entornos Big Data</h4>
                    <ul class="content-index-list">
                        <li>3.1.1 Definici√≥n y dimensiones de la calidad de datos</li>

                        <div class="lesson-links-container">
                            <a href="calidad_datos.html" class="lesson-link-card basica">
                                <h5>üìê Calidad de Datos en Big Data</h5>
                                <p>Principales dimensiones de la calidad: exactitud, completitud, consistencia y
                                    trazabilidad. KPIs cuantificables, dashboards de monitoreo con Grafana y marcos de
                                    trabajo como Great Expectations para garantizar la fiabilidad del dato.</p>
                            </a>
                        </div>

                        <li>3.1.2 Detecci√≥n y correcci√≥n de errores</li>

                        <div class="lesson-links-container">
                            <a href="deteccion_correccion_errores.html" class="lesson-link-card basica">
                                <h5>üîç Detecci√≥n y Correcci√≥n de Errores en Big Data</h5>
                                <p>Tipolog√≠as de errores en Big Data: sint√°cticos, sem√°nticos y de integraci√≥n. M√©todos
                                    de detecci√≥n mediante validaciones, cross-checking y ML. Estrategias de correcci√≥n e
                                    imputaci√≥n predictiva con PySpark.</p>
                            </a>
                        </div>

                        <li>3.1.3 Limpieza y normalizaci√≥n</li>

                        <div class="lesson-links-container">
                            <a href="limpieza_normalizacion.html" class="lesson-link-card basica">
                                <h5>üßπ Limpieza y Normalizaci√≥n de Datos en Big Data</h5>
                                <p>Etapas del proceso: profiling, estandarizaci√≥n de formatos, gesti√≥n de valores
                                    faltantes y eliminaci√≥n de duplicados. T√©cnicas de normalizaci√≥n num√©rica y
                                    categ√≥rica para preparar los datos para an√°lisis avanzado.</p>
                            </a>
                        </div>

                        <li>3.1.4 Monitoreo continuo de la calidad</li>

                        <div class="lesson-links-container">
                            <a href="codigo_monitoreo_cont_calidad.html" class="lesson-link-card basica">
                                <h5>üõ°Ô∏è Monitoreo Continuo de Calidad</h5>
                                <p>La calidad como proceso continuo. Observabilidad de datos con m√©tricas de completitud
                                    y latencia, alertas automatizadas y dashboards en Grafana para la detecci√≥n temprana
                                    de anomal√≠as en el pipeline.</p>
                            </a>
                        </div>
                    </ul>

                    <h4 class="content-index-subtitle">3.2 C√≥digo de ejemplo: validaci√≥n de Calidad con Great
                        Expectations</h4>

                    <div class="lesson-links-container">
                        <a href="codigo_validacion_calidad_great_expectations.html" class="lesson-link-card basica">
                            <h5>‚úÖ Validaci√≥n de Calidad con Great Expectations</h5>
                            <p>Framework de validaci√≥n de datos para pipelines Big Data. Definici√≥n de expectativas,
                                validaci√≥n automatizada, generaci√≥n de documentaci√≥n y checkpoints. Ejemplos pr√°cticos
                                de validaci√≥n de DataFrames y conexi√≥n con fuentes de datos.</p>
                        </a>
                    </div>

                    <h4 class="content-index-subtitle">3.3 Comprobaci√≥n de la integridad de datos en sistemas de
                        archivos distribuidos</h4>
                    <ul class="content-index-list">
                        <li>3.3.1 Concepto de integridad y verificaci√≥n</li>

                        <div class="lesson-links-container">
                            <a href="integridad_verificacion_datos.html" class="lesson-link-card basica">
                                <h5>üõ°Ô∏è Concepto de Integridad y Verificaci√≥n</h5>
                                <p>Explora qu√© es la integridad de datos, las principales causas de su p√©rdida (fallos
                                    f√≠sicos, bit rot, ataques) y c√≥mo los mecanismos de verificaci√≥n como checksums
                                    garantizan la fiabilidad en sistemas distribuidos.</p>
                            </a>
                        </div>
                        <li>3.3.2 Algoritmos de suma de verificaci√≥n (hash, checksum)</li>
                        <li>3.3.3 Implementaci√≥n pr√°ctica en HDFS y Ceph</li>
                        <li>3.3.4 Estrategias de validaci√≥n y reparaci√≥n autom√°tica</li>
                        <li>3.3.5 C√≥digo de ejemplo: verificaci√≥n de Integridad en HDFS con Python</li>
                    </ul>

                    <h4 class="content-index-subtitle">3.4 Movimiento de datos entre cl√∫steres, actualizaci√≥n y
                        migraci√≥n</h4>
                    <ul class="content-index-list">
                        <li>3.4.1 Transferencia y replicaci√≥n de datos entre cl√∫steres</li>
                        <li>3.4.2 Migraci√≥n de entornos y compatibilidad</li>
                        <li>3.4.3 Rol de los metadatos en la trazabilidad de datos</li>
                        <li>3.4.4 Herramientas y buenas pr√°cticas para migraciones seguras</li>
                    </ul>

                    <h4 class="content-index-subtitle">3.5 C√≥digo de ejemplo: transferencia de Datos con Apache NiFi
                    </h4>
                </div>
            </div>

            <div class="content-index-box">
                <h3 class="content-index-title">Tema 4. Monitorizaci√≥n, optimizaci√≥n y resoluci√≥n de problemas</h3>

                <div class="content-index-section">
                    <h4 class="content-index-subtitle">4.1 Herramientas de monitorizaci√≥n</h4>
                    <ul class="content-index-list">
                        <li>4.1.1 Interfaz web del JobTracker y NameNode</li>
                        <li>4.1.2 M√©tricas de rendimiento y latencia</li>
                        <li>4.1.3 Alertas y registros de eventos (logs)</li>
                        <li>4.1.4 Integraci√≥n con herramientas externas</li>
                    </ul>

                    <h4 class="content-index-subtitle">4.2 An√°lisis de los hist√≥ricos de ejecuci√≥n</h4>
                    <ul class="content-index-list">
                        <li>4.2.1 Registros y trazas de ejecuci√≥n</li>
                        <li>4.2.2 Identificaci√≥n de cuellos de botella</li>
                        <li>4.2.3 An√°lisis de patrones de fallo y repetici√≥n</li>
                    </ul>

                    <h4 class="content-index-subtitle">4.3 C√≥digo de ejemplo: an√°lisis de Logs con PySpark</h4>

                    <h4 class="content-index-subtitle">4.4 Monitorizaci√≥n del cl√∫ster con herramientas especializadas
                    </h4>
                    <ul class="content-index-list">
                        <li>4.4.1 Ganglia, Nagios, Prometheus</li>
                        <ul>
                            <li>4.4.1.1 Ganglia: monitorizaci√≥n distribuida y de bajo Coste</li>
                            <li>4.4.1.2 Nagios: monitorizaci√≥n y gesti√≥n de alertas</li>
                            <li>4.4.1.3 Prometheus: monitorizaci√≥n moderna orientada a m√©tricas</li>
                        </ul>
                        <li>4.4.2 Paneles visuales con Grafana</li>
                        <li>4.4.3 Casos de uso en entornos de producci√≥n</li>
                    </ul>

                    <h4 class="content-index-subtitle">4.5 C√≥digo de ejemplo: configuraci√≥n de Prometheus y Grafana</h4>

                    <h4 class="content-index-subtitle">4.6 Query PromQL Ejemplo</h4>
                </div>
            </div>

            <div class="content-index-box">
                <h3 class="content-index-title">Tema 5. Validaci√≥n de t√©cnicas Big Data en la toma de decisiones en
                    Inteligencia de Negocios (BI)</h3>

                <div class="content-index-section">
                    <h4 class="content-index-subtitle">5.1 Modelos de Inteligencia de Negocios (BI)</h4>
                    <ul class="content-index-list">
                        <li>5.1.1 Componentes del ecosistema BI: ETL, Data Warehouse, OLAP</li>
                        <li>5.1.2 Ejemplos de arquitecturas BI en la nube</li>
                    </ul>

                    <h4 class="content-index-subtitle">5.2 Proceso del modelo KDD (Knowledge Discovery in Databases)
                    </h4>
                    <ul class="content-index-list">
                        <li>5.2.1 Origen y definici√≥n del modelo KDD</li>
                        <li>5.2.2 Aplicaci√≥n en contextos Big Data</li>
                        <li>5.2.3 Relaci√≥n entre KDD y miner√≠a de datos</li>
                    </ul>

                    <h4 class="content-index-subtitle">5.3 Etapas del proceso KDD</h4>
                    <ul class="content-index-list">
                        <li>5.3.1 Selecci√≥n y adquisici√≥n de datos</li>
                        <li>5.3.2 Limpieza y preprocesamiento</li>
                        <li>5.3.3 Transformaci√≥n y reducci√≥n de dimensionalidad</li>
                        <li>5.3.4 Miner√≠a de datos: t√©cnicas y algoritmos</li>
                        <li>5.3.5 Interpretaci√≥n, evaluaci√≥n y visualizaci√≥n de resultados</li>
                    </ul>

                    <h4 class="content-index-subtitle">5.4 Implantaci√≥n de modelos de Inteligencia de Negocios (BI)</h4>
                    <ul class="content-index-list">
                        <li>5.4.1 Ciclo de vida de un proyecto BI</li>
                        <li>5.4.2 Herramientas BI (Power BI, Tableau, Qlik, Looker)</li>
                        <li>5.4.3 Integraci√≥n con sistemas Big Data (Hadoop, Spark, Presto)</li>
                        <li>5.4.4 Caso de estudio: dashboard de anal√≠tica avanzada</li>
                    </ul>

                    <h4 class="content-index-subtitle">5.5 T√©cnicas de validaci√≥n de modelos BI</h4>
                    <ul class="content-index-list">
                        <li>5.5.1 Validaci√≥n estad√≠stica y de negocio</li>
                        <li>5.5.2 M√©tricas de evaluaci√≥n (precisi√≥n, recall, F1, ROI)</li>
                        <li>5.5.3 Pruebas de estr√©s y robustez de modelos</li>
                        <li>5.5.4 Conclusiones y recomendaciones estrat√©gicas</li>
                    </ul>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <h3>iLERNA</h3>
        <p class="footer-course">Curso de Especializaci√≥n en Inteligencia Artificial y Big Data</p>
        <a href="https://www.ilerna.es/" target="_blank">www.ilerna.es</a>
        <p class="footer-info">Centro oficial de FP online y presencial. Ciclos formativos de Grado Medio y Grado
            Superior.</p>
        <p class="footer-info">Titulaciones 100% oficiales. ¬°Sin pruebas libres!</p>

        <div class="penguin">
            <span>üêß</span>
        </div>
    </footer>

    <script src="../js/lecciones.js"></script>
</body>

</html>