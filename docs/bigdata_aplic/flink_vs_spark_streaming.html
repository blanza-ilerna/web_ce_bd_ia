<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Apache Flink vs Spark Streaming | iLERNA</title>
    <link rel="stylesheet" href="../css/lecciones.css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
</head>
<body>
    <div class="container">
        <header>
            <div class="header-container">
                <div class="logo-container">
                    <a href="../index.html">
                        <img src="../img/logo-ilerna.svg" alt="Logo iLERNA">
                    </a>
                    <div class="logo-text">
                        iLERNA
                        <span>Curso de Especializaci√≥n en IA y Big Data</span>
                    </div>
                </div>
                <div class="breadcrumb">
                    <a href="../index.html">Inicio</a> ‚Ä∫
                    <a href="index.html">Big Data Aplicado</a> ‚Ä∫
                    <span>Apache Flink vs Spark Streaming</span>
                </div>
            </div>
            <h1 class="text-center">Apache Flink vs Spark Streaming</h1>
            <p class="subtitle text-center">True Streaming vs Micro-Batching en Big Data</p>
        </header>

        <main>
            <!-- SECCI√ìN 1: INTRODUCCI√ìN -->
            <section class="section">
                <h2>Procesamiento de Streams: Dos Filosof√≠as</h2>
                <p>
                    En el ecosistema de Big Data, <strong>Apache Flink</strong> y <strong>Spark Streaming</strong> representan dos enfoques fundamentales para procesar datos en tiempo real. <strong>Flink</strong> implementa procesamiento verdadero evento por evento (true streaming), mientras que <strong>Spark Streaming</strong> utiliza micro-batching, agrupando eventos en peque√±os lotes.
                </p>
                <p>
                    La elecci√≥n entre ambos depende de tus requisitos de <strong>latencia</strong>, <strong>complejidad del estado</strong>, y <strong>ecosistema existente</strong>. Flink destaca cuando necesitas latencias de <strong>milisegundos</strong> y procesamiento complejo con estado, mientras que Spark Streaming brilla cuando latencias de <strong>segundos</strong> son aceptables y ya trabajas con el ecosistema Spark.
                </p>

                <div class="highlight-box">
                    <p><strong>Ejemplo Real:</strong></p>
                    <p>Alibaba procesa m√°s de 4.5 mil millones de transacciones diarias durante eventos como Singles' Day usando Apache Flink, logrando detecci√≥n de fraude en menos de 100 milisegundos.</p>
                </div>

                <h3>Diferencia Fundamental</h3>
                <div class="feature-cards">
                    <div class="feature-card">
                        <h4>‚ö° Flink: True Streaming</h4>
                        <p>Procesa cada evento individualmente conforme llega. Latencia: <strong>milisegundos</strong>.</p>
                    </div>
                    <div class="feature-card">
                        <h4>üì¶ Spark: Micro-Batching</h4>
                        <p>Agrupa eventos en lotes peque√±os y los procesa juntos. Latencia: <strong>segundos</strong>.</p>
                    </div>
                </div>
            </section>

            <!-- SECCI√ìN 2: APACHE FLINK -->
            <section class="section">
                <h2>Apache Flink: Procesamiento Evento por Evento</h2>

                <h3>‚ö° Arquitectura True Streaming</h3>
                <div class="svg-container">
                    <svg width="900" height="400" viewBox="0 0 900 400" style="max-width: 100%; height: auto;">
                        <!-- T√≠tulo -->
                        <text x="450" y="30" font-size="20" font-weight="bold" fill="#49B9CE" text-anchor="middle" font-family="Arial">Apache Flink - Procesamiento Continuo Evento por Evento</text>

                        <!-- Fuente de eventos -->
                        <rect x="50" y="80" width="150" height="50" fill="#E8F7FA" stroke="#49B9CE" stroke-width="3" rx="8"/>
                        <text x="125" y="110" font-size="16" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Arial">Kafka Source</text>

                        <!-- Eventos individuales llegando -->
                        <g>
                            <circle cx="230" cy="90" r="8" fill="#49B9CE"/>
                            <text x="250" y="95" font-size="11" fill="#333333" font-family="Arial">E1</text>

                            <circle cx="230" cy="105" r="8" fill="#49B9CE"/>
                            <text x="250" y="110" font-size="11" fill="#333333" font-family="Arial">E2</text>

                            <circle cx="230" cy="120" r="8" fill="#49B9CE"/>
                            <text x="250" y="125" font-size="11" fill="#333333" font-family="Arial">E3</text>

                            <!-- Flecha indicando flujo continuo -->
                            <path d="M 200 105 L 220 105" stroke="#49B9CE" stroke-width="2" marker-end="url(#arrowblue)" fill="none"/>
                        </g>

                        <!-- Procesamiento continuo -->
                        <rect x="300" y="70" width="280" height="80" fill="white" stroke="#49B9CE" stroke-width="3" rx="8"/>
                        <rect x="310" y="80" width="260" height="30" fill="#49B9CE" rx="5"/>
                        <text x="440" y="100" font-size="16" font-weight="bold" fill="white" text-anchor="middle" font-family="Arial">FLINK OPERATORS</text>

                        <text x="320" y="125" font-size="12" fill="#333333" font-family="Arial">‚Ä¢ Procesa CADA evento inmediatamente</text>
                        <text x="320" y="142" font-size="12" fill="#333333" font-family="Arial">‚Ä¢ Sin esperas ni agrupaci√≥n</text>

                        <!-- L√≠nea temporal -->
                        <line x1="300" y1="180" x2="580" y2="180" stroke="#49B9CE" stroke-width="2"/>
                        <text x="440" y="200" font-size="13" font-weight="bold" fill="#49B9CE" text-anchor="middle" font-family="Arial">Tiempo Continuo ‚Üí</text>

                        <!-- Eventos proces√°ndose en el tiempo -->
                        <circle cx="320" cy="180" r="6" fill="#49B9CE"/>
                        <text x="320" y="165" font-size="10" fill="#333333" text-anchor="middle" font-family="Arial">t=0ms</text>

                        <circle cx="380" cy="180" r="6" fill="#49B9CE"/>
                        <text x="380" y="165" font-size="10" fill="#333333" text-anchor="middle" font-family="Arial">t=2ms</text>

                        <circle cx="440" cy="180" r="6" fill="#49B9CE"/>
                        <text x="440" y="165" font-size="10" fill="#333333" text-anchor="middle" font-family="Arial">t=5ms</text>

                        <circle cx="500" cy="180" r="6" fill="#49B9CE"/>
                        <text x="500" y="165" font-size="10" fill="#333333" text-anchor="middle" font-family="Arial">t=7ms</text>

                        <circle cx="560" cy="180" r="6" fill="#49B9CE"/>
                        <text x="560" y="165" font-size="10" fill="#333333" text-anchor="middle" font-family="Arial">t=10ms</text>

                        <!-- Estado distribuido -->
                        <rect x="650" y="70" width="200" height="80" fill="#F0EDF5" stroke="#8A7AAF" stroke-width="2" rx="8"/>
                        <text x="750" y="95" font-size="14" font-weight="bold" fill="#8A7AAF" text-anchor="middle" font-family="Arial">ESTADO</text>
                        <text x="750" y="115" font-size="11" fill="#333333" text-anchor="middle" font-family="Arial">Mantenido en</text>
                        <text x="750" y="130" font-size="11" fill="#333333" text-anchor="middle" font-family="Arial">memoria distribuida</text>
                        <text x="750" y="145" font-size="11" fill="#333333" text-anchor="middle" font-family="Arial">con checkpoints</text>

                        <path d="M 580 105 L 650 105" stroke="#8A7AAF" stroke-width="2" stroke-dasharray="5,5" fill="none"/>

                        <!-- Salida -->
                        <rect x="320" y="240" width="240" height="50" fill="#E8F7FA" stroke="#49B9CE" stroke-width="3" rx="8"/>
                        <text x="440" y="270" font-size="16" font-weight="bold" fill="#49B9CE" text-anchor="middle" font-family="Arial">Resultado en Tiempo Real</text>

                        <path d="M 440 150 L 440 240" stroke="#49B9CE" stroke-width="3" marker-end="url(#arrowblue)" fill="none"/>

                        <!-- Ventaja de latencia -->
                        <rect x="50" y="320" width="800" height="60" fill="#FFF8DC" stroke="#FFA726" stroke-width="2" rx="8"/>
                        <text x="450" y="345" font-size="15" font-weight="bold" fill="#E65100" text-anchor="middle" font-family="Arial">‚ö° Latencia Ultra-Baja: Milisegundos (&lt; 100ms t√≠pico)</text>
                        <text x="450" y="365" font-size="13" fill="#555555" text-anchor="middle" font-family="Arial">Ideal para detecci√≥n de fraude, alertas cr√≠ticas, IoT en tiempo real</text>

                        <!-- Marcador de flecha -->
                        <defs>
                            <marker id="arrowblue" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto" markerUnits="strokeWidth">
                                <path d="M0,0 L0,6 L9,3 z" fill="#49B9CE"/>
                            </marker>
                        </defs>
                    </svg>
                </div>

                <p>
                    Apache Flink es un framework de procesamiento de streams distribuido que se distingue por su capacidad de <strong>procesamiento verdadero evento por evento</strong>, procesando cada registro individualmente conforme llega, sin esperar a acumular lotes. Esta caracter√≠stica lo hace especialmente adecuado para aplicaciones que requieren <strong>latencias de milisegundos</strong> y procesamiento complejo con estado.
                </p>

                <h3>üéØ Caracter√≠sticas Clave de Flink</h3>

                <!-- 1. True Streaming -->
                <div class="highlight-box">
                    <h4>1. True Streaming (Procesamiento Continuo)</h4>
                    <p>
                        Flink procesa <strong>cada evento individualmente conforme llega</strong>, sin esperar a acumular un lote. Esto contrasta con Spark Streaming, que agrupa eventos en ventanas de segundos antes de procesarlos.
                    </p>

                    <div class="feature-card">
                        <p><strong>üîç ¬øPor qu√© importa?</strong></p>
                        <p>
                            Para aplicaciones como <strong>detecci√≥n de fraude</strong> en transacciones bancarias o <strong>alertas en sistemas cr√≠ticos</strong>, donde cada milisegundo cuenta, el procesamiento evento por evento de Flink es fundamental. Una transacci√≥n sospechosa puede bloquearse en menos de 100ms.
                        </p>
                    </div>

                    <p><strong>Ejemplo - Detecci√≥n de Fraude con Flink:</strong></p>
                    <pre><code class="language-java">// DataStream API de Flink - Procesamiento continuo
DataStream&lt;Transaction&gt; transactions = env
    .addSource(new FlinkKafkaConsumer&lt;&gt;("transactions", ...));

// Procesa CADA transacci√≥n inmediatamente
DataStream&lt;Alert&gt; fraudAlerts = transactions
    .keyBy(Transaction::getUserId)
    // Mantiene estado de √∫ltimas 100 transacciones por usuario
    .process(new FraudDetectionFunction())
    .filter(alert -> alert.getRiskScore() > 0.8);

// Resultado en milisegundos desde el evento original
fraudAlerts.addSink(new AlertingSink());

// Funci√≥n con estado
class FraudDetectionFunction extends KeyedProcessFunction&lt;...&gt; {
    private ValueState&lt;List&lt;Transaction&gt;&gt; userHistory;

    @Override
    public void processElement(Transaction tx, Context ctx, ...) {
        List&lt;Transaction&gt; history = userHistory.value();

        // Analiza INMEDIATAMENTE cada transacci√≥n
        if (isSuspicious(tx, history)) {
            out.collect(new Alert(tx, calculateRisk(tx, history)));
        }

        // Actualiza estado
        history.add(tx);
        userHistory.update(history);
    }
}</code></pre>
                    <p>‚ö° <strong>Latencia t√≠pica:</strong> 10-100 milisegundos end-to-end</p>
                </div>

                <!-- 2. Stateful Processing -->
                <div class="highlight-box">
                    <h4>2. Stateful Processing (Procesamiento con Estado)</h4>
                    <p>
                        Flink permite mantener <strong>estado entre eventos</strong> de forma distribuida y tolerante a fallos. El estado puede ser simple (un contador) o complejo (ventanas temporales con agregaciones, joins entre m√∫ltiples streams).
                    </p>

                    <div class="feature-card">
                        <p><strong>üíæ Gesti√≥n de Estado:</strong></p>
                        <ul>
                            <li><strong>ValueState:</strong> Un √∫nico valor por clave (ej: contador de clicks)</li>
                            <li><strong>ListState:</strong> Lista de elementos (ej: √∫ltimas 100 transacciones)</li>
                            <li><strong>MapState:</strong> Mapa clave-valor (ej: sesiones de usuarios)</li>
                            <li><strong>Checkpointing:</strong> Snapshots peri√≥dicos en almacenamiento distribuido</li>
                            <li><strong>Recuperaci√≥n autom√°tica:</strong> Restaura estado ante fallos sin p√©rdida</li>
                        </ul>
                    </div>

                    <p><strong>Ejemplo - Agregaciones con Estado:</strong></p>
                    <pre><code class="language-scala">// Mantener contadores por usuario en estado distribuido
val userClicks: DataStream[Click] = ...

val clicksPerUser = userClicks
  .keyBy(_.userId)
  .map(new RichMapFunction[Click, (String, Long)] {
    // Estado: contador de clicks por usuario
    private var clickCount: ValueState[Long] = _

    override def open(parameters: Configuration): Unit = {
      val descriptor = new ValueStateDescriptor[Long](
        "click-count", classOf[Long], 0L
      )
      clickCount = getRuntimeContext.getState(descriptor)
    }

    override def map(click: Click): (String, Long) = {
      // Incrementar contador en estado
      val current = clickCount.value()
      val newCount = current + 1
      clickCount.update(newCount)

      (click.userId, newCount)
    }
  })

// Si un nodo falla, Flink restaura autom√°ticamente
// el estado desde el √∫ltimo checkpoint</code></pre>
                </div>

                <!-- 3. Event Time Processing -->
                <div class="highlight-box">
                    <h4>3. Event Time Processing (Procesamiento por Tiempo de Evento)</h4>
                    <p>
                        Flink distingue entre el <strong>momento en que ocurri√≥ un evento</strong> (event time) y el <strong>momento en que lo procesamos</strong> (processing time). En sistemas distribuidos, los eventos pueden llegar desordenados debido a latencias de red o retrasos en la generaci√≥n.
                    </p>

                    <div class="feature-card">
                        <p><strong>üïê Ventaja del Event Time:</strong></p>
                        <p>
                            Flink ordena eventos seg√∫n su <strong>timestamp original</strong> (event time) en lugar de su hora de llegada, garantizando <strong>resultados correctos incluso con datos desordenados</strong>. Por ejemplo, si procesamos logs de un sistema m√≥vil que estuvo offline, Flink puede incorporar esos eventos tard√≠os en las ventanas temporales correctas.
                        </p>
                    </div>

                    <div class="feature-cards">
                        <div class="feature-card">
                            <p><strong>Event Time</strong></p>
                            <p>Cuando ocurri√≥ el evento realmente</p>
                        </div>

                        <div class="feature-card">
                            <p><strong>Ingestion Time</strong></p>
                            <p>Cuando lleg√≥ a Flink</p>
                        </div>

                        <div class="feature-card">
                            <p><strong>Processing Time</strong></p>
                            <p>Cuando lo proces√≥ el operador</p>
                        </div>
                    </div>
                </div>

                <!-- 4. Exactly-Once Semantics -->
                <div class="highlight-box">
                    <h4>4. Exactly-Once Semantics (Garant√≠as de Procesamiento)</h4>
                    <p>
                        Flink garantiza que <strong>cada evento se procesa exactamente una vez</strong>, sin p√©rdidas ni duplicados, incluso ante fallos. Flink logra esto mediante un mecanismo de <strong>checkpointing distribuido</strong> que coordina snapshots consistentes del estado de toda la aplicaci√≥n.
                    </p>

                    <div class="feature-card">
                        <p><strong>‚úÖ Importancia Cr√≠tica:</strong></p>
                        <p>
                            Para aplicaciones <strong>financieras</strong> o de <strong>facturaci√≥n</strong> donde la precisi√≥n es cr√≠tica, esta garant√≠a resulta indispensable. No queremos cobrar dos veces ni perder transacciones.
                        </p>
                    </div>
                </div>
            </section>

            <!-- SECCI√ìN 3: SPARK STREAMING -->
            <section class="section">
                <h2>Spark Streaming: Micro-Batching Pragm√°tico</h2>

                <h3>üì¶ Arquitectura Micro-Batching</h3>
                <div class="svg-container">
                    <svg width="900" height="450" viewBox="0 0 900 450" style="max-width: 100%; height: auto;">
                        <!-- T√≠tulo -->
                        <text x="450" y="30" font-size="20" font-weight="bold" fill="#8A7AAF" text-anchor="middle" font-family="Arial">Spark Streaming - Procesamiento por Micro-Lotes</text>

                        <!-- Fuente de eventos -->
                        <rect x="50" y="80" width="150" height="50" fill="#F0EDF5" stroke="#8A7AAF" stroke-width="3" rx="8"/>
                        <text x="125" y="110" font-size="16" font-weight="bold" fill="#333333" text-anchor="middle" font-family="Arial">Kafka Source</text>

                        <!-- Eventos llegando continuamente -->
                        <g>
                            <circle cx="230" cy="85" r="6" fill="#8A7AAF"/>
                            <circle cx="245" cy="85" r="6" fill="#8A7AAF"/>
                            <circle cx="260" cy="85" r="6" fill="#8A7AAF"/>
                            <circle cx="230" cy="100" r="6" fill="#8A7AAF"/>
                            <circle cx="245" cy="100" r="6" fill="#8A7AAF"/>
                            <circle cx="260" cy="100" r="6" fill="#8A7AAF"/>
                            <circle cx="230" cy="115" r="6" fill="#8A7AAF"/>
                            <circle cx="245" cy="115" r="6" fill="#8A7AAF"/>
                            <circle cx="260" cy="115" r="6" fill="#8A7AAF"/>
                        </g>

                        <!-- L√≠nea temporal con ventanas -->
                        <line x1="300" y1="100" x2="850" y2="100" stroke="#333333" stroke-width="3"/>

                        <!-- Ventanas de micro-batches -->
                        <g>
                            <!-- Batch 1 -->
                            <rect x="300" y="60" width="130" height="80" fill="#E8D8F0" stroke="#8A7AAF" stroke-width="3" rx="5"/>
                            <text x="365" y="95" font-size="14" font-weight="bold" fill="#8A7AAF" text-anchor="middle" font-family="Arial">Batch 1</text>
                            <text x="365" y="115" font-size="11" fill="#333333" text-anchor="middle" font-family="Arial">t=0-2s</text>
                            <text x="365" y="130" font-size="10" fill="#555555" text-anchor="middle" font-family="Arial">(100 eventos)</text>

                            <!-- Batch 2 -->
                            <rect x="450" y="60" width="130" height="80" fill="#E8D8F0" stroke="#8A7AAF" stroke-width="3" rx="5"/>
                            <text x="515" y="95" font-size="14" font-weight="bold" fill="#8A7AAF" text-anchor="middle" font-family="Arial">Batch 2</text>
                            <text x="515" y="115" font-size="11" fill="#333333" text-anchor="middle" font-family="Arial">t=2-4s</text>
                            <text x="515" y="130" font-size="10" fill="#555555" text-anchor="middle" font-family="Arial">(98 eventos)</text>

                            <!-- Batch 3 -->
                            <rect x="600" y="60" width="130" height="80" fill="#E8D8F0" stroke="#8A7AAF" stroke-width="3" rx="5"/>
                            <text x="665" y="95" font-size="14" font-weight="bold" fill="#8A7AAF" text-anchor="middle" font-family="Arial">Batch 3</text>
                            <text x="665" y="115" font-size="11" fill="#333333" text-anchor="middle" font-family="Arial">t=4-6s</text>
                            <text x="665" y="130" font-size="10" fill="#555555" text-anchor="middle" font-family="Arial">(105 eventos)</text>

                            <!-- Batch siguiente -->
                            <rect x="750" y="60" width="80" height="80" fill="#F0EDF5" stroke="#8A7AAF" stroke-width="2" stroke-dasharray="5,5" rx="5"/>
                            <text x="790" y="105" font-size="13" fill="#8A7AAF" text-anchor="middle" font-family="Arial">...</text>
                        </g>

                        <!-- Indicadores de ventana -->
                        <text x="365" y="50" font-size="11" font-weight="bold" fill="#8A7AAF" text-anchor="middle" font-family="Arial">2 segundos</text>
                        <path d="M 300 55 L 430 55" stroke="#8A7AAF" stroke-width="2" marker-end="url(#arrowpurple)" marker-start="url(#arrowpurple2)" fill="none"/>

                        <!-- Motor Spark -->
                        <rect x="300" y="180" width="430" height="100" fill="white" stroke="#8A7AAF" stroke-width="3" rx="8"/>
                        <rect x="310" y="190" width="410" height="35" fill="#8A7AAF" rx="5"/>
                        <text x="515" y="213" font-size="16" font-weight="bold" fill="white" text-anchor="middle" font-family="Arial">SPARK ENGINE (Batch + RDD)</text>

                        <text x="320" y="245" font-size="12" fill="#333333" font-family="Arial">‚Ä¢ Procesa cada micro-batch como un RDD</text>
                        <text x="320" y="263" font-size="12" fill="#333333" font-family="Arial">‚Ä¢ Usa motor batch tradicional de Spark</text>

                        <!-- Flecha hacia motor -->
                        <path d="M 515 140 L 515 180" stroke="#8A7AAF" stroke-width="3" marker-end="url(#arrowpurple3)" fill="none"/>

                        <!-- Salida -->
                        <rect x="340" y="320" width="350" height="50" fill="#F0EDF5" stroke="#8A7AAF" stroke-width="3" rx="8"/>
                        <text x="515" y="350" font-size="16" font-weight="bold" fill="#8A7AAF" text-anchor="middle" font-family="Arial">Resultado cada 2 segundos (por batch)</text>

                        <path d="M 515 280 L 515 320" stroke="#8A7AAF" stroke-width="3" marker-end="url(#arrowpurple3)" fill="none"/>

                        <!-- Ventaja -->
                        <rect x="50" y="390" width="800" height="50" fill="#E8F7FA" stroke="#49B9CE" stroke-width="2" rx="8"/>
                        <text x="450" y="412" font-size="15" font-weight="bold" fill="#49B9CE" text-anchor="middle" font-family="Arial">‚úÖ Ventaja: Mismo c√≥digo que batch + Integraci√≥n con ecosistema Spark</text>
                        <text x="450" y="430" font-size="13" fill="#555555" text-anchor="middle" font-family="Arial">Latencia: Segundos (1-10s t√≠pico) - Suficiente para muchos casos de uso</text>

                        <!-- Marcadores de flecha -->
                        <defs>
                            <marker id="arrowpurple" markerWidth="8" markerHeight="8" refX="7" refY="2.5" orient="auto" markerUnits="strokeWidth">
                                <path d="M0,0 L0,5 L7,2.5 z" fill="#8A7AAF"/>
                            </marker>
                            <marker id="arrowpurple2" markerWidth="8" markerHeight="8" refX="0" refY="2.5" orient="auto" markerUnits="strokeWidth">
                                <path d="M7,0 L7,5 L0,2.5 z" fill="#8A7AAF"/>
                            </marker>
                            <marker id="arrowpurple3" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto" markerUnits="strokeWidth">
                                <path d="M0,0 L0,6 L9,3 z" fill="#8A7AAF"/>
                            </marker>
                        </defs>
                    </svg>
                </div>

                <p>
                    Spark Streaming es la extensi√≥n de Apache Spark para procesamiento de datos en tiempo real. A diferencia del true streaming de Flink, Spark Streaming utiliza un enfoque de <strong>micro-batching</strong>: agrupa eventos que llegan durante peque√±as ventanas de tiempo (t√≠picamente 1-10 segundos) y los procesa como lotes usando el motor batch de Spark.
                </p>

                <h3>‚úÖ Ventajas del Micro-Batching</h3>

                <div class="highlight-box">
                    <h4>1. Reutilizaci√≥n de C√≥digo y APIs</h4>
                    <p>
                        Permite reutilizar el <strong>mismo c√≥digo y APIs</strong> que usamos para procesamiento batch, facilitando la transici√≥n entre ambos modos. Los desarrolladores familiarizados con Spark pueden aplicar inmediatamente sus conocimientos al procesamiento streaming sin aprender un framework completamente nuevo.
                    </p>

                    <p><strong>Ejemplo - DStreams (API Cl√°sica):</strong></p>
                    <pre><code class="language-python">from pyspark.streaming import StreamingContext

# Crear contexto con ventanas de 2 segundos
ssc = StreamingContext(sparkContext, 2)

# Leer stream (agrupa eventos cada 2 segundos)
lines = ssc.socketTextStream("localhost", 9999)

# Procesar como si fuera batch
wordCounts = lines \
    .flatMap(lambda line: line.split(" ")) \
    .map(lambda word: (word, 1)) \
    .reduceByKey(lambda a, b: a + b)

# Cada 2 segundos, procesa el micro-batch
wordCounts.pprint()

ssc.start()
ssc.awaitTermination()</code></pre>
                </div>

                <div class="highlight-box">
                    <h4>2. Integraci√≥n Total con Ecosistema Spark</h4>
                    <p>
                        La integraci√≥n con el ecosistema Spark es total: podemos combinar streaming con <strong>Spark SQL</strong> para consultas estructuradas, usar <strong>MLlib</strong> para aplicar modelos de machine learning en tiempo real, o integrarnos con <strong>GraphX</strong> para an√°lisis de grafos.
                    </p>

                    <div class="feature-card">
                        <p><strong>üîó Ecosistema Unificado:</strong></p>
                        <ul>
                            <li><strong>Spark SQL:</strong> Consultas SQL sobre streams</li>
                            <li><strong>MLlib:</strong> Aplicar modelos predictivos en tiempo real</li>
                            <li><strong>GraphX:</strong> An√°lisis de grafos din√°micos</li>
                            <li><strong>DataFrames/Datasets:</strong> APIs de alto nivel</li>
                        </ul>
                    </div>

                    <p><strong>Ejemplo - Structured Streaming (API Moderna):</strong></p>
                    <pre><code class="language-python">from pyspark.sql import SparkSession
from pyspark.sql.functions import *

spark = SparkSession.builder.appName("StructuredStream").getOrCreate()

# Leer stream como DataFrame (¬°tabla infinita!)
streamDF = spark.readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "localhost:9092") \
    .option("subscribe", "events") \
    .load()

# Procesar con SQL y ML
processedDF = streamDF \
    .selectExpr("CAST(value AS STRING)") \
    .select(from_json(col("value"), schema).alias("data")) \
    .select("data.*") \
    .withColumn("prediction", ml_model_udf(col("features")))

# Escribir resultados (¬°mismo c√≥digo que batch!)
query = processedDF.writeStream \
    .format("console") \
    .outputMode("append") \
    .trigger(processingTime="2 seconds") \
    .start()

query.awaitTermination()</code></pre>
                    <p>üí° <strong>Structured Streaming:</strong> Trata streams como tablas infinitas, permite usar el mismo c√≥digo SQL para batch y streaming.</p>
                </div>

                <div class="highlight-box">
                    <h4>3. Latencia Aceptable para Muchos Casos</h4>
                    <p>
                        El enfoque de micro-batching implica latencias m√≠nimas del orden de <strong>segundos</strong> en lugar de milisegundos. Para muchas aplicaciones (an√°lisis de m√©tricas, agregaci√≥n de logs, procesamiento de datos de sensores no cr√≠ticos) esta latencia resulta perfectamente aceptable.
                    </p>

                    <div class="feature-card">
                        <p><strong>üìä Casos de uso ideales:</strong></p>
                        <ul>
                            <li>An√°lisis de m√©tricas y dashboards (latencia 1-5s aceptable)</li>
                            <li>Agregaci√≥n de logs de aplicaciones</li>
                            <li>ETL en tiempo "casi real" (near real-time)</li>
                            <li>Procesamiento de datos IoT no cr√≠ticos</li>
                            <li>Recomendaciones y personalizaci√≥n (segundos OK)</li>
                        </ul>
                    </div>
                </div>

                <div class="highlight-box" style="background: #FFF8DC; border-color: #FFA726;">
                    <h4>üõ°Ô∏è Tolerancia a Fallos en Spark Streaming</h4>
                    <p>
                        La tolerancia a fallos se implementa mediante el <strong>linaje de RDDs</strong> de Spark: si un nodo falla, Spark puede reconstruir los datos perdidos reprocesando desde la fuente original. Esto garantiza recuperaci√≥n ante fallos sin necesidad de replicaci√≥n costosa, aunque puede implicar reprocesamiento de algunos micro-batches en caso de error.
                    </p>
                </div>
            </section>

            <!-- SECCI√ìN 4: COMPARACI√ìN EXHAUSTIVA -->
            <section class="section">
                <h2 class="text-center">Flink vs Spark Streaming: Comparaci√≥n Completa</h2>

                <div class="comparison-table">
                    <table>
                        <thead>
                            <tr>
                                <th>Caracter√≠stica</th>
                                <th>‚ö° Apache Flink</th>
                                <th>üì¶ Spark Streaming</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>Modelo de procesamiento</strong></td>
                                <td><strong>True Streaming</strong> (evento por evento)</td>
                                <td><strong>Micro-Batching</strong> (lotes peque√±os)</td>
                            </tr>
                            <tr>
                                <td><strong>Latencia t√≠pica</strong></td>
                                <td><strong>10-100 milisegundos</strong></td>
                                <td>1-10 segundos</td>
                            </tr>
                            <tr>
                                <td><strong>Estado (State)</strong></td>
                                <td><strong>Excelente</strong> - Dise√±ado para stateful</td>
                                <td>Bueno - Con limitaciones</td>
                            </tr>
                            <tr>
                                <td><strong>Event Time</strong></td>
                                <td><strong>Nativo y robusto</strong> (watermarks)</td>
                                <td>Soportado en Structured Streaming</td>
                            </tr>
                            <tr>
                                <td><strong>Exactly-Once</strong></td>
                                <td><strong>S√≠</strong> (checkpointing distribuido)</td>
                                <td><strong>S√≠</strong> (con idempotent sinks)</td>
                            </tr>
                            <tr>
                                <td><strong>Complejidad</strong></td>
                                <td>Media-Alta (curva aprendizaje)</td>
                                <td><strong>Baja</strong> (si conoces Spark)</td>
                            </tr>
                            <tr>
                                <td><strong>Ecosistema</strong></td>
                                <td>Flink Table API, SQL, CEP</td>
                                <td><strong>Spark SQL, MLlib, GraphX</strong></td>
                            </tr>
                            <tr>
                                <td><strong>Lenguajes</strong></td>
                                <td>Java, Scala, Python (PyFlink)</td>
                                <td>Python, Scala, Java, R</td>
                            </tr>
                            <tr>
                                <td><strong>Casos de uso</strong></td>
                                <td>Fraude, alertas cr√≠ticas, IoT real-time</td>
                                <td>Anal√≠tica, ETL, dashboards, ML</td>
                            </tr>
                            <tr>
                                <td><strong>Adopci√≥n</strong></td>
                                <td>Alibaba, Uber, Netflix, LinkedIn</td>
                                <td><strong>Mayor√≠a de empresas Spark</strong></td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <h3 class="text-center">üéØ Gu√≠a de Decisi√≥n</h3>

                <div class="feature-cards">
                    <div class="feature-card">
                        <h4 class="text-center">Elige Flink si...</h4>
                        <ul>
                            <li>Necesitas <strong>latencia ultra-baja</strong> (< 100ms)</li>
                            <li>Procesamiento <strong>complejo con estado</strong> distribuido</li>
                            <li><strong>Event time</strong> y datos desordenados son cr√≠ticos</li>
                            <li>Aplicaciones <strong>cr√≠ticas</strong> (fraude, alertas m√©dicas)</li>
                            <li>Puedes invertir en <strong>aprender una nueva tecnolog√≠a</strong></li>
                        </ul>
                    </div>

                    <div class="feature-card">
                        <h4 class="text-center">Elige Spark Streaming si...</h4>
                        <ul>
                            <li>Latencia de <strong>segundos es aceptable</strong></li>
                            <li>Ya usas <strong>Spark</strong> para batch y quieres unificar</li>
                            <li>Necesitas <strong>ML en streaming</strong> con MLlib</li>
                            <li>Tu equipo ya conoce <strong>Spark</strong></li>
                            <li>Priorizas <strong>simplicidad</strong> sobre latencia extrema</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- SECCI√ìN 5: CASOS DE USO REALES -->
            <section class="section">
                <h2>üåç Casos de Uso del Mundo Real</h2>

                <div class="feature-cards">
                    <div class="feature-card">
                        <h4>üõí Alibaba (Flink)</h4>
                        <p>Procesa 4.5 mil millones de transacciones/d√≠a con Flink para detecci√≥n de fraude en < 100ms durante Singles' Day.</p>
                    </div>

                    <div class="feature-card">
                        <h4>üöó Uber (Flink)</h4>
                        <p>Usa Flink para calcular precios din√°micos (surge pricing) con latencias de milisegundos bas√°ndose en demanda en tiempo real.</p>
                    </div>

                    <div class="feature-card">
                        <h4>üì∫ Netflix (Spark)</h4>
                        <p>Utiliza Spark Streaming para anal√≠tica de visualizaciones y recomendaciones near-real-time con latencia de segundos.</p>
                    </div>

                    <div class="feature-card">
                        <h4>üöï Lyft (Flink)</h4>
                        <p>Procesamiento de eventos de viajes y matching conductor-pasajero con Flink para minimizar tiempos de espera.</p>
                    </div>

                    <div class="feature-card">
                        <h4>üìå Pinterest (Spark)</h4>
                        <p>Spark Streaming + MLlib para feeds personalizados y detecci√≥n de spam con latencia de pocos segundos.</p>
                    </div>

                    <div class="feature-card">
                        <h4>üíº LinkedIn (Flink)</h4>
                        <p>Migr√≥ de Samza a Flink para mejorar latencia en notificaciones y feeds personalizados con state management.</p>
                    </div>
                </div>
            </section>

            <!-- SECCI√ìN 6: DATO CURIOSO -->
            <section class="section">
                <div class="highlight-box" style="background: #FFF8DC; border-color: #FFA726;">
                    <h3>üí° Dato Curioso: El Origen de Flink</h3>

                    <p>
                        Apache Flink comenz√≥ en 2010 como un <strong>proyecto de investigaci√≥n acad√©mica</strong> en la Universidad T√©cnica de Berl√≠n bajo el nombre <strong>"Stratosphere"</strong>. Los investigadores quer√≠an crear un sistema que superara las limitaciones del modelo MapReduce de Hadoop.
                    </p>

                    <h4>üéØ ¬øPor qu√© "Flink"?</h4>
                    <p>
                        El nombre <strong>"Flink"</strong> es una palabra alemana que significa <strong>"√°gil"</strong> o <strong>"r√°pido"</strong>. Tambi√©n es un juego de palabras con el logo del proyecto: una <strong>ardilla voladora</strong> (flying squirrel), que en alem√°n se llama "Flugh√∂rnchen". La ardilla simboliza la velocidad y agilidad del framework para procesar streams.
                    </p>

                    <div class="feature-card">
                        <p class="text-center">
                            üöÄ En 2014, el proyecto se don√≥ a la <strong>Apache Software Foundation</strong> y se convirti√≥ en un Top-Level Project. Hoy es usado por gigantes como Alibaba, Uber y Netflix procesando <strong>trillones de eventos diarios</strong>.
                        </p>
                    </div>
                </div>
            </section>

            <!-- MERMAID MINDMAP -->
            <section class="section">
                <h2 class="text-center">Mapa Mental: Flink vs Spark Streaming</h2>
                <div class="mermaid">
mindmap
  root((Streaming))
    Apache Flink
      True Streaming
        Evento por evento
        Latencia milisegundos
        Procesamiento continuo
      Estado Avanzado
        ValueState
        ListState
        MapState
        Checkpointing
      Event Time
        Watermarks
        Datos desordenados
        Timestamps originales
      Casos de Uso
        Detecci√≥n fraude
        Alertas cr√≠ticas
        IoT tiempo real
        Alibaba Singles Day
    Spark Streaming
      Micro-Batching
        Lotes peque√±os
        Latencia segundos
        Motor batch Spark
      Ecosistema
        Spark SQL
        MLlib
        GraphX
        DataFrames
      Ventajas
        Mismo c√≥digo batch
        Curva aprendizaje baja
        Integraci√≥n total
      Casos de Uso
        Anal√≠tica m√©tricas
        ETL near real-time
        Dashboards
        Netflix recomendaciones
                </div>
            </section>
        </main>

        <footer>
            <p>&copy; 2025 iLERNA - Curso de Especializaci√≥n en Inteligencia Artificial y Big Data</p>
            <p>Centro oficial de FP online y presencial | <a href="https://www.ilerna.es/" target="_blank">www.ilerna.es</a></p>
        </footer>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-java.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-scala.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
</body>
</html>