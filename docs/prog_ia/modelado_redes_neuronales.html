<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="Modelado de redes neuronales, estructura, funcionamiento y ejemplos con TensorFlow">
    <meta name="keywords"
        content="Redes Neuronales, Deep Learning, TensorFlow, Keras, Perceptr√≥n, CNN, RNN, Transformers, IA">
    <meta name="author" content="Bjlanza">
    <meta name="organization" content="ILERNA">
    <title>Modelado de Redes Neuronales | iLERNA</title>
    <link rel="stylesheet" href="../css/lecciones.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    <link rel="stylesheet" href="../css/mermaid-ilerna.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10.9.5/dist/mermaid.min.js"></script>
    <script src="../js/mermaid-config.js"></script>
</head>

<body>
    <header>
        <div class="header-container">
            <div class="logo-container">
                <a href="../index.html">
                    <img src="../img/logo-ilerna.svg" alt="Logo iLERNA">
                </a>
                <div class="logo-text">
                    Curso de Especializaci√≥n
                    <span>Inteligencia Artificial y Big Data</span>
                </div>
            </div>
            <nav class="breadcrumb">
                <a href="../index.html">Inicio</a> ‚Üí
                <a href="index.html">Programaci√≥n IA</a> ‚Üí
                <span>Modelado de Redes Neuronales</span>
            </nav>
        </div>
    </header>

    <main class="container">
        <div class="hero">
            <h1>Modelado de Redes Neuronales</h1>
            <p class="subtitle">Estructura, Funcionamiento y Ejemplos con TensorFlow</p>
        </div>

        <!-- √çNDICE DE CONTENIDOS -->
        <section>
            <div class="toc-container">
                <h3>√çndice de Contenidos</h3>
                <ul class="toc-list">
                    <li><a href="#intro">1. ¬øQu√© es una Red Neuronal?</a></li>
                    <li><a href="#estructura">2. Estructura B√°sica</a></li>
                    <li><a href="#como-aprenden">3. ¬øC√≥mo Aprenden?</a></li>
                    <li><a href="#por-que-funcionan">4. ¬øPor qu√© Funcionan?</a></li>
                    <li><a href="#tipos-habituales">5. Tipos Habituales de Redes</a></li>
                    <li><a href="#tensorflow-ejemplo">6. Ejemplo con TensorFlow</a></li>
                    <li><a href="#regularizacion">7. Regularizaci√≥n y Generalizaci√≥n</a></li>
                    <li><a href="#metricas">8. M√©tricas y Evaluaci√≥n</a></li>
                    <li><a href="#aplicaciones">9. Aplicaciones Reales</a></li>
                    <li><a href="#ventajas-limites">10. Ventajas y L√≠mites</a></li>
                </ul>
            </div>
        </section>

        <!-- SECCI√ìN 1: INTRODUCCI√ìN -->
        <section id="intro">
            <h2>¬øQu√© es una Red Neuronal?</h2>

            <p>
                Una red neuronal es un <strong>modelo matem√°tico de aprendizaje autom√°tico</strong> inspirado, de forma
                simplificada, en el funcionamiento del cerebro biol√≥gico. Est√° constituida por capas de "neuronas
                artificiales" interconectadas. Cada neurona procesa informaci√≥n num√©rica recibida, la combina mediante
                pesos y sesgos, y aplica una funci√≥n de activaci√≥n para generar una salida.
            </p>

            <div class="concept-card">
                <div class="formula-container" style="flex: 1; min-width: 250px;">
                    <p class="formula-title">C√°lculo de una Neurona B√°sica</p>
                    <p class="formula-text">$$ y = \sigma(w \cdot x + b) $$</p>
                    <p style="font-size: 0.9rem; color: var(--text-medium);">
                        Donde: <strong>x</strong> son las entradas, <strong>w</strong> los pesos, <strong>b</strong> el
                        sesgo y <strong>œÉ</strong> (sigma) la funci√≥n de activaci√≥n.
                    </p>
                </div>
                <div class="content" style="flex: 1; min-width: 250px;">
                    <p>En esencia, es un <strong>sistema diferenciable</strong> de capas conectadas que aprende
                        ajustando sus pesos para transformar datos de entrada en salidas √∫tiles (predicciones), todo
                        ello guiado por una funci√≥n de p√©rdida y un algoritmo optimizador.</p>
                </div>
            </div>
        </section>

        <!-- SECCI√ìN 2: ESTRUCTURA -->
        <section id="estructura">
            <h2>Estructura de una Red Neuronal</h2>
            <p>El flujo de informaci√≥n en una red neuronal t√≠pica se organiza en tres tipos principales de capas:</p>

            <div class="grid-features">
                <div class="feature-card primary">
                    <h4 class="color-primary">Capa de Entrada</h4>
                    <p>Es la puerta de acceso de los datos a la red. Recibe la informaci√≥n cruda, como valores de
                        p√≠xeles de una imagen, palabras codificadas o lecturas de sensores, y la pasa a las siguientes
                        capas.</p>
                </div>

                <div class="feature-card secondary">
                    <h4 class="color-secondary">Capas Ocultas</h4>
                    <p>El n√∫cleo de procesamiento. Estas capas transforman progresivamente la representaci√≥n de los
                        datos mediante neuronas y funciones de activaci√≥n no lineales (como <strong>ReLU</strong>,
                        <strong>tanh</strong>, o <strong>sigmoid</strong>), extrayendo caracter√≠sticas cada vez m√°s
                        complejas.
                    </p>
                </div>

                <div class="feature-card primary">
                    <h4 class="color-primary">Capa de Salida</h4>
                    <p>Entrega el resultado final del modelo. Dependiendo de la tarea, puede ser una clasificaci√≥n
                        (probabilidades de clases), un valor continuo (regresi√≥n) o una decisi√≥n binaria.</p>
                </div>
            </div>
        </section>

        <!-- SECCI√ìN 3: C√ìMO APRENDEN -->
        <section id="como-aprenden">
            <h2>¬øC√≥mo Aprenden?</h2>
            <p>El proceso de aprendizaje es un ciclo iterativo que busca minimizar el error en las predicciones. Se
                compone de cuatro pasos fundamentales:</p>

            <div class="scenario-box neutral">
                <h4>1. Propagaci√≥n hacia delante (Forward Propagation)</h4>
                <p>La red recibe las entradas, realiza los c√°lculos capa por capa y genera una predicci√≥n inicial. Al
                    principio, como los pesos son aleatorios, esta predicci√≥n suele ser incorrecta.</p>
            </div>

            <div class="scenario-box neutral">
                <h4>2. C√°lculo de la Funci√≥n de P√©rdida (Loss Function)</h4>
                <p>Se mide la discrepancia entre la predicci√≥n de la red y el valor real (objetivo). Funciones comunes
                    incluyen la <strong>Entrop√≠a Cruzada</strong> (para clasificaci√≥n) o el <strong>Error Cuadr√°tico
                        Medio (MSE)</strong> (para regresi√≥n).</p>
            </div>

            <div class="scenario-box neutral">
                <h4>3. Retropropagaci√≥n (Backpropagation)</h4>
                <p>El paso clave. Se calcula el gradiente del error respecto a cada peso de la red, determine cu√°nto
                    contribuy√≥ cada neurona al error total.</p>
            </div>

            <div class="scenario-box neutral">
                <h4>4. Optimizaci√≥n</h4>
                <p>Un algoritmo optimizador (como <strong>SGD</strong> o <strong>Adam</strong>) actualiza los pesos en
                    la direcci√≥n opuesta al gradiente para reducir el error en la siguiente iteraci√≥n.</p>
            </div>

            <p class="text-center mt-1">Este ciclo se repite durante m√∫ltiples <strong>√©pocas</strong> (vueltas
                completas al dataset) hasta que el rendimiento del modelo se estabiliza.</p>
        </section>

        <!-- SECCI√ìN 4: POR QU√â FUNCIONAN -->
        <section id="por-que-funcionan">
            <h2>¬øPor qu√© Funcionan?</h2>
            <div class="highlight-box secondary">
                <p class="title">La Magia de la No-Linealidad</p>
                <p class="content">
                    Las redes neuronales funcionan gracias a las <strong>activaciones no lineales</strong>. Sin ellas,
                    una red profunda ser√≠a equivalente a una simple regresi√≥n lineal, incapaz de resolver problemas
                    complejos. La no-linealidad permite a la red aproximar pr√°cticamente cualquier funci√≥n matem√°tica
                    compleja.
                </p>
                <p class="content" style="margin-top: 1rem;">
                    Con suficiente profundidad (n√∫mero de capas) y ancho (neuronas por capa), y alimentada con
                    suficientes datos, la red aprende a identificar <strong>patrones jer√°rquicos</strong>: desde bordes
                    y texturas simples en las primeras capas, hasta formas, objetos y conceptos abstractos en las capas
                    profundas.
                </p>
            </div>
        </section>

        <!-- SECCI√ìN 5: TIPOS HABITUALES -->
        <section id="tipos-habituales">
            <h2>Tipos Habituales de Redes Neuronales</h2>

            <div class="grid-features">
                <div class="feature-card primary">
                    <h4 class="color-primary">Perceptr√≥n Multicapa (MLP)</h4>
                    <p>Redes formadas por capas densas de neuronas. Son vers√°tiles y √∫tiles para trabajar con datos
                        tabulares estructurados o problemas relativamente simples.</p>
                </div>

                <div class="feature-card secondary">
                    <h4 class="color-secondary">Redes Convolucionales (CNN)</h4>
                    <p>Dise√±adas para procesar datos con estructura de rejilla, como im√°genes. Explotan patrones
                        espaciales locales y son el est√°ndar en visi√≥n artificial (clasificaci√≥n, detecci√≥n de objetos,
                        segmentaci√≥n).</p>
                </div>

                <div class="feature-card primary">
                    <h4 class="color-primary">Redes Recurrentes (RNN, LSTM, GRU)</h4>
                    <p>Especializadas en datos secuenciales (texto, audio, series temporales) ya que tienen "memoria" de
                        estados previos. Aunque potentes, han sido desplazadas en gran medida por los Transformers.</p>
                </div>

                <div class="feature-card secondary">
                    <h4 class="color-secondary">Transformers</h4>
                    <p>La arquitectura moderna dominante. Basados en mecanismos de <strong>atenci√≥n</strong> que
                        permiten procesar secuencias completas en paralelo. Son la base de los LLMs (como GPT) y cada
                        vez m√°s usados en visi√≥n (Vision Transformers).</p>
                </div>
            </div>
        </section>

        <!-- SECCI√ìN 6: EJEMPLO TENSORFLOW -->
        <section id="tensorflow-ejemplo">
            <h2>Ejemplo de Implementaci√≥n con TensorFlow</h2>
            <p>A continuaci√≥n, vemos c√≥mo definir una red neuronal simple (MLP) utilizando la API de Keras en TensorFlow
                para un problema de clasificaci√≥n binaria.</p>

            <div class="code-container">
                <pre><code class="language-python">import tensorflow as tf
from tensorflow.keras import layers, models

# 1. Definici√≥n del modelo (Arquitectura Secuencial)
model = models.Sequential([
    # Capa de entrada (ej. 20 caracter√≠sticas) y primera capa oculta con 64 neuronas
    # Activaci√≥n ReLU para introducir no-linealidad
    layers.Dense(64, activation='relu', input_shape=(20,)),
    
    # Segunda capa oculta con 32 neuronas
    layers.Dense(32, activation='relu'),
    
    # Capa de salida: 1 neurona con activaci√≥n Sigmoid
    # (Produce una probabilidad entre 0 y 1 para clasificaci√≥n binaria)
    layers.Dense(1, activation='sigmoid')
])

# 2. Compilaci√≥n del modelo
# Definimos c√≥mo va a aprender la red
model.compile(
    optimizer='adam',                # Optimizador moderno y eficiente
    loss='binary_crossentropy',      # Funci√≥n de p√©rdida para clasificaci√≥n binaria
    metrics=['accuracy']             # M√©trica para evaluar el rendimiento
)

# 3. Resumen de la arquitectura
model.summary()

# (Opcional) Entrenamiento del modelo con datos
# history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)</code></pre>
            </div>
        </section>

        <!-- SECCI√ìN 7: REGULARIZACI√ìN -->
        <section id="regularizacion">
            <h2>Regularizaci√≥n y Generalizaci√≥n</h2>
            <p>
                El objetivo final no es solo que la red aprenda los datos de entrenamiento, sino que
                <strong>generalice</strong> bien a datos nuevos que nunca ha visto. Para evitar el <strong>sobreajuste
                    (overfitting)</strong> ‚Äîdonde la red memoriza el ruido del entrenamiento‚Äî se emplean varias
                t√©cnicas:
            </p>

            <div class="grid-3">
                <div class="feature-card primary">
                    <h4 class="color-primary">T√©cnicas de Modelo</h4>
                    <ul>
                        <li><strong>Dropout:</strong> Apagar aleatoriamente neuronas durante el entrenamiento para
                            evitar co-dependencias.</li>
                        <li><strong>Weight Decay:</strong> Penalizar pesos grandes para mantener el modelo simple.</li>
                        <li><strong>Early Stopping:</strong> Detener el entrenamiento cuando la validaci√≥n deja de
                            mejorar.</li>
                    </ul>
                </div>
                <div class="feature-card secondary">
                    <h4 class="color-secondary">Datos</h4>
                    <p><strong>Aumento de Datos (Data Augmentation):</strong> Generar variaciones sint√©ticas de los
                        datos de entrenamiento (rotar im√°genes, a√±adir ruido al audio, modificar texto) para robustecer
                        el modelo.</p>
                </div>
                <div class="feature-card primary">
                    <h4 class="color-primary">Validaci√≥n</h4>
                    <p>Mantener siempre conjuntos de <strong>Validaci√≥n</strong> y <strong>Prueba</strong> estrictamente
                        separados del entrenamiento para obtener una evaluaci√≥n honesta del rendimiento real.</p>
                </div>
            </div>
        </section>

        <!-- SECCI√ìN 8: M√âTRICAS Y EVALUACI√ìN -->
        <section id="metricas">
            <h2>M√©tricas y Evaluaci√≥n</h2>
            <p>La elecci√≥n de la m√©trica de evaluaci√≥n es cr√≠tica y depende totalmente de la tarea a resolver. No basta
                con mirar un solo n√∫mero.</p>

            <div class="table-container">
                <table>
                    <thead>
                        <tr>
                            <th>Tipo de Problema</th>
                            <th>M√©tricas Comunes</th>
                            <th>Consideraci√≥n Importante</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Clasificaci√≥n</td>
                            <td>Accuracy, Precision, Recall, F1-Score, AUC-ROC</td>
                            <td>Esencial analizar el desglose por clase si los datos est√°n desbalanceados.</td>
                        </tr>
                        <tr>
                            <td>Regresi√≥n</td>
                            <td>MAE (Error Absoluto Medio), MSE (Error Cuadr√°tico Medio)</td>
                            <td>MSE penaliza m√°s los errores grandes (outliers) que MAE.</td>
                        </tr>
                        <tr>
                            <td>Visi√≥n/Detecci√≥n</td>
                            <td>IoU (Intersection over Union), mAP (mean Average Precision)</td>
                            <td>Eval√∫a tanto la localizaci√≥n (caja) como la clasificaci√≥n correcta.</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div class="warning-box">
                <h4>‚ö†Ô∏è Importante</h4>
                <p>Mire siempre m√°s all√° del promedio. Analice los <strong>errores t√≠picos</strong> y el rendimiento en
                    los casos borde para entender realmente c√≥mo se comporta su modelo.</p>
            </div>
        </section>

        <!-- SECCI√ìN 9: APLICACIONES -->
        <section id="aplicaciones">
            <h2>Aplicaciones en el Mundo Real</h2>
            <div class="grid-features">
                <div class="feature-card primary">
                    <h4 class="color-primary">üëÅÔ∏è Visi√≥n Artificial</h4>
                    <p>Reconocimiento facial, diagn√≥stico m√©dico asistido por imagen, veh√≠culos aut√≥nomos y sistemas de
                        conducci√≥n asistida.</p>
                </div>
                <div class="feature-card secondary">
                    <h4 class="color-secondary">üó£Ô∏è Procesamiento de Lenguaje (NLP)</h4>
                    <p>Traducci√≥n autom√°tica, clasificaci√≥n de textos, chatbots inteligentes, resumen autom√°tico de
                        documentos.</p>
                </div>
                <div class="feature-card primary">
                    <h4 class="color-primary">üîä Audio y Se√±al</h4>
                    <p>Reconocimiento de voz (ASR), detecci√≥n de eventos sonoros, mejora de audio.</p>
                </div>
                <div class="feature-card secondary">
                    <h4 class="color-secondary">üè≠ Industria y Otros</h4>
                    <p>Sistemas de recomendaci√≥n personalizados, detecci√≥n de fraude financiero, control de procesos
                        industriales y mantenimiento predictivo.</p>
                </div>
            </div>
        </section>

        <!-- SECCI√ìN 10: VENTAJAS Y L√çMITES -->
        <section id="ventajas-limites">
            <h2>Ventajas y Limitaciones</h2>
            <div class="comparison-grid">
                <div class="advantage-box">
                    <h4>Ventajas</h4>
                    <ul>
                        <li><strong>Gran capacidad de representaci√≥n:</strong> Pueden modelar relaciones extremadamente
                            complejas y no lineales.</li>
                        <li><strong>Rendimiento SOTA:</strong> Ofrecen resultados de vanguardia (State-Of-The-Art) en
                            tareas perceptuales (visi√≥n, audio).</li>
                        <li><strong>Aprendizaje Transferido:</strong> Permiten usar modelos pre-entrenados y ajustarlos
                            (fine-tuning) a nuevas tareas con menos datos.</li>
                    </ul>
                </div>
                <div class="disadvantage-box">
                    <h4>L√≠mites y Desaf√≠os</h4>
                    <ul>
                        <li><strong>Datos y C√≥mputo:</strong> Requieren grandes vol√∫menes de datos y potencia de c√°lculo
                            (GPUs) significativa para el entrenamiento.</li>
                        <li><strong>Caja Negra (Opacidad):</strong> A menudo es dif√≠cil interpretar por qu√© la red tom√≥
                            una decisi√≥n espec√≠fica (falta de interpretabilidad).</li>
                        <li><strong>Sensibilidad a Sesgos:</strong> Si los datos de entrenamiento tienen sesgos, la red
                            los aprender√° y amplificar√°.</li>
                    </ul>
                </div>
            </div>
        </section>
        <!-- SECCI√ìN 11: MAPA MENTAL -->
        <section class="section">
            <h2 class="section-title">Resumen Visual</h2>
            <div class="mermaid">
                mindmap
                root((Redes Neuronales))
                    Definici√≥n
                        Modelo Matem√°tico
                        Inspiraci√≥n Biol√≥gica
                    Estructura
                        Capa Entrada
                        Capas Ocultas
                        Capa Salida
                        Neurona
                            Pesos
                            Sesgo
                            Activaci√≥n
                    Aprendizaje
                        Forward Propagation
                        Loss Function
                        Backpropagation
                        Optimizaci√≥n
                            SGD
                            Adam
                    Tipos
                        MLP Tabular
                        CNN Visi√≥n
                        RNN Secuencias
                        Transformers
                    Aplicaciones
                        Visi√≥n Artificial
                        NLP
                        Audio y Voz
            </div>
        </section>
    </main>

    <footer>
        <h3>iLERNA</h3>
        <p class="footer-course">Curso de Especializaci√≥n en Inteligencia Artificial y Big Data</p>
        <a href="https://www.ilerna.es/" target="_blank">www.ilerna.es</a>
        <p class="footer-info">Centro oficial de FP online y presencial. Ciclos formativos de Grado Medio y Grado
            Superior.</p>
        <p class="footer-info">Titulaciones 100% oficiales. ¬°Sin pruebas libres!</p>

        <div class="penguin">
            <span>üêß</span>
        </div>
    </footer>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="../js/lecciones.js"></script>
</body>

</html>