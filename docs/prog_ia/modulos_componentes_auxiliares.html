<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="Componentes auxiliares predefinidos para el entrenamiento de modelos de IA: p√©rdida, optimizadores y m√°s.">
    <meta name="keywords" content="IA, Entrenamiento, Loss Function, Optimizer, Scheduler, Callbacks, Deep Learning">
    <meta name="author" content="Bjlanza">
    <meta name="organization" content="ILERNA">
    <title>Componentes Auxiliares de Entrenamiento | iLERNA</title>
    <link rel="stylesheet" href="../css/lecciones.css">
</head>

<body>
    <header>
        <div class="header-container">
            <div class="logo-container">
                <a href="../index.html">
                    <img src="../img/logo-ilerna.svg" alt="Logo iLERNA">
                </a>
                <div class="logo-text">
                    Curso de Especializaci√≥n
                    <span>Inteligencia Artificial y Big Data</span>
                </div>
            </div>
            <nav class="breadcrumb">
                <a href="../index.html">Inicio</a> ‚Üí
                <a href="index.html">Programaci√≥n IA</a> ‚Üí
                <span>Componentes Auxiliares</span>
            </nav>
        </div>
    </header>

    <main class="container">
        <div class="hero">
            <h1>Componentes Auxiliares de Entrenamiento</h1>
            <p class="subtitle">Herramientas cr√≠ticas para orquestar el aprendizaje profundo</p>
        </div>

        <!-- SECCI√ìN 1: FUNCIONES DE P√âRDIDA -->
        <section class="section">
            <h2>1. Funciones de P√©rdida (Loss Functions)</h2>
            <p>La funci√≥n de p√©rdida es la br√∫jula del modelo. Mide num√©ricamente la distancia entre la predicci√≥n
                realizada por la red y el valor real esperado. Sin una funci√≥n de p√©rdida bien definida, el optimizador
                no sabr√≠a en qu√© direcci√≥n ajustar los pesos para mejorar el rendimiento.</p>
            <p>Es vital alinear la p√©rdida con la naturaleza de la tarea. Por ejemplo, en tareas de clasificaci√≥n,
                buscamos minimizar la divergencia entre distribuciones de probabilidad, mientras que en tareas de
                regresi√≥n nos enfocamos en reducir el error cuadr√°tico o absoluto.</p>

            <div class="layout-grid-stack">
                <div class="feature-card primary" style="margin-bottom: 1.5rem;">
                    <h4 class="color-primary">CrossEntropy y BCE</h4>
                    <p>La <span class="code-badge">CrossEntropyLoss</span> es el est√°ndar para la clasificaci√≥n
                        multiclase. Calcula la entrop√≠a cruzada entre la salida del modelo y el objetivo. Es fundamental
                        entender que, por defecto, muchas implementaciones (como en PyTorch) esperan
                        <strong>logits</strong> (valores crudos sin normalizar) en lugar de probabilidades, aplicando
                        internamente una funci√≥n LogSoftmax para mayor estabilidad num√©rica.
                    </p>
                    <p>Para casos binarios, utilizamos <span class="code-badge">BCE</span> (Binary Cross Entropy). Una
                        variante recomendada es <span class="code-badge">BCEWithLogits</span>, que integra la funci√≥n
                        sigmoide dentro de la p√©rdida. Esto evita problemas de precisi√≥n matem√°tica que ocurren cuando
                        calculamos la sigmoide y el logaritmo por separado, resultando en un entrenamiento mucho m√°s
                        estable frente a valores extremos.</p>
                </div>

                <div class="feature-card primary" style="margin-bottom: 1.5rem;">
                    <h4 class="color-primary">MSE y CTC</h4>
                    <p>El <span class="code-badge">MSE</span> (Mean Squared Error) es el n√∫cleo de los problemas de
                        regresi√≥n. Penaliza de forma cuadr√°tica los errores grandes, lo que obliga al modelo a prestar
                        mucha atenci√≥n a los <em>outliers</em>. Si buscamos una mayor robustez frente a datos ruidosos,
                        podemos optar por el error absoluto (MAE) o la p√©rdida Huber, que combina lo mejor de ambos
                        mundos.</p>
                    <p>La p√©rdida <span class="code-badge">CTC</span> (Connectionist Temporal Classification) es una
                        joya en el procesamiento de secuencias como el habla (ASR) o el reconocimiento de texto (OCR).
                        Permite entrenar modelos cuando no conocemos la alineaci√≥n exacta entre la entrada (audio o
                        imagen) y la salida (texto), resolviendo el problema de secuencias de longitudes variables de
                        forma elegante.</p>
                </div>

                <div class="feature-card primary" style="margin-bottom: 1.5rem;">
                    <h4 class="color-primary">Dice y Focal Loss</h4>
                    <p>En la segmentaci√≥n de im√°genes, la p√©rdida <strong>Dice</strong> es esencial para combatir el
                        desequilibrio de clases. Se basa en el coeficiente de solapamiento entre la m√°scara predicha y
                        la real, siendo mucho m√°s efectiva que la entrop√≠a cruzada cuando el objeto que queremos
                        segmentar ocupa una parte min√∫scula de la imagen total.</p>
                    <p>La <strong>Focal Loss</strong> es una evoluci√≥n dise√±ada para tareas de detecci√≥n de objetos.
                        A√±ade un factor multiplicador a la p√©rdida que reduce la importancia de los ejemplos f√°ciles (el
                        fondo) y obliga al modelo a centrarse en los "ejemplos dif√≠ciles" que suele fallar. Es la clave
                        detr√°s del √©xito de detectores en una sola etapa como RetinaNet.</p>
                </div>
            </div>
        </section>

        <!-- SECCI√ìN 2: OPTIMIZADORES -->
        <section class="section">
            <h2>2. Optimizadores: El Motor del Cambio</h2>
            <p>Si la p√©rdida es la br√∫jula, el optimizador es el motor que mueve los pesos del modelo. Su funci√≥n es
                utilizar el gradiente calculado por la retropropagaci√≥n para determinar cu√°nto y en qu√© direcci√≥n deben
                cambiar los millones de par√°metros de la red.</p>
            <p>La elecci√≥n del optimizador y el ajuste de la tasa de aprendizaje (learning rate) son, posiblemente, los
                factores que m√°s influyen en que un modelo converja r√°pidamente o se pierda en un m√≠nimo local o en
                oscilaciones infinitas.</p>

            <div class="feature-grid">
                <div class="feature-card secondary" style="margin-bottom: 1.5rem;">
                    <h4 class="color-secondary">SGD con Momentum</h4>
                    <p>El <span class="code-badge">SGD</span> (Stochastic Gradient Descent) es el abuelo de todos los
                        optimizadores. Aunque simple, sigue siendo extremadamente potente cuando se combina con
                        <strong>momentum</strong>. El momentum act√∫a como una bola de nieve cayendo por una colina:
                        acumula inercia en las direcciones constantes, lo que ayuda a atravesar zonas planas (saddle
                        points) y a amortiguar las oscilaciones en valles estrechos.
                    </p>
                </div>
                <div class="feature-card secondary" style="margin-bottom: 1.5rem;">
                    <h4 class="color-secondary">Adam y AdamW</h4>
                    <p><span class="code-badge">Adam</span> es el optimizador "por defecto" para la mayor√≠a de los
                        investigadores. Adapta la tasa de aprendizaje para cada peso de forma individual bas√°ndose en la
                        media y la varianza de los gradientes. Sin embargo, tiene un fallo conocido: no gestiona bien el
                        <strong>weight decay</strong> (L2 regularization). Por ello naci√≥ <span
                            class="code-badge">AdamW</span>, que separa la penalizaci√≥n de los pesos de la actualizaci√≥n
                        de los gradientes, resultando en modelos con mejor capacidad de generalizaci√≥n.
                    </p>
                </div>
            </div>

            <div class="highlight-box accent">
                <p class="title">‚ö†Ô∏è Hiperpar√°metros Cr√≠ticos</p>
                <p class="content" style="font-size: 1.125rem;">No olvides ajustar el <strong>Learning Rate</strong>
                    (LR). Un valor muy alto
                    provocar√° que el modelo "explote" y la p√©rdida se vuelva infinita. Un valor muy bajo har√° que el
                    aprendizaje sea ag√≥nicamente lento. Adem√°s, el uso de <strong>Weight Decay</strong> es fundamental
                    para evitar que los pesos crezcan desmesuradamente, lo cual causar√≠a un sobreajuste severo.</p>
            </div>
        </section>

        <!-- SECCI√ìN 3: PLANIFICADORES DE LR -->
        <section class="section">
            <h2>3. Planificadores de LR (Schedulers)</h2>
            <p>Entrenar con una tasa de aprendizaje constante es como conducir a la misma velocidad por toda la ciudad.
                Al principio necesitamos ir r√°pido para explorar el terreno, pero al acercarnos al destino (el m√≠nimo de
                la funci√≥n de p√©rdida), necesitamos reducir la velocidad para aparcar con precisi√≥n.</p>
            <p>Los schedulers automatizan la reducci√≥n de la tasa de aprendizaje conforme avanza el entrenamiento,
                permitiendo una convergencia m√°s fina y estable en las fases finales.</p>

            <div class="scenario-box">
                <div class="scenario-item">
                    <div class="content">
                        <h4>StepLR y ExponentialLR</h4>
                        <p>Son los m√°s sencillos de entender. Reducen el LR en un factor determinado (p. ej., dividen
                            por 10) cada cierto n√∫mero de √©pocas. Es una estrategia discreta que funciona bien si
                            conocemos aproximadamente cu√°nto tarda el modelo en estabilizarse, permitiendo dar "saltos"
                            hacia una mayor precisi√≥n una vez que la meseta de p√©rdida es evidente.</p>
                    </div>
                </div>
                <div class="scenario-item">
                    <div class="content">
                        <h4>CosineAnnealing y OneCycle</h4>
                        <p>El <span class="code-badge">CosineAnnealing</span> reduce el LR siguiendo una curva de
                            coseno, lo que proporciona un descenso suave y continuo que suele dar excelentes resultados
                            en visi√≥n artificial. Por otro lado, la pol√≠tica <span class="code-badge">OneCycle</span>
                            eleva el LR r√°pidamente al inicio para "calentar" el modelo y luego lo reduce dr√°sticamente.
                            Esta t√©cnica, popularizada por fast.ai, permite alcanzar precisiones de estado del arte en
                            mucho menos tiempo (super-convergence).</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- SECCI√ìN 4: CALLBACKS -->
        <section class="section">
            <h2>4. Callbacks: Automatizaci√≥n y Monitorizaci√≥n</h2>
            <p>Los callbacks son funciones que se ejecutan autom√°ticamente en puntos espec√≠ficos del entrenamiento (al
                final de cada batch o de cada √©poca). Son herramientas de gesti√≥n que nos ahorran tiempo y protegen
                nuestro trabajo frente a fallos de hardware o humanos.</p>
            <p>Un flujo de entrenamiento moderno no se entiende sin una monitorizaci√≥n en tiempo real y una gesti√≥n
                inteligente de los pesos del modelo.</p>

            <div class="layout-grid-stack">
                <div class="feature-card" style="margin-bottom: 1.5rem;">
                    <h4>Early Stopping y Checkpointing</h4>
                    <p>El <strong>Early Stopping</strong> es el detector de humos del entrenamiento. Vigila la m√©trica
                        de validaci√≥n y, si deja de mejorar durante un n√∫mero de √©pocas (patience), detiene el
                        entrenamiento de forma segura. Esto no solo ahorra energ√≠a y tiempo, sino que es una excelente
                        forma de evitar el sobreajuste (overfitting).</p>
                    <p>El <strong>Model Checkpointing</strong> es nuestro sistema de "guardado r√°pido". Guarda los pesos
                        del modelo autom√°ticamente cada vez que se alcanza un nuevo r√©cord de precisi√≥n. Esto es vital
                        en entrenamientos largos: si el ordenador se apaga o el sistema falla, podemos retomar el
                        trabajo desde el √∫ltimo punto de control sin perder horas de c√≥mputo.</p>
                </div>
                <div class="feature-card" style="margin-bottom: 1.5rem;">
                    <h4>TensorBoard y Weights & Biases (WandB)</h4>
                    <p>Entrenar a ciegas es peligroso. Herramientas como <strong>TensorBoard</strong> nos permiten
                        visualizar curvas de p√©rdida, gradientes e incluso im√°genes de depuraci√≥n en tiempo real a
                        trav√©s del navegador. Es la herramienta est√°ndar para entender qu√© est√° pasando dentro de la
                        "caja negra".</p>
                    <p><strong>Weights & Biases</strong> lleva esto al siguiente nivel. Es un servicio en la nube (SaaS)
                        que almacena todos tus experimentos, permite comparar diferentes ejecuciones con gr√°ficas
                        interactivas y guarda incluso el c√≥digo y la configuraci√≥n utilizada. Es el cuaderno de bit√°cora
                        definitivo para cualquier ingeniero de IA que trabaje profesionalmente.</p>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <h3>iLERNA</h3>
        <p class="footer-course">Curso de Especializaci√≥n en Inteligencia Artificial y Big Data</p>
        <a href="https://www.ilerna.es/" target="_blank">www.ilerna.es</a>
        <p class="footer-info">Centro oficial de FP online y presencial. Ciclos formativos de Grado Medio y Grado
            Superior.</p>
        <div class="penguin">
            <span>üêß</span>
        </div>
    </footer>

    <script src="../js/lecciones.js"></script>
</body>

</html>