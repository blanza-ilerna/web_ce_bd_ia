<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="Gu√≠a pr√°ctica sobre cu√°ndo utilizar cada tipo de m√≥dulo predefinido en proyectos de IA.">
    <meta name="keywords" content="IA, ResNet, BERT, YOLO, Transformers, MobileNet, Machine Learning, Deep Learning">
    <meta name="author" content="Bjlanza">
    <meta name="organization" content="ILERNA">
    <title>¬øCu√°ndo usar cada tipo de M√≥dulo? | iLERNA</title>
    <link rel="stylesheet" href="../css/lecciones.css">
</head>

<body>
    <header>
        <div class="header-container">
            <div class="logo-container">
                <a href="../index.html">
                    <img src="../img/logo-ilerna.svg" alt="Logo iLERNA">
                </a>
                <div class="logo-text">
                    Curso de Especializaci√≥n
                    <span>Inteligencia Artificial y Big Data</span>
                </div>
            </div>
            <nav class="breadcrumb">
                <a href="../index.html">Inicio</a> ‚Üí
                <a href="index.html">Programaci√≥n IA</a> ‚Üí
                <span>¬øCu√°ndo usar cada M√≥dulo?</span>
            </nav>
        </div>
    </header>

    <main class="container">
        <div class="hero">
            <h1>¬øCu√°ndo usar cada tipo de M√≥dulo?</h1>
            <p class="subtitle">Gu√≠a de selecci√≥n de arquitecturas seg√∫n el problema y los recursos</p>
        </div>

        <!-- SECCI√ìN 1: VISI√ìN ARTIFICIAL -->
        <section class="section">
            <h2>1. Visi√≥n Artificial: De la Clasificaci√≥n al An√°lisis Espacial</h2>
            <p>La visi√≥n por computador es uno de los campos donde los m√≥dulos predefinidos brillan con m√°s fuerza.
                Dependiendo de si nuestra meta es identificar una categor√≠a global o localizar elementos precisos, la
                elecci√≥n cambiar√° dr√°sticamente.</p>

            <div class="feature-grid">
                <div class="feature-card primary" style="margin-bottom: 1.5rem;">
                    <h4 class="color-primary">Clasificaci√≥n con Pocos Datos</h4>
                    <p>Cuando trabajamos con datasets peque√±os (pocas cientos o miles de im√°genes), la mejor estrategia
                        es usar <strong>ResNet</strong> o <strong>EfficientNet</strong> preentrenados en ImageNet. Estos
                        modelos ya han aprendido a reconocer bordes, texturas y formas generales.</p>
                    <p>Simplemente "congelamos" la base (extractor de caracter√≠sticas) y a√±adimos una <strong>cabeza
                            densa</strong> personalizada (capas Fully Connected) al final. Estas capas act√∫an como el
                        "cerebro" que toma los patrones complejos extra√≠dos por el modelo base y los traduce a tus
                        categor√≠as espec√≠ficas. Al ser solo estas capas finales las que se entrenan, evitamos destruir
                        el conocimiento previo del modelo (backbone) y logramos resultados excelentes en tiempos r√©cord.
                    </p>
                </div>
                <div class="feature-card primary" style="margin-bottom: 1.5rem;">
                    <h4 class="color-primary">Detecci√≥n y Segmentaci√≥n</h4>
                    <p>Si necesitas saber <em>d√≥nde</em> est√°n los objetos, optamos por <strong>YOLO</strong> (You Only
                        Look Once) si priorizamos la velocidad en tiempo real, o por <strong>Mask R-CNN</strong> si
                        requerimos una precisi√≥n extrema delimitando el contorno exacto de cada objeto (segmentaci√≥n de
                        instancias).</p>
                    <p>En casos donde el objetivo es clasificar cada p√≠xel de la imagen (<strong>segmentaci√≥n
                            sem√°ntica</strong>), la arquitectura <strong>U-Net</strong> es el est√°ndar. A diferencia de
                        la detecci√≥n simple, la segmentaci√≥n sem√°ntica no dibuja cajas, sino que crea una "capa de
                        color" o m√°scara que cubre exactamente la silueta del objeto. Es como si el modelo estuviera
                        coloreando la imagen, asignando a cada punto (p√≠xel) una etiqueta espec√≠fica (p. ej.,
                        "carretera", "tumor" o "edificio"), lo cual es vital para el autoguiado o diagn√≥sticos m√©dicos
                        precisos.</p>
                </div>
            </div>
        </section>

        <!-- SECCI√ìN 2: PROCESAMIENTO DE LENGUAJE NATURAL (NLP) -->
        <section class="section">
            <h2>2. NLP: Entendimiento y Generaci√≥n de Texto</h2>
            <p>El lenguaje natural requiere capturar el contexto y la sem√°ntica. Aqu√≠, los modelos basados en
                Transformers han desplazado casi por completo a las redes recurrentes tradicionales.</p>

            <div class="layout-grid-stack">
                <div class="feature-card secondary" style="margin-bottom: 1.5rem;">
                    <h4 class="color-secondary">NLP Cl√°sico (Comprensi√≥n)</h4>
                    <p>Para tareas de clasificaci√≥n de sentimientos, reconocimiento de entidades (NER) o sistemas de
                        preguntas y respuestas (QA), la familia <strong>BERT</strong> o su versi√≥n optimizada
                        <strong>RoBERTa</strong> son los reyes. Estos modelos son "bidireccionales", lo que significa
                        que entienden el significado de una palabra mirando tanto lo que viene antes como lo que viene
                        despu√©s.
                    </p>
                    <p>Es fundamental utilizar siempre el <strong>tokenizador oficial</strong> del modelo elegido (p.
                        ej., WordPiece para BERT), ya que garantiza que el texto se divida exactamente de la misma forma
                        que durante su entrenamiento original, evitando errores sem√°nticos graves.</p>
                </div>
                <div class="feature-card secondary" style="margin-bottom: 1.5rem;">
                    <h4 class="color-secondary">Generaci√≥n de Texto</h4>
                    <p>Si el objetivo es crear contenido, resumir documentos o traducir, los modelos
                        <strong>GPT-like</strong> (solo decodificador) o <strong>T5</strong> (codificador-decodificador)
                        son los adecuados. Estos modelos est√°n dise√±ados para predecir la siguiente palabra de forma
                        coherente.
                    </p>
                    <p>Podemos utilizarlos mediante <strong>prompting</strong> (instrucciones en lenguaje natural) para
                        tareas r√°pidas, o mediante un <strong>fine-tuning</strong> instruccional si necesitamos que el
                        modelo adopte un tono, formato o base de conocimientos muy espec√≠ficos y corporativos.</p>
                </div>
            </div>
        </section>

        <!-- SECCI√ìN 3: DATOS SECUENCIALES Y TIEMPO -->
        <section class="section">
            <h2>3. Series Temporales y Datos Tabulares</h2>
            <p>No todo en la IA es imagen o texto. Los datos financieros, de sensores o de ventas requieren un enfoque
                en la dependencia temporal.</p>

            <div class="feature-grid">
                <div class="feature-card primary" style="margin-bottom: 1.5rem;">
                    <h4 class="color-primary">Series Temporales Simples</h4>
                    <p>Para predecir valores basados en un hist√≥rico corto, a veces un simple <strong>MLP</strong>
                        (Perceptr√≥n Multicapa) o una <strong>1D-Conv</strong> (Convoluci√≥n unidimensional) son
                        suficientes y mucho m√°s r√°pidos. Si la secuencia tiene una memoria clara a corto plazo, los
                        m√≥dulos <strong>GRU</strong> ofrecen un excelente equilibrio entre potencia y velocidad
                        computacional en comparaci√≥n con las pesadas LSTM.</p>
                </div>
                <div class="feature-card primary" style="margin-bottom: 1.5rem;">
                    <h4 class="color-primary">Patrones Complejos y Largo Plazo</h4>
                    <p>Cuando los datos presentan estacionalidades largas o dependencias entre puntos muy alejados en el
                        tiempo (p. ej., clima o mercados globales), debemos evaluar <strong>Transformers</strong>
                        espec√≠ficos para series temporales (como Informer o Autoformer). Estos modelos utilizan
                        mecanismos de atenci√≥n para decidir qu√© momentos del pasado son realmente relevantes.</p>
                </div>
            </div>
        </section>

        <!-- SECCI√ìN 4: OPTIMIZACI√ìN EN RECURSOS LIMITADOS -->
        <section class="section">
            <h2>4. Recursos Limitados: IA en el Borde (Edge Computing)</h2>
            <p>A veces el reto no es la precisi√≥n, sino el hardware. Si el modelo debe correr en un tel√©fono m√≥vil, una
                Raspberry Pi o un dispositivo IoT, debemos priorizar la eficiencia.</p>

            <div class="scenario-box secondary">
                <div class="scenario-item">
                    <div class="content">
                        <h4>Arquitecturas Ligeras</h4>
                        <p>En lugar de los gigantes convencionales, usamos <strong>MobileNet</strong> o
                            <strong>EfficientNet-lite</strong>. Estos m√≥dulos utilizan convoluciones inteligentes
                            (depthwise separable) que reducen el n√∫mero de c√°lculos por imagen en m√°s de un 80%,
                            manteniendo una precisi√≥n muy respetable en dispositivos m√≥viles.</p>
                    </div>
                </div>
                <div class="scenario-item">
                    <div class="content">
                        <h4>Cuantizaci√≥n y Pruning</h4>
                        <p>Adem√°s de elegir el m√≥dulo correcto, aplicamos optimizaciones cr√≠ticas: la
                            <strong>cuantizaci√≥n</strong> reduce el peso del modelo (de 32 a 8 bits) y el
                            <strong>pruning</strong> elimina conexiones redundantes, permitiendo que la IA sea veloz en
                            procesadores de muy bajo consumo.</p>
                    </div>
                </div>
            </div>
        </section>

        <section class="section">
            <h2>5. Resumen de Selecci√≥n</h2>
            <div class="highlight-box accent">
                <p class="title">üí° Recomendaci√≥n Final</p>
                <p class="content" style="font-size: 1.125rem;">Antes de elegir, hazte tres preguntas: <strong>¬øQu√© tipo
                        de dato tengo?</strong> (imagen, texto, serie temporal), <strong>¬øCu√°ntos datos tengo?</strong>
                    (m√°s datos permiten m√°s fine-tuning) y <strong>¬øD√≥nde va a correr?</strong> (servidor potente o
                    m√≥vil). Empieza siempre por el m√≥dulo m√°s sencillo que resuelva el problema y solo escala a
                    arquitecturas complejas si el rendimiento no es suficiente.</p>
            </div>
        </section>
    </main>

    <footer>
        <h3>iLERNA</h3>
        <p class="footer-course">Curso de Especializaci√≥n en Inteligencia Artificial y Big Data</p>
        <a href="https://www.ilerna.es/" target="_blank">www.ilerna.es</a>
        <p class="footer-info">Centro oficial de FP online y presencial. Ciclos formativos de Grado Medio y Grado
            Superior.</p>
        <div class="penguin">
            <span>üêß</span>
        </div>
    </footer>

    <script src="../js/lecciones.js"></script>
</body>

</html>