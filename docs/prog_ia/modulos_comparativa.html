<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="Comparativa detallada sobre el modelado con redes neuronales, tipos de arquitecturas y cu√°ndo utilizar m√≥dulos predefinidos.">
    <meta name="keywords" content="IA, Redes Neuronales, MLP, CNN, Transformers, RNN, GNN, GAN, M√≥dulos Predefinidos">
    <meta name="author" content="Bjlanza">
    <meta name="organization" content="ILERNA">
    <title>Comparativa de Modelado y M√≥dulos | iLERNA</title>
    <link rel="stylesheet" href="../css/lecciones.css">
</head>

<body>
    <header>
        <div class="header-container">
            <div class="logo-container">
                <a href="../index.html">
                    <img src="../img/logo-ilerna.svg" alt="Logo iLERNA">
                </a>
                <div class="logo-text">
                    Curso de Especializaci√≥n
                    <span>Inteligencia Artificial y Big Data</span>
                </div>
            </div>
            <nav class="breadcrumb">
                <a href="../index.html">Inicio</a> ‚Üí
                <a href="index.html">Programaci√≥n IA</a> ‚Üí
                <span>Comparativa de Modelado</span>
            </nav>
        </div>
    </header>

    <main class="container">
        <div class="hero">
            <h1>Comparativa de Modelado y M√≥dulos</h1>
            <p class="subtitle">Estrategias de selecci√≥n seg√∫n arquitectura, datos y objetivos</p>
        </div>

        <section class="section">
            <h2>1. El Arte de Elegir la Red Correcta</h2>
            <p>En el desarrollo de IA moderna, no se trata solo de construir una red, sino de seleccionar la
                arquitectura que mejor se adapte al problema. La elecci√≥n depende de tres pilares fundamentales:</p>

            <div class="layout-grid-stack">
                <div class="feature-card secondary" style="margin-bottom: 1.5rem;">
                    <h4 class="color-secondary">1.1. üìä Naturaleza de los Datos</h4>
                    <p>¬øSon tablas estructuradas, im√°genes, secuencias de texto o grafos sociales? La estructura del
                        dato dicta la conectividad de la red.</p>
                </div>
                <div class="feature-card secondary" style="margin-bottom: 1.5rem;">
                    <h4 class="color-secondary">1.2. üéØ Objetivo de la Tarea</h4>
                    <p>¬øClasificaci√≥n simple, generaci√≥n de contenido, predicci√≥n de series temporales o detecci√≥n de
                        objetos en tiempo real?</p>
                </div>
                <div class="feature-card secondary">
                    <h4 class="color-secondary">1.3. ‚ö° Recursos y Latencia</h4>
                    <p>¬øSe ejecutar√° en un servidor con 4 GPUs o en un dispositivo m√≥vil? El tama√±o del modelo y los
                        m√≥dulos predefinidos son clave aqu√≠.</p>
                </div>
            </div>
        </section>

        <section class="section">
            <h2>2. Tipos de Redes y Escenarios de Uso</h2>
            <p>Dependiendo del dominio del problema, existen arquitecturas especializadas (muchas disponibles como
                m√≥dulos predefinidos) que ofrecen el mejor rendimiento:</p>

            <div class="layout-grid-stack">
                <div class="feature-card secondary" style="margin-bottom: 1.5rem;">
                    <h4 class="color-secondary">2.1. Datos Tabulares: El dominio de la MLP</h4>
                    <p>Para datos estructurados (archivos CSV, bases de datos SQL), el <span
                            class="code-badge">MLP</span> (Perceptr√≥n Multicapa) sigue siendo el est√°ndar. Cuando los
                        datos no tienen una relaci√≥n espacial o temporal clara, una red densa bien ajustada sobre
                        vectores es
                        suficiente y mucho m√°s eficiente que arquitecturas complejas.</p>
                </div>

                <div class="feature-card secondary" style="margin-bottom: 1.5rem;">
                    <h4 class="color-secondary">2.2. Visi√≥n Artificial: CNN vs. ViT</h4>
                    <p>Hist√≥ricamente, las <span class="code-badge">CNN</span> (Redes Neuronales Convolucionales) han
                        dominado el procesado de im√°genes y v√≠deo gracias a su capacidad para detectar patrones
                        espaciales. Sin embargo, los <span class="code-badge">Transformers</span> (como ViT - Vision
                        Transformer) est√°n ganando terreno en datasets masivos, ofreciendo una mejor comprensi√≥n global
                        de la imagen a cambio de un mayor coste computacional.</p>
                </div>

                <div class="feature-card secondary" style="margin-bottom: 1.5rem;">
                    <h4 class="color-secondary">2.3. Secuencias y Texto: De RNN a Transformers</h4>
                    <p>Para procesar lenguaje o se√±ales temporales, las <span class="code-badge">RNN</span>, <span
                            class="code-badge">LSTM</span> y <span class="code-badge">GRU</span> siguen siendo √∫tiles en
                        escenarios ligeros o con recursos limitados. No obstante, para tareas de gran escala o
                        multimodales, los <span class="code-badge">Transformers</span> son la opci√≥n hegem√≥nica por su
                        capacidad de atenci√≥n global y paralelizaci√≥n.</p>
                </div>

                <div class="feature-card secondary" style="margin-bottom: 1.5rem;">
                    <h4 class="color-secondary">2.4. Relaciones Complejas: GNN</h4>
                    <p>Cuando los datos se representan mejor como nodos y aristas (redes de transporte, mol√©culas
                        qu√≠micas, recomendaciones sociales), las <span class="code-badge">GNN</span> (Graph Neural
                        Networks) aprovechan las relaciones expl√≠citas que otras redes ignorar√≠an mediante el paso de
                        mensajes entre nodos.</p>
                </div>

                <div class="feature-card secondary">
                    <h4 class="color-secondary">2.5. S√≠ntesis y Aumento: Modelos Generativos</h4>
                    <p>Para la creaci√≥n de nuevos datos o el aumento de datasets escasos, empleamos redes <span
                            class="code-badge">GAN</span> (Generativas Antag√≥nicas) o modelos de
                        <strong>Difusi√≥n</strong>, fundamentales en la IA generativa actual para crear im√°genes, audio o
                        gemelos digitales.
                    </p>
                </div>
            </div>

            <div class="highlight-box secondary mt-2">
                <p class="content"><strong>Tendencia Actual:</strong> En NLP y, cada vez m√°s en visi√≥n, los
                    <strong>Transformers</strong> dominan el estado del arte; sin embargo, en entornos de producci√≥n con
                    restricciones de c√≥mputo, las <strong>CNN</strong> siguen siendo la opci√≥n m√°s s√≥lida para im√°genes
                    puras.
                </p>
            </div>
        </section>

        <section class="section">
            <h2>3. El Cat√°logo de M√≥dulos Predefinidos</h2>
            <p>Los m√≥dulos predefinidos no son solo modelos completos, sino piezas modulares que podemos combinar para
                construir arquitecturas robustas y optimizadas.</p>

            <div class="feature-grid">
                <div class="feature-card primary mt-2">
                    <h4>üß© Capas Elementales</h4>
                    <p>Componentes b√°sicos como <span class="code-badge">Dense</span>, <span
                            class="code-badge">Conv2D</span>, <span class="code-badge">LSTM</span>, <span
                            class="code-badge">Multi-Head Attention</span> y <span class="code-badge">Embedding</span>.
                    </p>
                    <p>Incluyen t√©cnicas de normalizaci√≥n (<span class="code-badge">BatchNorm</span>, <span
                            class="code-badge">LayerNorm</span>) y regularizaci√≥n (<span
                            class="code-badge">Dropout</span>).</p>
                </div>
                <div class="feature-card primary mt-2">
                    <h4>üß± Bloques y Patrones</h4>
                    <p>Estructuras probadas como los bloques <strong>Residuales</strong> (ResNet), bloques de eficiencia
                        (EfficientNet, MobileNet) o patrones <strong>Encoder-Decoder</strong> (U-Net) para segmentaci√≥n.
                    </p>
                </div>
                <div class="feature-card primary mt-2">
                    <h4>üèÜ Modelos Preentrenados</h4>
                    <p>Arquitecturas listas para <strong>Transfer Learning</strong>:</p>
                    <ul>
                        <li><strong>Visi√≥n:</strong> ResNet, EfficientNet, ViT.</li>
                        <li><strong>NLP:</strong> BERT, RoBERTa, T5, GPT.</li>
                        <li><strong>Multimodal:</strong> CLIP, BLIP.</li>
                    </ul>
                </div>
            </div>

            <div class="highlight-box primary mt-2">
                <p class="title">üöÄ Ventaja Competitiva</p>
                <p class="content" style="font-size: 1.125rem;">El uso de estos m√≥dulos acelera el desarrollo y permite
                    el <strong>Transfer
                        Learning</strong>: entrenar modelos potentes con muchos menos datos al "heredar" el conocimiento
                    de bases de datos masivas.</p>
            </div>
        </section>

        <section class="section">
            <h2>4. Criterios de Selecci√≥n Final</h2>
            <p>Una vez identificada la familia de redes, el uso de <strong>m√≥dulos predefinidos</strong> frente al
                modelado desde cero se gu√≠a por:</p>

            <div class="layout-grid-stack">
                <div class="feature-card secondary" style="margin-bottom: 1.5rem;">
                    <h4 class="color-secondary">4.1. Tama√±o del Dataset y Transfer Learning</h4>
                    <p>En datasets peque√±os, el Transfer Learning es obligatorio. Aprovechar una red preentrenada en
                        millones de datos es m√°s efectivo que intentar entrenar una arquitectura propia desde cero.</p>
                </div>
                <div class="feature-card secondary" style="margin-bottom: 1.5rem;">
                    <h4 class="color-secondary">4.2. Latencia y Despliegue Objetivo</h4>
                    <p>En dispositivos <em>Edge</em> (m√≥viles, IoT), elegimos m√≥dulos optimizados (MobileNet, Tiny-YOLO)
                        o versiones destiladas para optimizar tiempos de respuesta.</p>
                </div>
                <div class="feature-card secondary">
                    <h4 class="color-secondary">4.3. Interpretabilidad y Auditor√≠a</h4>
                    <p>En sectores cr√≠ticos, a veces es preferible una arquitectura simple y transparente frente a
                        modelos de "caja negra" complejos de auditar.</p>
                </div>
            </div>
        </section>

        <section class="section">
            <h2>5. Flujo de Trabajo Recomendado</h2>
            <p>Para garantizar el √©xito en el modelado con m√≥dulos predefinidos, debemos seguir un proceso met√≥dico:</p>

            <div class="step-list">
                <div class="step-item">
                    <div class="step-number">1</div>
                    <div class="step-content">
                        <h4>Definici√≥n y Datos</h4>
                        <p>Identificar la tarea, fijar m√©tricas objetivo (accuracy, F1, latencia) y asegurar un dataset
                            balanceado y reproducible.</p>
                    </div>
                </div>
                <div class="step-item">
                    <div class="step-number">2</div>
                    <div class="step-content">
                        <h4>Pipeline de Preprocesado</h4>
                        <p>Establecer transformaciones coherentes (normalizaci√≥n, tokenizaci√≥n, aumento).
                            <strong>Importante:</strong> el mismo pipeline debe usarse en entrenamiento e inferencia.
                        </p>
                    </div>
                </div>
                <div class="step-item">
                    <div class="step-number">3</div>
                    <div class="step-content">
                        <h4>Selecci√≥n de Arquitectura Base</h4>
                        <p>Elegir el m√≥dulo predefinido af√≠n al dominio (ResNet para imagen, BERT para texto). Decidir
                            entre <em>Feature Extraction</em> o <em>Fine-tuning</em>.</p>
                    </div>
                </div>
                <div class="step-item">
                    <div class="step-number">4</div>
                    <div class="step-content">
                        <h4>Construcci√≥n y Adaptaci√≥n</h4>
                        <p>A√±adir la "cabeza" del modelo (n√∫mero de clases), loss function alineada y capas de
                            regularizaci√≥n para evitar sobreajuste.</p>
                    </div>
                </div>
                <div class="step-item">
                    <div class="step-number">5</div>
                    <div class="step-content">
                        <h4>Entrenamiento Controlado</h4>
                        <p>Configurar optimizador (Adam/SGD), learning rate y monitorizar con <em>Early Stopping</em> y
                            <em>Checkpointing</em>.
                        </p>
                    </div>
                </div>
                <div class="step-item">
                    <div class="step-number">6</div>
                    <div class="step-content">
                        <h4>An√°lisis de Errores</h4>
                        <p>Revisar matriz de confusi√≥n y muestras mal clasificadas para detectar sesgos o falta de datos
                            en casos espec√≠ficos.</p>
                    </div>
                </div>
                <div class="step-item">
                    <div class="step-number">7</div>
                    <div class="step-content">
                        <h4>Empaquetado y Despliegue</h4>
                        <p>Exportar el pipeline completo (SavedModel/ONNX). Validar la latencia en el entorno destino
                            antes del lanzamiento final.</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- TABLA RECOPILATORIA -->
        <section class="section">
            <h2>6. Resumen: ¬øQu√© red usar y cu√°ndo?</h2>
            <div class="table-container">
                <table>
                    <thead>
                        <tr>
                            <th>Arquitectura</th>
                            <th>Idea Clave</th>
                            <th>Cu√°ndo Usar</th>
                            <th>Ventajas</th>
                            <th>L√≠mites</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>MLP</strong></td>
                            <td>Capas densas sobre vectores</td>
                            <td>Datos tabulares, se√±ales featurizadas</td>
                            <td>Sencillo y muy r√°pido</td>
                            <td>No capta estructura espacial/temporal</td>
                        </tr>
                        <tr>
                            <td><strong>CNN</strong></td>
                            <td>Convoluciones (patrones locales)</td>
                            <td>Im√°genes, audio (espectrogramas), v√≠deo</td>
                            <td>Eficacia extrema en visi√≥n</td>
                            <td>Requiere m√°s datos/c√≥mputo</td>
                        </tr>
                        <tr>
                            <td><strong>RNN / LSTM</strong></td>
                            <td>Dependencias temporales</td>
                            <td>Secuencias cortas/medias (sensores)</td>
                            <td>Modelan el orden temporal</td>
                            <td>Menos competitivas que Transformers en NLP</td>
                        </tr>
                        <tr>
                            <td><strong>Transformers</strong></td>
                            <td>Atenci√≥n global paralelizable</td>
                            <td>NLP, Visi√≥n (ViT), Multimodal</td>
                            <td>Estado del arte, transfer potente</td>
                            <td>Pesados en c√≥mputo y memoria</td>
                        </tr>
                        <tr>
                            <td><strong>GNN</strong></td>
                            <td>Paso de mensajes en grafos</td>
                            <td>Recomendaci√≥n, qu√≠mica, redes</td>
                            <td>Explota estructuras relacionales</td>
                            <td>M√°s complejas de dise√±ar</td>
                        </tr>
                        <tr>
                            <td><strong>GAN / Difusi√≥n</strong></td>
                            <td>Generaci√≥n de contenido</td>
                            <td>S√≠ntesis de im√°genes, audio, datos</td>
                            <td>Creaci√≥n de datos realistas</td>
                            <td>Entrenamiento inestable</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </section>

        <section class="section">
            <div class="highlight-box secondary">
                <p class="title">‚ö†Ô∏è Antipatrones a Evitar</p>
                <div class="content" style="font-size: 1.125rem;">
                    <ul class="list-warning">
                        <li>Ajustar hiperpar√°metros usando el conjunto de <strong>test</strong> (provoca optimismo
                            falso).</li>
                        <li>Utilizar un preprocesado diferente entre entrenamiento e inferencia.</li>
                        <li>Ignorar las <strong>semillas aleatorias</strong> (impide la reproducibilidad).</li>
                        <li>Evaluar solo el <em>accuracy</em> global sin analizar el rendimiento por clase.</li>
                    </ul>
                </div>
            </div>
        </section>

        <div class="highlight-box primary">
            <p class="title">üí° Resumen Estrat√©gico</p>
            <p class="content" style="font-size: 1.125rem;">No existe la "mejor red", sino la m√°s adecuada. El
                desarrollador de IA moderno debe
                conocer el cat√°logo de <strong>m√≥dulos predefinidos</strong> para no reinventar la rueda, aplicando
                personalizaciones solo donde el valor a√±adido del problema lo requiera.</p>
        </div>
    </main>

    <footer>
        <h3>iLERNA</h3>
        <p class="footer-course">Curso de Especializaci√≥n en Inteligencia Artificial y Big Data</p>
        <a href="https://www.ilerna.es/" target="_blank">www.ilerna.es</a>
        <p class="footer-info">Centro oficial de FP online y presencial. Ciclos formativos de Grado Medio y Grado
            Superior.</p>
        <div class="penguin">
            <span>üêß</span>
        </div>
    </footer>

    <script src="../js/lecciones.js"></script>
</body>

</html>