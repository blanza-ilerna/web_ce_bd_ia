<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Entornos de Modelado de IA: Manipulaci√≥n y Preparaci√≥n de Datos - iLERNA">
    <meta name="keywords" content="IA, Limpieza de Datos, Pandas, NumPy, Scikit-learn, Spark, Normalizaci√≥n, ETL">
    <meta name="author" content="Bjlanza">
    <meta name="organization" content="ILERNA">
    <title>Manipulaci√≥n de Datos en IA | iLERNA</title>
    <link rel="stylesheet" href="../css/lecciones.css">
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
</head>

<body>
    <header>
        <div class="header-container">
            <div class="logo-container">
                <a href="../index.html">
                    <img src="../img/logo-ilerna.svg" alt="Logo iLERNA">
                </a>
                <div class="logo-text">
                    iLERNA
                    <span>Curso de Especializaci√≥n en IA y Big Data</span>
                </div>
            </div>
            <nav class="breadcrumb">
                <a href="../index.html">Inicio</a> ‚Ä∫
                <a href="index.html">Programaci√≥n IA</a> ‚Ä∫
                <span>Manipulaci√≥n de Datos</span>
            </nav>
        </div>
    </header>

    <main class="container">
        <!-- Hero Section -->
        <div class="hero">
            <h1 class="color-primary">Manipulaci√≥n y Preparaci√≥n de Datos</h1>
            <p class="subtitle">Del Caos a la Informaci√≥n Estructurada</p>
        </div>

        <!-- SECCI√ìN 1: INTRODUCCI√ìN -->
        <section class="section">
            <h2 class="section-title">El Paso Cr√≠tico: "Garbage In, Garbage Out"</h2>
            <p class="mb-4">
                Antes de que cualquier algoritmo de IA pueda aprender, los datos deben ser preparados meticulosamente.
                Los datos del mundo real suelen ser incompletos, inconsistentes y ruidosos. La fase de
                <strong>preparaci√≥n de datos</strong> suele consumir entre el 60% y el 80% del tiempo de un proyecto de
                ciencia de datos.
            </p>
            <p class="mb-4">
                Este proceso incluye la limpieza (tratamiento de valores nulos y duplicados), la transformaci√≥n
                (convertir formatos, normalizar escalas) y la selecci√≥n de caracter√≠sticas (elegir las variables m√°s
                relevantes para el modelo).
            </p>

            <div class="highlight-box primary">
                <p>
                    A continuaci√≥n, analizamos las herramientas fundamentales para esta etapa cr√≠tica, desde librer√≠as
                    de Python hasta soluciones Big Data y herramientas visuales.
                </p>
            </div>
        </section>

        <!-- SECCI√ìN 2: PANDAS Y NUMPY -->
        <section class="section">
            <h2 class="section-title">El Ecosistema Python: Pandas y NumPy</h2>

            <div class="card secondary mb-6">
                <h3 class="color-secondary">Limpieza y Manipulaci√≥n √Ågil</h3>
                <p class="mb-2">
                    <strong>Pandas</strong> y <strong>NumPy</strong> son el est√°ndar de la industria para trabajar con
                    datos en memoria. Ofrecen estructuras de datos flexibles y funciones vectorizadas de alto
                    rendimiento para filtrar, limpiar y transformar datasets complejos.
                </p>
                <p class="mb-4">
                    Permiten detectar autom√°ticamente valores faltantes (`NaN`), rellenarlos con estrategias
                    estad√≠sticas (media, mediana) o eliminar registros corruptos, as√≠ como realizar conversiones de
                    tipos de datos de forma masiva.
                </p>

                <h4 class="font-bold mb-2">Ejemplo de Limpieza con Pandas:</h4>
                <pre><code class="language-python">import pandas as pd
import numpy as np

# Crear DataFrame con datos "sucios"
data = {
    'nombre': ['Ana', 'Juan', 'Luis', np.nan],
    'edad': [25, 30, np.nan, 22],
    'salario': ['30000', '45000', '50000', 'missing']
}
df = pd.read_csv("datos_ventas.csv") # Simulaci√≥n de carga

# 1. Tratar valores nulos (Imputaci√≥n)
# Rellenar edad faltante con la media
df['edad'].fillna(df['edad'].mean(), inplace=True)

# 2. Conversi√≥n de formatos
# Convertir 'salario' a num√©rico, forzando errores a NaN
df['salario'] = pd.to_numeric(df['salario'], errors='coerce')

# 3. Eliminar filas que sigan teniendo nulos cr√≠ticos
df.dropna(subset=['nombre', 'salario'], inplace=True)

print("Datos limpios:")
print(df.head())</code></pre>
            </div>
        </section>

        <!-- SECCI√ìN 3: SCIKIT-LEARN -->
        <section class="section">
            <h2 class="section-title">Preprocesamiento para ML con Scikit-learn</h2>

            <div class="card primary mb-6">
                <h3 class="color-primary">Transformaci√≥n y Normalizaci√≥n</h3>
                <p class="mb-2">
                    Una vez los datos est√°n limpios, deben transformarse para que los algoritmos matem√°ticos puedan
                    procesarlos eficientemente. <strong>Scikit-learn</strong> ofrece m√≥dulos robustos como
                    `preprocessing` para estas tareas.
                </p>
                <div class="grid-features mb-4">
                    <div class="feature-card secondary">
                        <h4>StandardScaler / MinMaxScaler</h4>
                        <p>Normalizan los datos num√©ricos para que todas las variables tengan la misma escala, evitando
                            que una variable domine a las dem√°s (ej. salario vs edad).</p>
                    </div>
                    <div class="feature-card secondary">
                        <h4>OneHotEncoder</h4>
                        <p>Convierte variables categ√≥ricas (texto como "Rojo", "Verde") en vectores num√©ricos binarios
                            que las redes neuronales pueden entender.</p>
                    </div>
                </div>

                <h4 class="font-bold mb-2">Pipline de Preprocesamiento:</h4>
                <pre><code class="language-python">from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
import pandas as pd

# Datos de ejemplo
X = pd.DataFrame({
    'edad': [25, 45, 35],
    'ciudad': ['Madrid', 'Barcelona', 'Madrid']
})

# Definir transformaciones
preprocessor = ColumnTransformer(
    transformers=[
        # Escalar 'edad' (media 0, desviaci√≥n 1)
        ('num', StandardScaler(), ['edad']),
        # Codificar 'ciudad' como vectores binarios
        ('cat', OneHotEncoder(), ['ciudad'])
    ])

# Aplicar transformaciones
X_transformed = preprocessor.fit_transform(X)

print("Matriz procesada lista para entrenar:")
print(X_transformed)</code></pre>
            </div>
        </section>

        <!-- SECCI√ìN 4: BIG DATA (SPARK) -->
        <section class="section">
            <h2 class="section-title">Vol√∫menes Masivos: Apache Spark</h2>

            <div class="card secondary mb-6">
                <h3 class="color-secondary">Procesamiento Distribuido con PySpark</h3>
                <p class="mb-2">
                    Cuando los datos superan la memoria de una sola m√°quina (Terabytes o Petabytes), Pandas no es
                    suficiente. <strong>Apache Spark</strong> distribuye los datos a trav√©s de un cl√∫ster de servidores,
                    permitiendo realizar las mismas operaciones de limpieza y transformaci√≥n en paralelo.
                </p>
                <p class="mb-4">
                    Su m√≥dulo `Spark MLlib` incluye herramientas espec√≠ficas para Feature Engineering a gran escala,
                    como `VectorAssembler` y `StringIndexer`.
                </p>

                <pre><code class="language-python">from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler, StringIndexer

spark = SparkSession.builder.appName("DataPrep").getOrCreate()

# Cargar dataset distribuido
df = spark.read.csv("hdfs://datos_log_masivos.csv", header=True, inferSchema=True)

# Indexar columna de texto (String -> √çndice Num√©rico)
indexer = StringIndexer(inputCol="categoria", outputCol="categoria_index")
df_indexed = indexer.fit(df).transform(df)

# Ensamblar todas las caracter√≠sticas en un solo vector (requisito de Spark ML)
assembler = VectorAssembler(
    inputCols=["edad", "salario", "categoria_index"],
    outputCol="features")

output = assembler.transform(df_indexed)
output.select("features", "label").show(5)</code></pre>
            </div>
        </section>

        <!-- SECCI√ìN 5: HERRAMIENTAS VISUALES -->
        <section class="section">
            <h2 class="section-title">Herramientas Visuales y No-Code</h2>
            <p class="mb-4">
                No siempre es necesario programar. Existen herramientas potentes para analistas que permiten preparar
                datos mediante interfaces visuales intuitivas.
            </p>

            <div class="grid-features">
                <div class="feature-card primary">
                    <h4>Power BI</h4>
                    <p>
                        A trav√©s de su editor <strong>Power Query</strong>, permite realizar transformaciones complejas
                        (ETL) paso a paso: filtrar filas, dividir columnas, reemplazar valores y combinar tablas, todo
                        sin escribir c√≥digo, aunque permite usar lenguaje M para l√≥gica avanzada.
                    </p>
                </div>
                <div class="feature-card secondary">
                    <h4>Google Cloud DataPrep</h4>
                    <p>
                        Servicio inteligente en la nube (basado en Trifacta) que sugiere transformaciones
                        autom√°ticamente al analizar los datos. Visualiza la distribuci√≥n de valores en tiempo real,
                        facilitando la detecci√≥n de anomal√≠as y outliers antes de exportar a BigQuery.
                    </p>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <h3>iLERNA</h3>
        <p class="footer-course">Curso de Especializaci√≥n en Inteligencia Artificial y Big Data</p>
        <a href="https://www.ilerna.es/" target="_blank">www.ilerna.es</a>
        <div class="penguin">
            <span>üêß</span>
        </div>
    </footer>

    <script src="../js/lecciones.js"></script>
</body>

</html>