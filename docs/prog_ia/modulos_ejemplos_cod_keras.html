<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="Ejemplo pr√°ctico de Transfer Learning con Keras y ResNet50 para clasificaci√≥n de im√°genes.">
    <meta name="author" content="iLERNA">
    <meta name="organization" content="ILERNA">
    <title>Transfer Learning con ResNet50 | iLERNA</title>
    <link rel="stylesheet" href="../css/lecciones.css">
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;600;700&display=swap" rel="stylesheet">
    <!-- Prism.js para resaltado de c√≥digo -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
</head>

<body>
    <div class="container">
        <header>
            <div class="header-container">
                <div class="logo-container">
                    <a href="../index.html">
                        <img src="../img/logo-ilerna.svg" alt="Logo iLERNA">
                    </a>
                    <div class="logo-text">
                        iLERNA
                        <span>Curso de Especializaci√≥n en IA y Big Data</span>
                    </div>
                </div>
                <div class="breadcrumb">
                    <a href="../index.html">Inicio</a> ‚Ä∫
                    <a href="index.html">Programaci√≥n de IA</a> ‚Ä∫
                    <span>Transfer Learning con ResNet50</span>
                </div>
            </div>
            <h1 class="text-center">Keras: Transfer Learning con ResNet50</h1>
            <p class="subtitle text-center">Clasificaci√≥n de im√°genes eficiente mediante modelos preentrenados</p>
        </header>

        <main>
            <!-- TOC -->
            <nav class="toc-container">
                <h3>üìë Contenido de la Lecci√≥n</h3>
                <ul class="toc-list">
                    <li><a href="#objetivo">1. Objetivo del Proyecto</a></li>
                    <li><a href="#que-es-transfer-learning">2. ¬øQu√© es Transfer Learning?</a></li>
                    <li><a href="#ejemplo-codigo">3. Ejemplo de C√≥digo en Keras</a></li>
                    <li><a href="#desglose-tecnico">4. Desglose T√©cnico del Proceso</a></li>
                    <li><a href="#preparacion-datos">5. Preparaci√≥n de Datos</a></li>
                    <li><a href="#buenas-practicas">6. Buenas Pr√°cticas y Errores Comunes</a></li>
                    <li><a href="#conclusion">7. Conclusi√≥n</a></li>
                </ul>
            </nav>

            <!-- SECCI√ìN 1: OBJETIVO -->
            <section class="section" id="objetivo">
                <h2 class="section-title">1. ¬øQu√© se quiere conseguir?</h2>
                <p>
                    El objetivo principal es construir un <strong>clasificador de im√°genes</strong> robusto capaz de
                    identificar categor√≠as espec√≠ficas (por ejemplo: "gato", "perro", "p√°jaro") a partir de im√°genes de
                    <strong>224√ó224 p√≠xeles RGB</strong>.
                </p>
                <div class="grid-2-cols">
                    <div class="feature-card">
                        <h4>üöÄ Eficiencia</h4>
                        <p>Lograr resultados competitivos de forma r√°pida y con un conjunto de datos reducido.</p>
                    </div>
                    <div class="feature-card">
                        <h4>üß† Reutilizaci√≥n</h4>
                        <p>Aprovechar el conocimiento de <strong>ResNet50</strong>, un modelo preentrenado en millones
                            de im√°genes (ImageNet).</p>
                    </div>
                </div>
                <div class="highlight-box warning">
                    <p><strong>Atenci√≥n:</strong> En lugar de entrenar desde cero, reutilizamos la capacidad de la red
                        para "ver" patrones b√°sicos (bordes, texturas) y solo entrenamos la parte final para nuestra
                        tarea espec√≠fica.</p>
                </div>

                <div class="highlight-box secondary">
                    <h4 class="color-secondary">‚ö†Ô∏è Antipatrones a evitar</h4>
                    <p>Para asegurar la validez cient√≠fica de tu modelo, evita estos errores cr√≠ticos:</p>
                    <ul class="list-disc-padded">
                        <li><strong>Fuga de datos (Data Leakage):</strong> No ajustes hiperpar√°metros usando el conjunto
                            de test; usa siempre el de validaci√≥n.</li>
                        <li><strong>Inconsistencia de Pipeline:</strong> Aplicar un preprocesado diferente entre el
                            entrenamiento y la inferencia real.</li>
                        <li><strong>Inestabilidad:</strong> Ignorar el control de semillas (random state) para
                            reproducir resultados.</li>
                        <li><strong>Visi√≥n sesgada:</strong> Evaluar solo el <em>accuracy</em> global sin desglosar
                            m√©tricas por cada clase.</li>
                    </ul>
                </div>
            </section>

            <!-- SECCI√ìN 2: DEFINICI√ìN -->
            <section class="section" id="que-es-transfer-learning">
                <h2 class="section-title">2. ¬øQu√© es "Transfer Learning" y por qu√© se usa?</h2>
                <p>
                    Consiste en transferir el conocimiento de un modelo grande y general a un problema concreto. Es el
                    equivalente a no tener que aprender a leer desde cero cada vez que abres un libro nuevo.
                </p>
                <div class="vertical-stack">
                    <div class="card primary">
                        <h4>Ventajas Clave</h4>
                        <ul class="list-disc-padded">
                            <li><strong>Menos datos:</strong> No necesitas millones de fotos para empezar.</li>
                            <li><strong>Menos c√≥mputo:</strong> Se ahorran horas (o d√≠as) de entrenamiento en GPU.</li>
                            <li><strong>Mejores resultados:</strong> Los modelos preentrenados suelen generalizar mejor
                                desde el inicio.</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- SECCI√ìN 3: C√ìDIGO -->
            <section class="section" id="ejemplo-codigo">
                <h2 class="section-title">3. Ejemplo de C√≥digo</h2>
                <div class="scenario-box white">
                    <pre><code class="language-python">import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras import layers, models

# 1) Base preentrenada (congelada)
# Weights="imagenet" carga los pesos aprendidos de millones de im√°genes
# include_top=False elimina las capas finales de clasificaci√≥n originales
base = ResNet50(weights="imagenet", include_top=False, input_shape=(224,224,3))
base.trainable = False # Importante: congelar al inicio

# 2) Cabeza final adaptada a nuestro problema
inputs = tf.keras.Input(shape=(224,224,3))
# El preprocesado es CR√çTICO para que el modelo entienda los datos
x = preprocess_input(inputs)
x = base(x, training=False)
x = layers.GlobalAveragePooling2D()(x) # Resume mapas de activaci√≥n
x = layers.Dropout(0.2)(x) # Evita el sobreajuste
outputs = layers.Dense(3, activation="softmax")(x) # 3 clases de ejemplo

model = models.Model(inputs, outputs)

# 3) Compilaci√≥n del modelo
model.compile(
    optimizer=tf.keras.optimizers.Adam(1e-3),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

# 4) Entrenamiento (suponiendo train_ds y val_ds preparados)
model.fit(train_ds, validation_data=val_ds, epochs=5)

# 5) Opcional: Fine-tuning parcial
base.trainable = True
for layer in base.layers[:-20]: # Congelamos todo menos las √∫ltimas 20 capas
    layer.trainable = False

model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), 
              loss="sparse_categorical_crossentropy", 
              metrics=["accuracy"])
model.fit(train_ds, validation_data=val_ds, epochs=5)</code></pre>
                </div>
            </section>

            <!-- SECCI√ìN 4: DESGLOSE -->
            <section class="section" id="desglose-tecnico">
                <h2 class="section-title">4. ¬øQu√© hace cada parte del ejemplo?</h2>
                <div class="vertical-stack">
                    <div class="card secondary">
                        <h4 class="color-secondary">1. Cargar la base preentrenada</h4>
                        <p>Al usar <code>include_top=False</code>, eliminamos el "cerebro" final del modelo y nos
                            quedamos con los "ojos" (el extractor de caracter√≠sticas). Congelar la base impide que el
                            entrenamiento inicial destruya lo que el modelo ya sabe.</p>
                    </div>
                    <div class="card primary">
                        <h4 class="color-primary">2. Preprocesado propio</h4>
                        <p>Cada arquitectura necesita que los datos lleguen en un formato espec√≠fico (escalado de 0 a 1,
                            o de -1 a 1, centrado de colores). <code>preprocess_input</code> asegura que estemos
                            hablando el "idioma" de ResNet50.</p>
                    </div>
                    <div class="card secondary">
                        <h4 class="color-secondary">3. A√±adir la "Cabeza"</h4>
                        <p>Conectamos una capa de <code>GlobalAveragePooling2D</code> para convertir los mapas de
                            caracter√≠sticas espaciales en un vector que una capa <code>Dense</code> final pueda
                            clasificar.</p>
                    </div>
                    <div class="card primary">
                        <h4 class="color-primary">4. Fine-tuning (Ajuste fino)</h4>
                        <p>Una vez que la cabeza nueva est√° estabilizada, podemos "descongelar" las √∫ltimas capas de la
                            base para que se adapten con extrema precisi√≥n a nuestro dataset.</p>
                    </div>
                </div>
            </section>

            <!-- SECCI√ìN 5: DATOS -->
            <section class="section" id="preparacion-datos">
                <h2 class="section-title">5. ¬øQu√© datos hacen falta y c√≥mo se preparan?</h2>
                <div class="grid-2-cols">
                    <div class="feature-card">
                        <h4>üìÇ Estructura de Carpetas</h4>
                        <div
                            style="background: var(--bg-code); color: #f8f8f2; padding: 1rem; border-radius: 8px; font-family: monospace; border-left: 4px solid var(--color-primary); margin-top: 0.5rem;">
                            <pre
                                style="margin: 0; padding: 0; background: transparent; color: inherit; font-size: 1.125rem;">data/
  train/
    clase_A/
    clase_B/
  val/
    clase_A/
    clase_B/</pre>
                        </div>
                    </div>
                    <div class="feature-card">
                        <h4>üîÑ Data Augmentation</h4>
                        <p>Rotar, recortar y cambiar el brillo de las im√°genes durante el entrenamiento ayuda al modelo
                            a ser m√°s robusto ante imprevistos.</p>
                    </div>
                </div>
            </section>

            <!-- SECCI√ìN 6: BUENAS PR√ÅCTICAS -->
            <section class="section" id="buenas-practicas">
                <h2 class="section-title">6. Buenas Pr√°cticas y Errores Comunes</h2>
                <div class="grid-2-cols">
                    <div class="feature-card primary">
                        <h4 class="color-primary">‚úÖ Buenas Pr√°cticas</h4>
                        <ul class="list-disc-padded">
                            <li>Usar el mismo preprocesado en entrenamiento e inferencia.</li>
                            <li>Empezar siempre con la base congelada.</li>
                            <li>Utilizar una tasa de aprendizaje (LR) muy baja para el fine-tuning.</li>
                        </ul>
                    </div>
                    <div class="feature-card secondary">
                        <h4 class="color-secondary">‚ùå Errores Comunes</h4>
                        <ul class="list-disc-padded">
                            <li>Olvidar el <code>preprocess_input</code> espec√≠fico de la arquitectura.</li>
                            <li>Descongelar toda la base demasiado pronto (explota el gradiente).</li>
                            <li>No usar un conjunto de validaci√≥n para monitorizar el sobreajuste.</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- CONCLUSI√ìN -->
            <section class="section" id="conclusion">
                <div class="highlight-box primary"
                    style="padding: 2.5rem; border-radius: 1.5rem; text-align: center; border: 2px solid var(--color-primary); background: linear-gradient(135deg, var(--bg-primary-light) 0%, #ffffff 100%);">
                    <h3 style="color: var(--color-primary); margin-bottom: 1.5rem; font-size: 1.75rem;">üéØ Conclusi√≥n
                    </h3>
                    <p
                        style="font-size: 1.125rem; color: var(--text-dark); max-width: 850px; margin: 0 auto; line-height: 1.6; font-weight: 500;">
                        Gracias al <strong>Transfer Learning</strong>, podemos lograr rendimientos de vanguardia en
                        visi√≥n artificial sin necesidad de infraestructuras masivas ni millones de datos. Es la t√©cnica
                        que democratiza el acceso a la IA profunda para cualquier proyecto.
                    </p>
                </div>
            </section>
        </main>

        <footer>
            <h3>iLERNA</h3>
            <p class="footer-course">Curso de Especializaci√≥n en Inteligencia Artificial y Big Data</p>
            <a href="https://www.ilerna.es/" target="_blank">www.ilerna.es</a>
            <p class="footer-info">Centro oficial de FP online y presencial. Ciclos formativos de Grado Medio y Grado
                Superior.</p>
            <p class="footer-info">Titulaciones 100% oficiales. ¬°Sin pruebas libres!</p>
            <div class="penguin">
                <span>üêß</span>
            </div>
        </footer>
    </div>

    <script src="../js/lecciones.js"></script>
</body>

</html>