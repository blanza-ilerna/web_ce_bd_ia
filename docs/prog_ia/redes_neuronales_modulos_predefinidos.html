<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="Tipos de m√≥dulos predefinidos m√°s comunes: capas, bloques arquitect√≥nicos y modelos pre-entrenados.">
    <meta name="keywords"
        content="Keras, TensorFlow, Dense, CNN, LSTM, Attention, ResNet, BERT, Transformer, Transfer Learning">
    <meta name="author" content="Bjlanza">
    <meta name="organization" content="ILERNA">
    <title>Tipos de M√≥dulos Predefinidos | iLERNA</title>
    <link rel="stylesheet" href="../css/lecciones.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
</head>

<body>
    <header>
        <div class="header-container">
            <div class="logo-container">
                <a href="../index.html">
                    <img src="../img/logo-ilerna.svg" alt="Logo iLERNA">
                </a>
                <div class="logo-text">
                    Curso de Especializaci√≥n
                    <span>Inteligencia Artificial y Big Data</span>
                </div>
            </div>
            <nav class="breadcrumb">
                <a href="../index.html">Inicio</a> ‚Üí
                <a href="index.html">Programaci√≥n IA</a> ‚Üí
                <span>Tipos de M√≥dulos</span>
            </nav>
        </div>
    </header>

    <main class="container">
        <div class="hero">
            <h1>Tipos de M√≥dulos Predefinidos</h1>
            <p class="subtitle">De las Capas B√°sicas a las Arquitecturas de Vanguardia</p>
        </div>

        <!-- SECCI√ìN 1: CAPAS B√ÅSICAS -->
        <section class="section">
            <h2>1. Capas B√°sicas: Los Cimientos</h2>
            <p>Las capas son los componentes fundamentales que transforman los datos de entrada mediante operaciones
                matem√°ticas espec√≠ficas. En el dise√±o de modelos modernos, estas capas se apilan estrat√©gicamente para
                extraer informaci√≥n jer√°rquica.</p>

            <div class="layout-grid-stack">
                <!-- DENSAS -->
                <div class="feature-card primary">
                    <h4 class="color-primary">Densas / Lineales (Dense Layers)</h4>
                    <p>
                        Las capas densas son el tipo m√°s b√°sico de capa en una red neuronal, donde cada neurona est√°
                        conectada a todas las neuronas de la capa anterior. Su funci√≥n principal es realizar una
                        combinaci√≥n lineal de las entradas (pesos por entradas m√°s sesgo) seguida de una funci√≥n de
                        activaci√≥n no lineal.
                    </p>
                    <p>
                        Se utilizan fundamentalmente para aprender representaciones globales de los datos. En un modelo
                        de clasificaci√≥n, las √∫ltimas capas suelen ser densas para poder integrar toda la informaci√≥n
                        extra√≠da por capas previas y tomar una decisi√≥n final basada en el conjunto completo de
                        caracter√≠sticas.
                    </p>
                    <p>
                        Sin embargo, tienen limitaciones importantes: son computacionalmente costosas en t√©rminos de
                        par√°metros y no tienen en cuenta la estructura espacial de los datos. Por ello, se debe tener
                        especial cuidado con la normalizaci√≥n de las entradas y el uso de t√©cnicas de regularizaci√≥n
                        para evitar que el modelo memorice el ruido del entrenamiento.
                    </p>
                </div>

                <!-- CONVOLUCIONALES -->
                <div class="feature-card primary">
                    <h4 class="color-primary">Convolucionales (Convolutional Layers)</h4>
                    <p>
                        A diferencia de las densas, las capas convolucionales (Conv1D/2D/3D) est√°n dise√±adas para
                        procesar datos con una estructura de cuadr√≠cula o secuencia, extrayendo patrones locales como
                        bordes, texturas o formas. Funcionan deslizando un filtro o "kernel" sobre los datos, lo que
                        permite detectar la misma caracter√≠stica sin importar su posici√≥n (invarianza a la traslaci√≥n).
                    </p>
                    <p>
                        Estas capas suelen ir acompa√±adas de operaciones de <strong>Pooling</strong> (como Max o Average
                        Pooling), que reducen la resoluci√≥n espacial para quedarse con la informaci√≥n m√°s relevante, y
                        en tareas de generaci√≥n de im√°genes, de <strong>Upsampling</strong> para recuperar el tama√±o
                        original. Son el est√°ndar absoluto en visi√≥n artificial por su eficiencia y efectividad.
                    </p>
                    <p>
                        Su gran ventaja reside en el "compartir pesos": un mismo filtro se aplica a toda la imagen, lo
                        que reduce dr√°sticamente el n√∫mero de par√°metros en comparaci√≥n con una capa densa equivalente.
                        Esto las hace ideales para detectar jerarqu√≠as de conceptos visuales, desde simples l√≠neas hasta
                        objetos complejos.
                    </p>
                </div>

                <!-- RECURRENTES -->
                <div class="feature-card primary">
                    <h4 class="color-primary">Recurrentes (LSTM / GRU)</h4>
                    <p>
                        Las redes recurrentes est√°n especializadas en el procesamiento de secuencias temporales donde el
                        orden de los elementos es cr√≠tico. A diferencia de las capas anteriores, mantienen un "estado"
                        que funciona como memoria interna, permitiendo que la informaci√≥n de pasos previos influya en el
                        procesamiento del paso actual.
                    </p>
                    <p>
                        Variantes avanzadas como <strong>LSTM</strong> (Long Short-Term Memory) y <strong>GRU</strong>
                        (Gated Recurrent Unit)
                        fueron dise√±adas para mitigar el problema del desvanecimiento del gradiente, permitiendo a la
                        red recordar informaci√≥n relevante a largo plazo. Se han utilizado hist√≥ricamente en traducci√≥n
                        de texto, predicci√≥n de series temporales y an√°lisis de audio.
                    </p>
                    <p>
                        Aunque han sido el n√∫cleo del procesamiento de lenguaje natural (NLP) durante a√±os, su
                        naturaleza secuencial impide la paralelizaci√≥n masiva durante el entrenamiento. Debido a esto,
                        est√°n siendo desplazadas en muchas aplicaciones por arquitecturas de Atenci√≥n y Transformers,
                        que son m√°s r√°pidas y eficaces en secuencias muy largas.
                    </p>
                </div>

                <!-- ATENCI√ìN -->
                <div class="feature-card primary">
                    <h4 class="color-primary">Atenci√≥n (Multi-Head Attention)</h4>
                    <p>
                        La capa de atenci√≥n permite al modelo "mirar" todas las partes de una secuencia al mismo tiempo
                        y decidir cu√°les son las m√°s importantes para entender el elemento actual. En lugar de procesar
                        los datos uno a uno, calcula relaciones globales din√°micas entre todos los componentes de la
                        entrada.
                    </p>
                    <p>
                        El mecanismo de <strong>Multi-Head Attention</strong> divide esta b√∫squeda de relevancia en
                        m√∫ltiples
                        "cabezas" paralelas, permitiendo que el modelo capture diferentes tipos de relaciones
                        simult√°neamente (por ejemplo, en una frase, una cabeza puede centrarse en la gram√°tica y otra en
                        el significado sem√°ntico).
                    </p>
                    <p>
                        Es el motor fundamental de los <strong>Transformers</strong>. Su capacidad para procesar
                        informaci√≥n en
                        paralelo y capturar dependencias de largo alcance sin importar la distancia f√≠sica de los
                        elementos ha revolucionado no solo el texto (GPT, BERT), sino tambi√©n la visi√≥n (ViT) y la
                        generaci√≥n de prote√≠nas.
                    </p>
                </div>

                <!-- EMBEDDINGS -->
                <div class="feature-card secondary">
                    <h4 class="color-secondary">Embeddings</h4>
                    <p>
                        Los embeddings son capas de proyecci√≥n que convierten datos categ√≥ricos (como palabras o IDs de
                        usuario) en vectores de n√∫meros reales en un espacio continuo. A diferencia de representar
                        palabras como c√≥digos aislados, los embeddings aprenden a situar conceptos similares en
                        posiciones cercanas del espacio vectorial.
                    </p>
                    <p>
                        Esto permite capturar relaciones sem√°nticas complejas: el modelo puede aprender matem√°ticamente
                        que "Rey" es a "Hombre" como "Reina" es a "Mujer". Son esenciales en cualquier tarea que trabaje
                        con datos discretos, ya que proporcionan una representaci√≥n densa y rica en significado para que
                        el resto de la red trabaje sobre ella.
                    </p>
                </div>

                <!-- NORMALIZACIONES -->
                <div class="feature-card secondary">
                    <h4 class="color-secondary">Normalizaciones (BatchNorm / LayerNorm)</h4>
                    <p>
                        Estas capas ajustan las activaciones de la red para que tengan una media de cero y una varianza
                        de uno. <strong>BatchNorm</strong> lo hace a trav√©s de los datos del batch de entrenamiento,
                        mientras que
                        <strong>LayerNorm</strong> lo hace de forma independiente para cada ejemplo, siendo muy com√∫n en
                        modelos de
                        texto.
                    </p>
                    <p>
                        Su principal beneficio es la estabilidad y la velocidad: permiten usar tasas de aprendizaje m√°s
                        altas sin que el entrenamiento se vuelva ca√≥tico. Adem√°s de acelerar la convergencia, act√∫an
                        como un ligero regularizador, facilitando que el modelo aprenda patrones generales en lugar de
                        obsesionarse con los valores at√≠picos de los datos.
                    </p>
                </div>

                <!-- REGULARIZACIONES -->
                <div class="feature-card secondary">
                    <h4 class="color-secondary">Regularizaciones (Dropout / Weight Decay)</h4>
                    <p>
                        El sobreajuste (overfitting) ocurre cuando una red neuronal "se aprende de memoria" los datos de
                        entrenamiento pero falla con datos nuevos. Las capas de <strong>Dropout</strong> combaten esto
                        desactivando
                        aleatoriamente un porcentaje de neuronas durante cada paso del entrenamiento, obligando a la red
                        a no depender de rutas espec√≠ficas.
                    </p>
                    <p>
                        Otras t√©cnicas como el <strong>Weight Decay</strong> (penalizaci√≥n de pesos grandes) o el
                        <strong>Early Stopping</strong>
                        (detener el entrenamiento cuando el error de validaci√≥n deja de bajar) complementan esta labor.
                        El objetivo es siempre forzar a la red a encontrar soluciones m√°s simples y robustas que
                        funcionen bien en el mundo real.
                    </p>
                </div>
            </div>
        </section>

        <!-- SECCI√ìN 2: BLOQUES Y PATRONES -->
        <section class="section">
            <h2>2. Bloques y Patrones Arquitect√≥nicos</h2>
            <p>Cuando las capas se agrupan de forma inteligente, surgen patrones que resuelven problemas complejos de
                entrenamiento y eficiencia.</p>

            <div class="scenario-box">
                <div class="scenario-item">
                    <div class="content">
                        <h4>üîó Bloques Residuales (ResNet) <span style="font-weight: normal; margin-left: 10px;"></span>
                        </h4>
                        <p>Introducen conexiones de salto (skip connections) que suman la entrada directamente a la
                            salida del bloque operacional. Esto mitiga el problema del desvanecimiento del gradiente,
                            permitiendo entrenar redes extremadamente profundas (cientos de capas) con √©xito.</p>
                    </div>
                </div>
                <div class="scenario-item">
                    <div class="content">
                        <h4>‚ö° Bloques de Eficiencia <span style="font-weight: normal; margin-left: 10px;"></span></h4>
                        <p>Inception y convoluciones separables (Xception, MobileNet). Optimizan el uso de par√°metros y
                            c√≥mputo dividiendo operaciones complejas en varias m√°s peque√±as y eficientes, permitiendo
                            ejecutar IA en dispositivos m√≥viles.</p>
                    </div>
                </div>
                <div class="scenario-item">
                    <div class="content">
                        <h4>üèóÔ∏è Encoder-Decoder (U-Net) <span style="font-weight: normal; margin-left: 10px;"></span>
                        </h4>
                        <p>Estructuras que primero comprimen la informaci√≥n en una representaci√≥n latente (encoder) y
                            luego la reconstruyen (decoder). Es el dise√±o est√°ndar para segmentaci√≥n de im√°genes m√©dicas
                            y de sat√©lite.</p>
                    </div>
                </div>
            </div>

            <div class="highlight-box secondary">
                <p class="title">El Est√°ndar Transformer</p>
                <p class="content">
                    Consiste en una pila repetitiva de capas de atenci√≥n y normalizaci√≥n combinadas con MLP. Su dise√±o
                    modular y capacidad de paralelizaci√≥n lo han convertido en el est√°ndar indiscutible para grandes
                    modelos de lenguaje y visi√≥n.
                </p>
            </div>
        </section>

        <!-- SECCI√ìN 3: MODELOS PRE-ENTRENADOS -->
        <section class="section">
            <h2>3. El Atajo: Modelos Pre-entrenados</h2>
            <p>El <strong>Transfer Learning</strong> permite usar modelos ya entrenados en bases de datos gigantescas
                para aplicar ese conocimiento a tus propios problemas con un esfuerzo m√≠nimo.</p>

            <div class="layout-grid-stack">
                <!-- RESNET / EFFICIENTNET -->
                <div class="feature-card">
                    <h4>Vision Models: ResNet y EfficientNet</h4>
                    <p>
                        <strong>ResNet</strong> (Residual Networks) revolucion√≥ el campo al demostrar que las redes m√°s
                        profundas
                        pod√≠an entrenarse f√°cilmente mediante conexiones de salto. Es la arquitectura m√°s utilizada como
                        base para extraer caracter√≠sticas de im√°genes debido a su solidez y facilidad de implementaci√≥n.
                    </p>
                    <p>
                        <strong>EfficientNet</strong>, por su parte, utiliza una t√©cnica de escalado sistem√°tico para
                        equilibrar
                        profundidad, anchura y resoluci√≥n. Es capaz de alcanzar precisiones de estado del arte (SOTA)
                        con una fracci√≥n de los par√°metros de modelos anteriores, siendo la elecci√≥n ideal cuando los
                        recursos computacionales son limitados pero se requiere alta precisi√≥n.
                    </p>
                    <p>
                        Ambos modelos se usan hoy para todo: desde el reconocimiento facial y la detecci√≥n de
                        enfermedades en radiograf√≠as hasta el control de calidad en l√≠neas de producci√≥n industriales,
                        donde act√∫an como potentes "ojos" ya entrenados.
                    </p>
                </div>

                <!-- YOLO -->
                <div class="feature-card">
                    <h4>YOLO (You Only Look Once)</h4>
                    <p>
                        <strong>YOLO</strong> es el est√°ndar de la industria para la detecci√≥n de objetos en tiempo
                        real. A
                        diferencia de otros sistemas que escanean la imagen varias veces, YOLO procesa la imagen
                        completa en una sola pasada de red, prediciendo simult√°neamente las cajas delimitadoras y las
                        clases de los objetos detectados.
                    </p>
                    <p>
                        Su dise√±o optimizado permite velocidades de procesamiento incre√≠bles (hasta 60-120 FPS), lo que
                        lo hace perfecto para aplicaciones de videovigilancia, conducci√≥n aut√≥noma y rob√≥tica. Cada
                        nueva versi√≥n (como v8 o v10) mejora el equilibrio entre velocidad y precisi√≥n, adapt√°ndose
                        mejor a objetos peque√±os y escenas complejas.
                    </p>
                </div>

                <!-- BERT / GPT -->
                <div class="feature-card">
                    <h4>Language Models: BERT y GPT</h4>
                    <p>
                        <strong>BERT</strong> (Bidirectional Encoder Representations from Transformers) est√° dise√±ado
                        para entender
                        el contexto de una palabra mirando tanto a su izquierda como a su derecha. Esto lo hace
                        insuperable en tareas de comprensi√≥n donde el matiz es clave, como el an√°lisis de sentimiento,
                        la detecci√≥n de spam y la b√∫squeda sem√°ntica.
                    </p>
                    <p>
                        <strong>GPT</strong> (Generative Pre-trained Transformer), por el contrario, est√° optimizado
                        para la
                        predicci√≥n del siguiente elemento en una secuencia. Su enfoque auto-regresivo le permite generar
                        texto coherente y creativo, realizar traducciones y programar c√≥digo. Es el motor detr√°s de la
                        ola actual de inteligencia artificial generativa.
                    </p>
                    <p>
                        Mientras BERT es excelente para "leer e interpretar", GPT es excelente para "crear y razonar".
                        Ambos han eliminado la necesidad de entrenar modelos de lenguaje desde cero para la mayor√≠a de
                        las empresas, permitiendo usar una versi√≥n pre-entrenada y ajustarla con pocos datos.
                    </p>
                </div>

                <!-- CLIP -->
                <div class="feature-card">
                    <h4>Multimodal: CLIP</h4>
                    <p>
                        <strong>CLIP</strong> (Contrastive Language-Image Pre-training) es un modelo puente que aprende
                        a relacionar
                        im√°genes y texto de forma simult√°nea. Ha sido entrenado en cientos de millones de pares de
                        imagen-texto, aprendiendo a entender visualmente conceptos descritos en lenguaje natural.
                    </p>
                    <p>
                        Es el componente cr√≠tico que permite crear herramientas como DALL-E o Stable Diffusion, ya que
                        traduce las instrucciones de texto del usuario en un espacio matem√°tico que el generador de
                        im√°genes puede entender. Tambi√©n permite clasificar im√°genes de categor√≠as nunca vistas durante
                        el entrenamiento (Zero-shot classification).
                    </p>
                </div>
            </div>

            <div class="warning-box" style="margin-top: 2rem;">
                <h4>üí° Ventaja Competitiva</h4>
                <p>El uso de estos modelos reduce el coste computacional y la cantidad de datos necesarios. El
                    conocimiento ya est√° "cocinado"; t√∫ solo necesitas a√±adir el ingrediente final para tu problema
                    espec√≠fico mediante el <strong>Fine-tuning</strong>.
                </p>
            </div>
        </section>
    </main>

    <footer>
        <h3>iLERNA</h3>
        <p class="footer-course">Curso de Especializaci√≥n en Inteligencia Artificial y Big Data</p>
        <a href="https://www.ilerna.es/" target="_blank">www.ilerna.es</a>
        <p class="footer-info">Centro oficial de FP online y presencial. Ciclos formativos de Grado Medio y Grado
            Superior.</p>
        <div class="penguin">
            <span>üêß</span>
        </div>
    </footer>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="../js/lecciones.js"></script>
</body>

</html>