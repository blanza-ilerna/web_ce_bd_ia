<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="Regresi√≥n Log√≠stica: Clasificaci√≥n y probabilidad. Aprende c√≥mo el modelo estima la pertenencia a una clase mediante la funci√≥n sigmoide.">
    <meta name="keywords"
        content="Regresi√≥n Log√≠stica, Logistic Regression, Clasificaci√≥n Binaria, Sigmoide, Probabilidad, Scikit-learn">
    <meta name="author" content="Bjlanza">
    <meta name="organization" content="ILERNA">
    <title>Regresi√≥n Log√≠stica | iLERNA</title>
    <link rel="stylesheet" href="../css/lecciones.css">
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
</head>

<body>
    <div class="container">
        <header>
            <div class="header-container">
                <div class="logo-container">
                    <a href="../index.html">
                        <img src="../img/logo-ilerna.svg" alt="Logo iLERNA">
                    </a>
                    <div class="logo-text">
                        iLERNA
                        <span>Curso de Especializaci√≥n en IA y Big Data</span>
                    </div>
                </div>
                <div class="breadcrumb">
                    <a href="../index.html">Inicio</a> ‚Ä∫
                    <a href="index.html">Sistemas de Aprendizaje Autom√°tico</a> ‚Ä∫
                    <span>Regresi√≥n Log√≠stica</span>
                </div>
            </div>
            <h1 class="text-center">Regresi√≥n Log√≠stica</h1>
            <p class="subtitle text-center">Clasificaci√≥n basada en probabilidades</p>
        </header>

        <main>
            <!-- SECCI√ìN 1: ¬øQU√â ES LA REGRESI√ìN LOG√çSTICA? -->
            <section class="section">
                <h2 class="section-title">¬øRegresi√≥n o Clasificaci√≥n?</h2>
                <p>
                    A pesar de su nombre, la <strong>Regresi√≥n Log√≠stica</strong> es un algoritmo de
                    <strong>clasificaci√≥n</strong>. Se utiliza para predecir la probabilidad de que una instancia
                    pertenezca a una categor√≠a espec√≠fica (por ejemplo, "Spam" o "No Spam", "Enfermo" o "Sano").
                </p>
                <p>
                    A diferencia de la regresi√≥n lineal, que busca predecir un valor num√©rico continuo, la log√≠stica
                    estima la <strong>probabilidad de pertenencia a una clase</strong>. Si la probabilidad es mayor a un
                    umbral (normalmente 0.5), se asigna la clase positiva.
                </p>

                <div class="highlight-box primary">
                    <p class="title">üìà La Funci√≥n Sigmoide</p>
                    <p class="content">
                        Para convertir un valor real en una probabilidad entre 0 y 1, el modelo utiliza la
                        <strong>funci√≥n log√≠stica o sigmoide</strong>. Su forma de "S" asegura que, sin importar cu√°n
                        grande o peque√±o sea el valor de entrada, la salida siempre estar√° en el rango de probabilidad.
                    </p>
                </div>
            </section>

            <!-- SECCI√ìN 2: EJEMPLO DE CLASIFICACI√ìN BINARIA -->
            <section class="section">
                <h2 class="section-title">üíª Ejemplo: Clasificando Flores (Iris)</h2>
                <p>
                    En este ejemplo, simplificamos el famoso dataset de Iris para convertirlo en un problema binario:
                    distinguir entre <em>Iris setosa</em> e <em>Iris versicolor</em>.
                </p>

                <div class="code-container">
                    <pre><code class="language-python">from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_iris
import numpy as np

# 1. Cargar datos
iris = load_iris()
X, y = iris.data, iris.target

# 2. Filtrar para tener solo dos clases (0 y 1)
mask = y != 2
X_bin, y_bin = X[mask], y[mask]

# 3. Estandarizaci√≥n (Muy recomendada para log√≠stica)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_bin)

# 4. Divisi√≥n entrenamiento/prueba
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_bin, test_size=0.2, random_state=42)

# 5. Entrenamiento
model = LogisticRegression()
model.fit(X_train, y_train)

# 6. Evaluaci√≥n
accuracy = model.score(X_test, y_test)
print(f"Precisi√≥n del modelo: {accuracy:.4f}")

# Predecir probabilidades
probs = model.predict_proba(X_test[:3])
print("Probabilidades por clase:\n", probs)</code></pre>
                </div>

                <div class="feature-card primary-bg" style="margin-top: 1.5rem;">
                    <h4>Interpretaci√≥n de Resultados</h4>
                    <p>
                        El modelo aprende a trazar una "frontera de decisi√≥n". Al usar <code
                            class="code-badge">predict_proba()</code>, podemos ver que el modelo no solo dice "es la
                        clase A", sino que dice "estoy un 98% seguro de que es la clase A". Esta informaci√≥n es vital en
                        medicina o finanzas.
                    </p>
                </div>
            </section>

            <!-- SECCI√ìN 3: PUNTOS CLAVE -->
            <section class="section">
                <h2 class="section-title">üîë Conceptos Fundamentales</h2>
                <div class="grid-features">
                    <div class="feature-card">
                        <h4>üéØ Frontera de Decisi√≥n</h4>
                        <p>Es la l√≠nea (o plano) que divide las clases. Las instancias a un lado se clasifican como 0 y
                            al otro como 1.</p>
                    </div>
                    <div class="feature-card">
                        <h4>‚öñÔ∏è Escalado</h4>
                        <p>Al igual que Ridge o Lasso, la regresi√≥n log√≠stica se beneficia enormemente de la
                            estandarizaci√≥n de variables.</p>
                    </div>
                    <div class="feature-card">
                        <h4>üì¶ Multiclase</h4>
                        <p>Aunque es binaria por naturaleza, puede extenderse a m√∫ltiples clases mediante estrategias
                            como "One-vs-Rest" (OvR).</p>
                    </div>
                </div>
            </section>
        </main>

        <footer>
            <h3>iLERNA</h3>
            <p class="footer-course">Curso de Especializaci√≥n en Inteligencia Artificial y Big Data</p>
            <a href="https://www.ilerna.es/" target="_blank">www.ilerna.es</a>
            <div class="penguin">
                <span>üêß</span>
            </div>
        </footer>
    </div>

    <script src="../js/lecciones.js"></script>
</body>

</html>