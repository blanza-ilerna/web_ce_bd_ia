<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="M√©tricas de Evaluaci√≥n en Machine Learning - Clasificaci√≥n, Regresi√≥n y Aprendizaje No Supervisado">
    <meta name="keywords"
        content="Machine Learning, M√©tricas, Accuracy, Precision, Recall, F1-Score, MSE, RMSE, MAE, R¬≤, Silhouette">
    <meta name="author" content="Bjlanza">
    <meta name="organization" content="ILERNA">
    <title>M√©tricas de Evaluaci√≥n en Machine Learning | iLERNA</title>
    <link rel="stylesheet" href="../css/lecciones.css">
    <!-- PRISM.JS PARA C√ìDIGO -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
</head>

<body>
    <header>
        <div class="header-container">
            <div class="logo-container">
                <a href="../index.html">
                    <img src="../img/logo-ilerna.svg" alt="Logo iLERNA">
                </a>
                <div class="logo-text">
                    Curso de Especializaci√≥n
                    <span>Inteligencia Artificial y Big Data</span>
                </div>
            </div>
            <nav class="breadcrumb">
                <a href="../index.html">Inicio</a> ‚Üí
                <a href="index.html">Sistemas de Aprendizaje Autom√°tico</a> ‚Üí
                <span>M√©tricas de Evaluaci√≥n</span>
            </nav>
        </div>
    </header>

    <main class="container">
        <!-- HERO -->
        <div class="hero">
            <h1>üìä M√©tricas de Evaluaci√≥n en Machine Learning</h1>
            <p class="subtitle">C√≥mo medir el rendimiento real de tus modelos</p>
        </div>

        <!-- TABLE OF CONTENTS -->
        <nav class="toc-container">
            <h3>üìë Contenido de la Lecci√≥n</h3>
            <ul class="toc-list">
                <li><a href="#importancia">1. Importancia de las m√©tricas</a></li>
                <li><a href="#tipos-problemas">2. Tipos de problemas: Clasificaci√≥n, Regresi√≥n y Clustering</a></li>
                <li><a href="#metricas-clasificacion">3. M√©tricas de Clasificaci√≥n: Accuracy, Precision, Recall y F1</a>
                </li>
                <li><a href="#metricas-regresion">4. M√©tricas de Regresi√≥n: MSE, RMSE, MAE y R¬≤</a></li>
                <li><a href="#mse-vs-mae">5. Comparativa T√©cnica: MSE vs MAE</a></li>
                <li><a href="#metricas-no-supervisado">6. M√©tricas No Supervisadas: Silhouette y Varianza Explicada</a>
                </li>
                <li><a href="#guia-seleccion">7. Gu√≠a de Selecci√≥n: ¬øQu√© m√©trica usar en cada caso?</a></li>
                <li><a href="#resumen">8. Resumen y Puntos Clave</a></li>
            </ul>
        </nav>

        <!-- SECCI√ìN 1: INTRODUCCI√ìN -->
        <section id="importancia">
            <h2>¬øPor qu√© son importantes las m√©tricas?</h2>
            <p>
                En Machine Learning, entrenar un modelo es solo el primer paso. Lo verdaderamente cr√≠tico es
                <strong>evaluar su rendimiento</strong> de forma objetiva y cuantificable. Sin m√©tricas adecuadas,
                no podemos saber si nuestro modelo es √∫til en producci√≥n.
            </p>
            <p>
                <strong>No existe una m√©trica universal</strong> porque cada una resalta distintos aspectos del
                rendimiento.
                La elecci√≥n adecuada depende del <strong>tipo de problema</strong> (clasificaci√≥n, regresi√≥n,
                clustering)
                y del <strong>contexto de negocio</strong>.
            </p>

            <div class="highlight-box primary">
                <p class="title">Ejemplo real ‚Äì Detecci√≥n de fraude en tarjetas de cr√©dito</p>
                <p class="content">
                    En un sistema de detecci√≥n de fraude, el <strong>accuracy</strong> puede ser enga√±oso: si solo el
                    0.1%
                    de las transacciones son fraudulentas, un modelo que predice "no fraude" siempre tendr√≠a 99.9% de
                    accuracy,
                    pero ser√≠a completamente in√∫til. Aqu√≠ necesitamos m√©tricas como <strong>Recall</strong> y
                    <strong>F1-Score</strong>
                    que capturen mejor el rendimiento en clases desbalanceadas.
                </p>
            </div>
        </section>

        <!-- SECCI√ìN 2: TIPOS DE PROBLEMAS -->
        <section id="tipos-problemas">
            <h2>Clasificaci√≥n de m√©tricas seg√∫n el tipo de problema</h2>

            <div class="grid-comparison">
                <div class="card secondary-bg">
                    <h3 class="color-secondary">üìä Clasificaci√≥n</h3>
                    <p>
                        Predicci√≥n de <strong>categor√≠as discretas</strong>: spam/no spam, enfermo/sano,
                        gato/perro/p√°jaro.
                    </p>
                    <p><strong>M√©tricas:</strong> Accuracy, Precision, Recall, F1-Score, AUC-ROC</p>
                </div>
                <div class="card primary-bg">
                    <h3 class="color-primary">üìà Regresi√≥n</h3>
                    <p>
                        Predicci√≥n de <strong>valores continuos</strong>: precio de una casa, temperatura, ventas
                        futuras.
                    </p>
                    <p><strong>M√©tricas:</strong> MSE, RMSE, MAE, R¬≤, MAPE</p>
                </div>
                <div class="card secondary-bg">
                    <h3 class="color-secondary">üîç Aprendizaje No Supervisado</h3>
                    <p>
                        <strong>Sin etiquetas</strong>: clustering, reducci√≥n de dimensionalidad, detecci√≥n de
                        anomal√≠as.
                    </p>
                    <p><strong>M√©tricas:</strong> Silhouette Score, Davies-Bouldin, Varianza Explicada</p>
                </div>
            </div>
        </section>

        <!-- SECCI√ìN 3: M√âTRICAS DE CLASIFICACI√ìN -->
        <section id="metricas-clasificacion">
            <h2>M√©tricas de evaluaci√≥n en clasificaci√≥n</h2>
            <h3 class="color-primary">La matriz de confusi√≥n: base de todo</h3>

            <p>
                Todas las m√©tricas de clasificaci√≥n se derivan de la <strong>matriz de confusi√≥n</strong>,
                que compara las predicciones del modelo con las etiquetas reales:
            </p>

            <!-- SVG MATRIZ DE CONFUSI√ìN -->
            <div class="svg-container">
                <svg viewBox="0 0 700 450" style="max-width: 600px;">
                    <defs>
                        <linearGradient id="tpGrad" x1="0%" y1="0%" x2="100%" y2="100%">
                            <stop offset="0%" style="stop-color:#4CAF50;stop-opacity:0.8" />
                            <stop offset="100%" style="stop-color:#81C784;stop-opacity:0.8" />
                        </linearGradient>
                        <linearGradient id="fpGrad" x1="0%" y1="0%" x2="100%" y2="100%">
                            <stop offset="0%" style="stop-color:#FF5252;stop-opacity:0.8" />
                            <stop offset="100%" style="stop-color:#FF8A80;stop-opacity:0.8" />
                        </linearGradient>
                        <linearGradient id="fnGrad" x1="0%" y1="0%" x2="100%" y2="100%">
                            <stop offset="0%" style="stop-color:#FFA726;stop-opacity:0.8" />
                            <stop offset="100%" style="stop-color:#FFB74D;stop-opacity:0.8" />
                        </linearGradient>
                        <linearGradient id="tnGrad" x1="0%" y1="0%" x2="100%" y2="100%">
                            <stop offset="0%" style="stop-color:#4CAF50;stop-opacity:0.8" />
                            <stop offset="100%" style="stop-color:#81C784;stop-opacity:0.8" />
                        </linearGradient>
                    </defs>

                    <rect x="0" y="0" width="700" height="450" rx="15" fill="#f5f5f5" />

                    <!-- T√≠tulo -->
                    <text x="350" y="40" text-anchor="middle" font-family="Montserrat" font-size="22" font-weight="700"
                        fill="#333333">
                        Matriz de Confusi√≥n
                    </text>

                    <!-- Etiquetas superiores -->
                    <text x="350" y="80" text-anchor="middle" font-family="Montserrat" font-size="16" font-weight="700"
                        fill="#49B9CE">
                        Predicci√≥n del Modelo
                    </text>
                    <text x="280" y="110" text-anchor="middle" font-family="Montserrat" font-size="14" font-weight="700"
                        fill="#333333">
                        Positivo
                    </text>
                    <text x="470" y="110" text-anchor="middle" font-family="Montserrat" font-size="14" font-weight="700"
                        fill="#333333">
                        Negativo
                    </text>

                    <!-- Etiquetas laterales -->
                    <text x="80" y="200" text-anchor="middle" font-family="Montserrat" font-size="16" font-weight="700"
                        fill="#8A7AAF" transform="rotate(-90 80 200)">
                        Realidad
                    </text>
                    <text x="130" y="210" text-anchor="end" font-family="Montserrat" font-size="14" font-weight="700"
                        fill="#333333">
                        Positivo
                    </text>
                    <text x="130" y="330" text-anchor="end" font-family="Montserrat" font-size="14" font-weight="700"
                        fill="#333333">
                        Negativo
                    </text>

                    <!-- Cuadrante TP (Verdadero Positivo) -->
                    <rect x="160" y="140" width="180" height="110" rx="10" fill="url(#tpGrad)" stroke="#4CAF50"
                        stroke-width="3" />
                    <text x="250" y="185" text-anchor="middle" font-family="Montserrat" font-size="18" font-weight="700"
                        fill="#ffffff">
                        TP
                    </text>
                    <text x="250" y="210" text-anchor="middle" font-family="Montserrat" font-size="13" fill="#ffffff">
                        Verdadero
                    </text>
                    <text x="250" y="230" text-anchor="middle" font-family="Montserrat" font-size="13" fill="#ffffff">
                        Positivo
                    </text>

                    <!-- Cuadrante FN (Falso Negativo) -->
                    <rect x="360" y="140" width="180" height="110" rx="10" fill="url(#fnGrad)" stroke="#FFA726"
                        stroke-width="3" />
                    <text x="450" y="185" text-anchor="middle" font-family="Montserrat" font-size="18" font-weight="700"
                        fill="#ffffff">
                        FN
                    </text>
                    <text x="450" y="210" text-anchor="middle" font-family="Montserrat" font-size="13" fill="#ffffff">
                        Falso
                    </text>
                    <text x="450" y="230" text-anchor="middle" font-family="Montserrat" font-size="13" fill="#ffffff">
                        Negativo
                    </text>

                    <!-- Cuadrante FP (Falso Positivo) -->
                    <rect x="160" y="270" width="180" height="110" rx="10" fill="url(#fpGrad)" stroke="#FF5252"
                        stroke-width="3" />
                    <text x="250" y="315" text-anchor="middle" font-family="Montserrat" font-size="18" font-weight="700"
                        fill="#ffffff">
                        FP
                    </text>
                    <text x="250" y="340" text-anchor="middle" font-family="Montserrat" font-size="13" fill="#ffffff">
                        Falso
                    </text>
                    <text x="250" y="360" text-anchor="middle" font-family="Montserrat" font-size="13" fill="#ffffff">
                        Positivo
                    </text>

                    <!-- Cuadrante TN (Verdadero Negativo) -->
                    <rect x="360" y="270" width="180" height="110" rx="10" fill="url(#tnGrad)" stroke="#4CAF50"
                        stroke-width="3" />
                    <text x="450" y="315" text-anchor="middle" font-family="Montserrat" font-size="18" font-weight="700"
                        fill="#ffffff">
                        TN
                    </text>
                    <text x="450" y="340" text-anchor="middle" font-family="Montserrat" font-size="13" fill="#ffffff">
                        Verdadero
                    </text>
                    <text x="450" y="360" text-anchor="middle" font-family="Montserrat" font-size="13" fill="#ffffff">
                        Negativo
                    </text>

                    <!-- Leyenda -->
                    <text x="350" y="420" text-anchor="middle" font-family="Montserrat" font-size="12" fill="#555555">
                        Verde = Aciertos | Rojo = Error Tipo I | Naranja = Error Tipo II
                    </text>
                </svg>
            </div>

            <!-- M√©tricas principales -->
            <h3 class="color-primary mt-2">M√©tricas principales</h3>

            <div class="grid-features">
                <!-- Accuracy -->
                <div class="feature-card primary">
                    <h4 class="color-primary">üéØ Accuracy (Exactitud)</h4>
                    <p>Porcentaje de predicciones correctas sobre el total.</p>
                    <div class="formula-block">
                        Accuracy = (TP + TN) / (TP + TN + FP + FN)
                    </div>
                    <p><strong>Cu√°ndo usarla:</strong> Clases balanceadas.</p>
                    <p><strong>Limitaci√≥n:</strong> Enga√±osa con clases desbalanceadas.</p>
                </div>

                <!-- Precision -->
                <div class="feature-card primary">
                    <h4 class="color-primary">üîç Precision (Precisi√≥n)</h4>
                    <p>De todas las predicciones positivas, ¬øcu√°ntas son correctas?</p>
                    <div class="formula-block">
                        Precision = TP / (TP + FP)
                    </div>
                    <p><strong>Cu√°ndo usarla:</strong> Cuando los falsos positivos son costosos (ej: spam, diagn√≥stico
                        m√©dico).</p>
                </div>

                <!-- Recall -->
                <div class="feature-card primary">
                    <h4 class="color-primary">üé£ Recall (Sensibilidad)</h4>
                    <p>De todos los casos positivos reales, ¬øcu√°ntos detect√≥ el modelo?</p>
                    <div class="formula-block">
                        Recall = TP / (TP + FN)
                    </div>
                    <p><strong>Cu√°ndo usarla:</strong> Cuando los falsos negativos son costosos (ej: detecci√≥n de
                        c√°ncer, fraude).</p>
                </div>

                <!-- F1-Score -->
                <div class="feature-card primary">
                    <h4 class="color-primary">‚öñÔ∏è F1-Score</h4>
                    <p>Media arm√≥nica entre Precision y Recall. Balance entre ambas.</p>
                    <div class="formula-block">
                        F1 = 2 √ó (Precision √ó Recall) / (Precision + Recall)
                    </div>
                    <p><strong>Cu√°ndo usarla:</strong> Clases desbalanceadas donde importan tanto FP como FN.</p>
                </div>

                <!-- AUC-ROC -->
                <div class="feature-card primary">
                    <h4 class="color-primary">üìä AUC-ROC</h4>
                    <p>√Årea bajo la curva ROC. Mide la capacidad discriminativa del modelo.</p>
                    <div class="formula-block">
                        AUC = 1.0 (perfecto) | 0.5 (aleatorio)
                    </div>
                    <p><strong>Cu√°ndo usarla:</strong> Evaluar modelos independientemente del umbral de decisi√≥n.</p>
                </div>
            </div>

            <!-- Ejemplo de c√≥digo -->
            <div class="highlight-box primary mt-2">
                <p class="title">Ejemplo en Python ‚Äì M√©tricas de clasificaci√≥n con scikit-learn</p>
            </div>
            <div class="code-copy-container">
                <button class="copy-code-btn" onclick="copyCode(this)">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
                        stroke-width="2">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar</span>
                </button>
                <pre><code class="language-python">from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_classification

# Crear dataset de ejemplo (clasificaci√≥n binaria desbalanceada)
X, y = make_classification(n_samples=1000, n_features=20, n_classes=2,
                           weights=[0.9, 0.1], random_state=42)

# Dividir datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entrenar modelo
modelo = RandomForestClassifier(n_estimators=100, random_state=42)
modelo.fit(X_train, y_train)

# Predicciones
y_pred = modelo.predict(X_test)
y_pred_proba = modelo.predict_proba(X_test)[:, 1]  # Probabilidades para AUC-ROC

# Calcular m√©tricas
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
auc_roc = roc_auc_score(y_test, y_pred_proba)

print("üìä M√âTRICAS DE CLASIFICACI√ìN")
print(f"Accuracy:  {accuracy:.3f}")
print(f"Precision: {precision:.3f}")
print(f"Recall:    {recall:.3f}")
print(f"F1-Score:  {f1:.3f}")
print(f"AUC-ROC:   {auc_roc:.3f}")

print("\nüî¢ Matriz de Confusi√≥n:")
print(confusion_matrix(y_test, y_pred))

print("\nüìã Reporte Completo:")
print(classification_report(y_test, y_pred))</code></pre>
            </div>
        </section>

        <!-- SECCI√ìN 4: M√âTRICAS DE REGRESI√ìN -->
        <section id="metricas-regresion">
            <h2>M√©tricas de evaluaci√≥n en regresi√≥n</h2>
            <h3 class="color-secondary">Midiendo la distancia entre predicci√≥n y realidad</h3>

            <p>
                En problemas de regresi√≥n, evaluamos <strong>qu√© tan cerca est√°n las predicciones de los valores
                    reales</strong>.
                Las m√©tricas se basan en el concepto de <strong>error</strong>: la diferencia entre el valor predicho y
                el real.
            </p>

            <div class="grid-features">
                <!-- MSE -->
                <div class="feature-card secondary">
                    <h4 class="color-secondary">üìê MSE (Mean Squared Error)</h4>
                    <p>Media de los errores al cuadrado. Penaliza m√°s los errores grandes.</p>
                    <div class="formula-block">
                        MSE = (1/n) √ó Œ£(y_real - y_pred)¬≤
                    </div>
                    <p><strong>Ventaja:</strong> Diferenciable, √∫til para optimizaci√≥n.</p>
                    <p><strong>Desventaja:</strong> Sensible a outliers.</p>
                </div>

                <!-- RMSE -->
                <div class="feature-card secondary">
                    <h4 class="color-secondary">üìè RMSE (Root Mean Squared Error)</h4>
                    <p>Ra√≠z cuadrada del MSE. Valores en el mismo rango que la variable objetivo.</p>
                    <div class="formula-block">
                        RMSE = ‚àöMSE
                    </div>
                    <p><strong>Ventaja:</strong> Interpretable en las unidades originales.</p>
                    <p><strong>Uso com√∫n:</strong> Predicci√≥n de precios, temperaturas.</p>
                </div>

                <!-- MAE -->
                <div class="feature-card secondary">
                    <h4 class="color-secondary">üìä MAE (Mean Absolute Error)</h4>
                    <p>Media de los errores absolutos. Penaliza menos los errores grandes.</p>
                    <div class="formula-block">
                        MAE = (1/n) √ó Œ£|y_real - y_pred|
                    </div>
                    <p><strong>Ventaja:</strong> M√°s robusta a outliers que MSE.</p>
                    <p><strong>Desventaja:</strong> No diferenciable en cero.</p>
                </div>

                <!-- R¬≤ -->
                <div class="feature-card secondary">
                    <h4 class="color-secondary">üìà R¬≤ (Coeficiente de Determinaci√≥n)</h4>
                    <p>Proporci√≥n de varianza explicada por el modelo.</p>
                    <div class="formula-block">
                        R¬≤ = 1 - (SS_res / SS_tot)
                    </div>
                    <p><strong>Interpretaci√≥n:</strong> 1 = perfecto, 0 = predice la media, negativo = peor que la
                        media.</p>
                </div>

                <!-- MAPE -->
                <div class="feature-card secondary">
                    <h4 class="color-secondary">üìâ MAPE (Mean Absolute Percentage Error)</h4>
                    <p>Error porcentual medio absoluto. F√°cil de interpretar.</p>
                    <div class="formula-block">
                        MAPE = (100/n) √ó Œ£|y_real - y_pred| / |y_real|
                    </div>
                    <p><strong>Ventaja:</strong> Independiente de la escala.</p>
                    <p><strong>Limitaci√≥n:</strong> Indefinido cuando y_real = 0.</p>
                </div>
            </div>

            <!-- Ejemplo de c√≥digo -->
            <div class="highlight-box secondary mt-2">
                <p class="title">Ejemplo en Python ‚Äì M√©tricas de regresi√≥n con scikit-learn</p>
            </div>
            <div class="code-copy-container">
                <button class="copy-code-btn" onclick="copyCode(this)">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
                        stroke-width="2">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar</span>
                </button>
                <pre><code class="language-python">from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_regression
import numpy as np

# Crear dataset de ejemplo
X, y = make_regression(n_samples=1000, n_features=10, noise=20, random_state=42)

# Dividir datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entrenar modelo
modelo = LinearRegression()
modelo.fit(X_train, y_train)

# Predicciones
y_pred = modelo.predict(X_test)

# Calcular m√©tricas
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# MAPE manual (scikit-learn no lo incluye por defecto)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100

print("üìä M√âTRICAS DE REGRESI√ìN")
print(f"MSE:   {mse:.2f}")
print(f"RMSE:  {rmse:.2f}")
print(f"MAE:   {mae:.2f}")
print(f"R¬≤:    {r2:.3f}")
print(f"MAPE:  {mape:.2f}%")

# Ejemplo de interpretaci√≥n
print(f"\nüí° Interpretaci√≥n:")
print(f"El modelo explica el {r2*100:.1f}% de la varianza de los datos")
print(f"Error promedio: {mae:.2f} unidades")</code></pre>
            </div>

            <!-- Ejemplo real -->
            <div class="highlight-box secondary mt-2">
                <p class="title">Ejemplo real ‚Äì Predicci√≥n de precios de viviendas en Zillow</p>
                <p class="content">
                    Zillow utiliza modelos de regresi√≥n para estimar precios de viviendas. Usan principalmente
                    <strong>RMSE</strong>
                    porque est√° en d√≥lares (interpretable) y <strong>MAPE</strong> para comparar el rendimiento entre
                    diferentes
                    rangos de precios. Un MAPE del 5% significa que, en promedio, las predicciones se desv√≠an un 5% del
                    precio real.
                </p>
            </div>
        </section>

        <!-- SECCI√ìN 5: COMPARATIVA MSE vs MAE -->
        <section id="mse-vs-mae">
            <h2>MSE vs MAE: ¬øCu√°l elegir?</h2>
            <h3 class="color-primary">Sensibilidad a outliers</h3>

            <div class="table-container">
                <table>
                    <thead>
                        <tr>
                            <th>Caracter√≠stica</th>
                            <th>MSE / RMSE</th>
                            <th>MAE</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Sensibilidad a outliers</td>
                            <td>Alta (penaliza errores grandes)</td>
                            <td>Baja (trata todos los errores igual)</td>
                        </tr>
                        <tr>
                            <td>Diferenciabilidad</td>
                            <td>S√≠ (√∫til para gradiente descendente)</td>
                            <td>No en cero</td>
                        </tr>
                        <tr>
                            <td>Interpretabilidad</td>
                            <td>RMSE en unidades originales</td>
                            <td>Directamente en unidades originales</td>
                        </tr>
                        <tr>
                            <td>Cu√°ndo usar</td>
                            <td>Cuando los errores grandes son cr√≠ticos</td>
                            <td>Cuando hay outliers o errores uniformes</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div class="highlight-box primary">
                <p class="title">üí° Regla pr√°ctica</p>
                <p class="content">
                    Usa <strong>MSE/RMSE</strong> cuando quieras penalizar fuertemente los errores grandes (ej:
                    predicci√≥n de demanda
                    donde subestimar es muy costoso). Usa <strong>MAE</strong> cuando todos los errores tengan el mismo
                    peso
                    o cuando haya outliers que no quieras que dominen la m√©trica.
                </p>
            </div>
        </section>

        <!-- SECCI√ìN 6: APRENDIZAJE NO SUPERVISADO -->
        <section id="metricas-no-supervisado">
            <h2>M√©tricas en aprendizaje no supervisado</h2>
            <h3 class="color-secondary">Evaluaci√≥n sin etiquetas</h3>

            <p>
                En aprendizaje no supervisado <strong>no disponemos de etiquetas reales</strong> para comparar,
                por lo que la evaluaci√≥n es m√°s compleja y depende del tipo de problema.
            </p>

            <!-- Clustering -->
            <h3 class="color-secondary mt-2">M√©tricas para Clustering</h3>

            <div class="grid-features">
                <!-- Silhouette Score -->
                <div class="feature-card secondary">
                    <h4 class="color-secondary">üéØ Silhouette Score</h4>
                    <p>Mide qu√© tan similar es un punto a su propio cluster comparado con otros clusters.</p>
                    <div class="formula-block">
                        Rango: [-1, 1]<br>
                        1 = clusters perfectos<br>
                        0 = clusters solapados<br>
                        -1 = asignaci√≥n incorrecta
                    </div>
                </div>

                <!-- Davies-Bouldin Index -->
                <div class="feature-card secondary">
                    <h4 class="color-secondary">üìä Davies-Bouldin Index</h4>
                    <p>Ratio entre la dispersi√≥n intra-cluster y la separaci√≥n inter-cluster.</p>
                    <div class="formula-block">
                        Rango: [0, ‚àû)<br>
                        0 = clusters perfectos<br>
                        Valores bajos = mejor
                    </div>
                </div>

                <!-- Inertia -->
                <div class="feature-card secondary">
                    <h4 class="color-secondary">üé≤ Inertia (Inercia)</h4>
                    <p>Suma de distancias al cuadrado de cada punto a su centroide m√°s cercano.</p>
                    <div class="formula-block">
                        Valores bajos = clusters compactos<br>
                        √ötil para el m√©todo del codo
                    </div>
                </div>
            </div>

            <!-- Ejemplo de c√≥digo clustering -->
            <div class="highlight-box secondary mt-2">
                <p class="title">Ejemplo en Python ‚Äì M√©tricas de clustering con scikit-learn</p>
            </div>
            <div class="code-copy-container">
                <button class="copy-code-btn" onclick="copyCode(this)">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
                        stroke-width="2">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar</span>
                </button>
                <pre><code class="language-python">from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score
from sklearn.datasets import make_blobs
import matplotlib.pyplot as plt

# Crear dataset de ejemplo
X, y_true = make_blobs(n_samples=500, n_features=2, centers=4,
                       cluster_std=1.0, random_state=42)

# Aplicar K-Means
kmeans = KMeans(n_clusters=4, random_state=42)
y_pred = kmeans.fit_predict(X)

# Calcular m√©tricas
silhouette = silhouette_score(X, y_pred)
davies_bouldin = davies_bouldin_score(X, y_pred)
inertia = kmeans.inertia_

print("üìä M√âTRICAS DE CLUSTERING")
print(f"Silhouette Score:     {silhouette:.3f}")
print(f"Davies-Bouldin Index: {davies_bouldin:.3f}")
print(f"Inertia:              {inertia:.2f}")

# M√©todo del codo para encontrar k √≥ptimo
inertias = []
silhouettes = []
K_range = range(2, 11)

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X)
    inertias.append(kmeans.inertia_)
    silhouettes.append(silhouette_score(X, kmeans.labels_))

print("\nüìà M√©todo del codo:")
for k, inertia, sil in zip(K_range, inertias, silhouettes):
    print(f"k={k}: Inertia={inertia:.2f}, Silhouette={sil:.3f}")</code></pre>
            </div>

            <!-- Reducci√≥n de dimensionalidad -->
            <h3 class="color-secondary mt-2">M√©tricas para Reducci√≥n de Dimensionalidad</h3>

            <div class="grid-features">
                <!-- Varianza Explicada -->
                <div class="feature-card secondary">
                    <h4 class="color-secondary">üìä Varianza Explicada (PCA)</h4>
                    <p>Proporci√≥n de informaci√≥n del espacio original que se conserva.</p>
                    <div class="formula-block">
                        Rango: [0, 1]<br>
                        0.95 = conserva 95% de la informaci√≥n
                    </div>
                </div>

                <!-- Error de Reconstrucci√≥n -->
                <div class="feature-card secondary">
                    <h4 class="color-secondary">üîÑ Error de Reconstrucci√≥n</h4>
                    <p>Diferencia entre los datos originales y los reconstruidos desde el espacio reducido.</p>
                    <div class="formula-block">
                        Valores bajos = mejor preservaci√≥n<br>
                        √ötil en autoencoders
                    </div>
                </div>
            </div>

            <!-- Ejemplo de c√≥digo PCA -->
            <div class="highlight-box secondary mt-2">
                <p class="title">Ejemplo en Python ‚Äì Varianza explicada con PCA</p>
            </div>
            <div class="code-copy-container">
                <button class="copy-code-btn" onclick="copyCode(this)">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
                        stroke-width="2">
                        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                    </svg>
                    <span>Copiar</span>
                </button>
                <pre><code class="language-python">from sklearn.decomposition import PCA
from sklearn.datasets import load_digits
import numpy as np

# Cargar dataset (im√°genes de d√≠gitos 8x8 = 64 dimensiones)
digits = load_digits()
X = digits.data

print(f"Dimensiones originales: {X.shape}")

# Aplicar PCA con diferentes n√∫meros de componentes
for n_components in [10, 20, 30, 40]:
    pca = PCA(n_components=n_components)
    X_reduced = pca.fit_transform(X)

    # Varianza explicada total
    varianza_explicada = pca.explained_variance_ratio_.sum()

    print(f"\nüìä PCA con {n_components} componentes:")
    print(f"   Varianza explicada: {varianza_explicada:.3f} ({varianza_explicada*100:.1f}%)")
    print(f"   Dimensiones reducidas: {X_reduced.shape}")

# Encontrar n√∫mero √≥ptimo de componentes para 95% de varianza
pca_full = PCA()
pca_full.fit(X)
varianza_acumulada = np.cumsum(pca_full.explained_variance_ratio_)
n_componentes_95 = np.argmax(varianza_acumulada >= 0.95) + 1

print(f"\n‚úÖ Para conservar 95% de varianza se necesitan {n_componentes_95} componentes")
print(f"   Reducci√≥n: {X.shape[1]} ‚Üí {n_componentes_95} dimensiones")</code></pre>
            </div>

            <!-- Ejemplo real -->
            <div class="highlight-box secondary mt-2">
                <p class="title">Ejemplo real ‚Äì Segmentaci√≥n de clientes en Amazon</p>
                <p class="content">
                    Amazon utiliza clustering (K-Means, DBSCAN) para segmentar clientes seg√∫n su comportamiento de
                    compra.
                    Eval√∫an la calidad de los clusters con <strong>Silhouette Score</strong> para asegurar que los
                    grupos
                    sean coherentes y bien separados, permitiendo personalizar recomendaciones y campa√±as de marketing.
                </p>
            </div>
        </section>

        <!-- SECCI√ìN 7: TABLA COMPARATIVA GENERAL -->
        <section id="guia-seleccion">
            <h2>Tabla comparativa: ¬øQu√© m√©trica usar?</h2>
            <h3 class="color-primary">Gu√≠a r√°pida de selecci√≥n</h3>

            <div class="table-container">
                <table>
                    <thead>
                        <tr>
                            <th>Tipo de Problema</th>
                            <th>Contexto</th>
                            <th>M√©trica Recomendada</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Clasificaci√≥n binaria balanceada</td>
                            <td>Clases con similar cantidad de muestras</td>
                            <td>Accuracy, AUC-ROC</td>
                        </tr>
                        <tr>
                            <td>Clasificaci√≥n desbalanceada</td>
                            <td>Clase minoritaria importante (fraude, enfermedad)</td>
                            <td>F1-Score, Recall, Precision</td>
                        </tr>
                        <tr>
                            <td>Detecci√≥n de spam</td>
                            <td>Minimizar falsos positivos (correos leg√≠timos como spam)</td>
                            <td>Precision</td>
                        </tr>
                        <tr>
                            <td>Detecci√≥n de c√°ncer</td>
                            <td>Minimizar falsos negativos (no detectar enfermedad)</td>
                            <td>Recall</td>
                        </tr>
                        <tr>
                            <td>Predicci√≥n de precios</td>
                            <td>Errores grandes son cr√≠ticos</td>
                            <td>RMSE, R¬≤</td>
                        </tr>
                        <tr>
                            <td>Predicci√≥n con outliers</td>
                            <td>Datos con valores at√≠picos frecuentes</td>
                            <td>MAE</td>
                        </tr>
                        <tr>
                            <td>Comparar modelos entre escalas</td>
                            <td>Diferentes rangos de valores objetivo</td>
                            <td>MAPE, R¬≤</td>
                        </tr>
                        <tr>
                            <td>Segmentaci√≥n de clientes</td>
                            <td>Clustering sin etiquetas</td>
                            <td>Silhouette Score, Davies-Bouldin</td>
                        </tr>
                        <tr>
                            <td>Compresi√≥n de datos</td>
                            <td>Reducci√≥n de dimensionalidad</td>
                            <td>Varianza Explicada, Error de Reconstrucci√≥n</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div class="warning-box">
                <h4>‚ö†Ô∏è Advertencia importante</h4>
                <p>
                    <strong>No existe una m√©trica perfecta.</strong> En proyectos reales, es com√∫n usar
                    <strong>m√∫ltiples m√©tricas</strong>
                    para obtener una visi√≥n completa del rendimiento. Por ejemplo, en clasificaci√≥n desbalanceada,
                    reporta
                    Precision, Recall, F1-Score y AUC-ROC simult√°neamente. El contexto de negocio siempre debe guiar la
                    elecci√≥n.
                </p>
            </div>
        </section>

        <!-- SECCI√ìN 8: RESUMEN FINAL -->
        <section id="resumen">
            <h2 class="text-center">Resumen y puntos clave</h2>

            <div class="final-grid">
                <div class="final-card technical">
                    <h3 class="color-primary">‚úÖ Clasificaci√≥n</h3>
                    <ul>
                        <li><strong>Accuracy:</strong> √∫til con clases balanceadas</li>
                        <li><strong>Precision:</strong> minimiza falsos positivos</li>
                        <li><strong>Recall:</strong> minimiza falsos negativos</li>
                        <li><strong>F1-Score:</strong> balance en clases desbalanceadas</li>
                        <li><strong>AUC-ROC:</strong> capacidad discriminativa global</li>
                    </ul>
                </div>
                <div class="final-card philosophical">
                    <h3 class="color-secondary">‚úÖ Regresi√≥n</h3>
                    <ul>
                        <li><strong>MSE/RMSE:</strong> penaliza errores grandes</li>
                        <li><strong>MAE:</strong> robusta a outliers</li>
                        <li><strong>R¬≤:</strong> proporci√≥n de varianza explicada</li>
                        <li><strong>MAPE:</strong> error porcentual interpretable</li>
                    </ul>
                </div>
                <div class="final-card technical">
                    <h3 class="color-primary">‚úÖ No Supervisado</h3>
                    <ul>
                        <li><strong>Silhouette Score:</strong> calidad de clusters</li>
                        <li><strong>Davies-Bouldin:</strong> compacidad y separaci√≥n</li>
                        <li><strong>Varianza Explicada:</strong> informaci√≥n conservada (PCA)</li>
                        <li><strong>Inertia:</strong> m√©todo del codo para K-Means</li>
                    </ul>
                </div>
            </div>

            <div class="challenge-box">
                <h3>üí° Para llevarte de esta lecci√≥n</h3>
                <p>
                    La elecci√≥n de m√©tricas es tan importante como la elecci√≥n del modelo. <strong>No existe una m√©trica
                        universal</strong>
                    porque cada una captura diferentes aspectos del rendimiento. Siempre considera el <strong>contexto
                        del problema</strong>,
                    el <strong>balance de clases</strong>, y el <strong>coste de los errores</strong>. En producci√≥n,
                    usa m√∫ltiples m√©tricas
                    para obtener una visi√≥n completa y toma decisiones informadas basadas en el impacto real del
                    negocio.
                    Recuerda: <strong>una m√©trica alta no siempre significa un modelo √∫til</strong> si no est√° alineada
                    con los objetivos.
                </p>
            </div>
        </section>
    </main>

    <!-- FOOTER -->
    <footer>
        <h3>iLERNA</h3>
        <p class="subtitle">Curso de Especializaci√≥n en Inteligencia Artificial y Big Data</p>
        <a href="https://www.ilerna.es/" target="_blank">www.ilerna.es</a>
        <p class="description">
            Centro oficial de FP online y presencial. Ciclos formativos de Grado Medio y Grado Superior.
        </p>
        <p class="description">
            Titulaciones 100% oficiales. ¬°Sin pruebas libres!
        </p>
        <div class="penguin">
            <span>üêß</span>
        </div>
    </footer>

    <!-- PRISM.JS CORE -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>

    <!-- Script para copiar c√≥digo -->
    <script>
        function copyCode(button) {
            const codeBlock = button.parentElement.querySelector('code');
            const text = codeBlock.textContent;

            navigator.clipboard.writeText(text).then(() => {
                button.classList.add('copied');
                button.querySelector('span').textContent = '¬°Copiado!';

                setTimeout(() => {
                    button.classList.remove('copied');
                    button.querySelector('span').textContent = 'Copiar';
                }, 2000);
            });
        }
    </script>
</body>

</html>