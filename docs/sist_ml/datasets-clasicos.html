<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="Datasets cl√°sicos en Machine Learning: Iris, Titanic, MNIST y Boston Housing. Historia, estructura y ejemplos de uso en Python.">
    <meta name="keywords"
        content="Datasets Machine Learning, Iris Dataset, Titanic Dataset, MNIST, Boston Housing, Scikit-learn, Pandas">
    <meta name="author" content="Bjlanza">
    <meta name="organization" content="ILERNA">
    <title>Datasets Cl√°sicos en Machine Learning | iLERNA</title>
    <link rel="stylesheet" href="../css/lecciones.css">
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
</head>

<body>
    <header>
        <div class="header-container">
            <div class="logo-container">
                <a href="../index.html">
                    <img src="../img/logo-ilerna.svg" alt="Logo iLERNA">
                </a>
                <div class="logo-text">
                    iLERNA
                    <span>Curso de Especializaci√≥n en IA y Big Data</span>
                </div>
            </div>
            <div class="breadcrumb">
                <a href="../index.html">Inicio</a> ‚Ä∫
                <a href="index.html">Sistemas de Aprendizaje Autom√°tico</a> ‚Ä∫
                <span>Datasets Cl√°sicos</span>
            </div>
        </div>
        <h1 class="text-center">Datasets Cl√°sicos en Machine Learning</h1>
        <p class="subtitle text-center">Conjuntos de datos fundamentales para benchmarking y aprendizaje</p>
    </header>

    <!-- SECCI√ìN INTRODUCCI√ìN -->
    <section class="section">
        <h2 class="section-title">La Importancia de los Datasets Est√°ndar</h2>
        <p>
            En el mundo de la Inteligencia Artificial, disponer de conjuntos de datos estandarizados es crucial.
            Permiten a estudiantes e investigadores <strong>comparar el rendimiento de diferentes algoritmos</strong> en
            igualdad de condiciones. Estos datasets, a menudo llamados "datasets de juguete" (toy datasets), son
            peque√±os, limpios y bien entendidos, lo que los hace ideales para aprender y prototipar.
        </p>

        <div class="highlight-box">
            <p class="tech-title">üöÄ ¬øPor qu√© usarlos?</p>
            <p>
                No necesitas limpiar datos ni preocuparte por la recolecci√≥n. Vienen preprocesados y listos para ser
                consumidos por bibliotecas como <strong>Scikit-learn</strong> o <strong>TensorFlow</strong>,
                permiti√©ndote enfocarte puramente en el modelado.
            </p>
        </div>
    </section>

    <!-- SECCI√ìN 1: IRIS DATASET -->
    <section class="section">
        <h2 class="section-title">üå∏ Iris Dataset: El "Hola Mundo" de la Clasificaci√≥n</h2>

        <div class="content-grid-2">
            <div>
                <p>
                    Creado por el estad√≠stico brit√°nico <strong>Ronald Fisher</strong> en 1936, este dataset es
                    probablemente el m√°s famoso en la historia del reconocimiento de patrones. Contiene datos de 150
                    flores de iris de tres especies diferentes.
                </p>
                <div class="highlight-box" style="margin-bottom: 1rem; border-left-color: var(--color-primary);">
                    <p style="margin-bottom: 0.5rem;"><strong>üí° Dato Clave:</strong></p>
                    <p style="font-size: 0.95rem;">
                        La clase <strong>Setosa</strong> es linealmente separable de las otras dos, mientras que
                        <strong>Versicolor</strong> y <strong>Virginica</strong> se superponen, lo que lo convierte en
                        un excelente banco de pruebas para comparar clasificadores lineales (como SVM lineal) vs no
                        lineales.
                    </p>
                </div>
                <div class="feature-card primary">
                    <h4>Caracter√≠sticas:</h4>
                    <ul>
                        <li><strong>Instancias:</strong> 150 (50 por clase)</li>
                        <li><strong>Atributos (4):</strong> Largo y ancho de s√©palo y p√©talo.</li>
                        <li><strong>Clases (3):</strong> Setosa, Versicolor, Virginica.</li>
                        <li><strong>Uso Com√∫n:</strong> Pruebas de clasificaci√≥n y visualizaci√≥n (Pairplots).</li>
                    </ul>
                </div>
            </div>
            <div class="svg-container">
                <!-- Placeholder visual simple o imagen -->
                <div style="background: white; padding: 20px; border-radius: 10px; text-align: center;">
                    <div style="font-size: 4rem;">üå∫ üå∏ üåº</div>
                    <p>Tres especies distinguibles por sus p√©talos</p>
                </div>
            </div>
        </div>

        <h3>C√≥mo cargarlo con Python</h3>
        <pre><code class="language-python">from sklearn.datasets import load_iris
import pandas as pd

# Cargar el dataset
data = load_iris()
df = pd.DataFrame(data.data, columns=data.feature_names)
df['target'] = data.target

# Mostrar las primeras filas
print(df.head())

# Output esperado:
#    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  target
# 0                5.1               3.5                1.4               0.2       0
# 1                4.9               3.0                1.4               0.2       0</code></pre>
    </section>

    <!-- SECCI√ìN 2: TITANIC DATASET -->
    <section class="section">
        <h2 class="section-title">üö¢ Titanic: Predicci√≥n de Supervivencia</h2>
        <p>
            Un desaf√≠o cl√°sico de Kaggle. El objetivo es predecir qu√© pasajeros sobrevivieron al hundimiento del Titanic
            bas√°ndose en caracter√≠sticas como edad, sexo, clase del billete y tarifa.
        </p>

        <div class="highlight-box secondary">
            <p class="title">üí° Desaf√≠o de Limpieza de Datos</p>
            <p>
                A diferencia de Iris, el dataset del Titanic es "sucio". Contiene <strong>valores nulos</strong>
                (especialmente en 'Age' y 'Cabin'), variables categ√≥ricas que necesitan codificaci√≥n ('Sex', 'Embarked')
                y nombres que requieren procesamiento de texto. Es perfecto para practicar <strong>Feature
                    Engineering</strong>.
            </p>
        </div>

        <div class="grid-features">
            <div class="feature-card secondary">
                <h4>Variables Clave</h4>
                <ul>
                    <li><strong>Pclass:</strong> Clase (1¬™, 2¬™, 3¬™) - Proxy de estatus socioecon√≥mico.</li>
                    <li><strong>Sex:</strong> G√©nero (fuerte predictor).</li>
                    <li><strong>Age:</strong> Edad (ni√±os ten√≠an prioridad).</li>
                    <li><strong>Fare:</strong> Tarifa pagada.</li>
                </ul>
            </div>
            <div class="feature-card">
                <h4>Aprendizaje Esperado</h4>
                <ul>
                    <li>Manejo de <strong>Missing Values</strong>.</li>
                    <li>Codificaci√≥n <strong>One-Hot</strong> y <strong>Label Encoding</strong>.</li>
                    <li>Regresi√≥n Log√≠stica y √Årboles de Decisi√≥n.</li>
                </ul>
            </div>
        </div>

        <pre><code class="language-python">import seaborn as sns

# Seaborn tiene el dataset 'titanic' integrado
df_titanic = sns.load_dataset('titanic')

# Ver valores nulos
print(df_titanic.isnull().sum())

# Filtrar por clase y supervivencia
sobrevivientes_clase_1 = df_titanic[(df_titanic['pclass'] == 1) & (df_titanic['survived'] == 1)]
print(f"Sobrevivientes 1ra clase: {len(sobrevivientes_clase_1)}")</code></pre>
    </section>

    <!-- SECCI√ìN 3: MNIST DATASET -->
    <section class="section">
        <h2 class="section-title">‚úçÔ∏è MNIST: Visi√≥n por Computadora B√°sica</h2>
        <p>
            El dataset <strong>Mixed National Institute of Standards and Technology (MNIST)</strong> consiste en 70,000
            im√°genes de peque√±os d√≠gitos escritos a mano (0-9). Es el dataset por excelencia para iniciarse en
            <strong>Redes Neuronales</strong> y <strong>Deep Learning</strong>.
        </p>

        <div class="content-grid-2">
            <div>
                <div class="feature-card primary">
                    <h4>Especificaciones:</h4>
                    <ul>
                        <li><strong>Im√°genes:</strong> Escala de grises, 28x28 p√≠xeles.</li>
                        <li><strong>Train Set:</strong> 60,000 im√°genes.</li>
                        <li><strong>Test Set:</strong> 10,000 im√°genes.</li>
                        <li><strong>Objetivo:</strong> Clasificar la imagen en uno de los 10 d√≠gitos.</li>
                    </ul>
                </div>
            </div>
            <div>
                <p>
                    Las im√°genes se representan com√∫nmente como matrices planas (vectores de 784 valores) para
                    algoritmos cl√°sicos, o como matrices 2D para <strong>Redes Neuronales Convolucionales
                        (CNN)</strong>.
                </p>
            </div>
        </div>

        <pre><code class="language-python">from sklearn.datasets import fetch_openml
import matplotlib.pyplot as plt

# Descargar MNIST (puede tardar un poco la primera vez)
mnist = fetch_openml('mnist_784', version=1, as_frame=False)
X, y = mnist.data, mnist.target

# Visualizar un d√≠gito
digito = X[0]
digito_imagen = digito.reshape(28, 28)

plt.imshow(digito_imagen, cmap='binary')
plt.axis('off')
plt.title(f"Etiqueta: {y[0]}")
plt.show()</code></pre>
    </section>

    <!-- SECCI√ìN 4: WINE DATASET -->
    <section class="section">
        <h2 class="section-title">üç∑ Wine Dataset: Qu√≠mica y Clasificaci√≥n</h2>
        <p>
            Este dataset es el resultado de un an√°lisis qu√≠mico de vinos cultivados en la misma regi√≥n de Italia pero
            derivados de tres cultivares diferentes. El an√°lisis determin√≥ las cantidades de 13 constituyentes
            encontrados en cada uno de los tres tipos de vinos.
        </p>

        <div class="content-grid-2">
            <div class="feature-card secondary">
                <h4>Detalles T√©cnicos</h4>
                <ul>
                    <li><strong>Instancias:</strong> 178 muestras.</li>
                    <li><strong>Atributos (13):</strong> Alcohol, √Åcido m√°lico, Ceniza, Alcalinidad, Magnesio, Fenoles,
                        etc.</li>
                    <li><strong>Clases (3):</strong> Tres tipos de cultivares (Clase 0, 1, 2).</li>
                    <li><strong>Reto:</strong> Clasificaci√≥n con alta dimensionalidad relativa a las muestras.</li>
                </ul>
            </div>
            <div>
                <pre><code class="language-python">from sklearn.datasets import load_wine

# Cargar dataset de vinos
wine = load_wine()
X, y = wine.data, wine.target

# Nombres de las caracter√≠sticas
print("Atributos:", wine.feature_names)
# ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', ...]</code></pre>
            </div>
        </div>
    </section>

    <!-- SECCI√ìN 5: BREAST CANCER WISCONSIN -->
    <section class="section">
        <h2 class="section-title">‚öïÔ∏è Breast Cancer Wisconsin: Diagn√≥stico M√©dico</h2>
        <p>
            Un dataset cr√≠tico para aplicaciones de IA en medicina. Las caracter√≠sticas se calculan a partir de una
            imagen digitalizada de una aspiraci√≥n con aguja fina (FNA) de una masa mamaria. Describen las
            caracter√≠sticas de los n√∫cleos celulares presentes en la imagen.
        </p>

        <div class="highlight-box warning">
            <p class="title">‚ö†Ô∏è Importancia del Recall (Sensibilidad)</p>
            <p>
                En este tipo de problemas m√©dicos, es crucial minimizar los <strong>Falsos Negativos</strong> (decir que
                es benigno cuando es maligno). Por ello, solemos optimizar m√©tricas como el <strong>Recall</strong>
                sobre la Precisi√≥n pura.
            </p>
        </div>

        <ul class="mb-2">
            <li><strong>Clases:</strong> Maligno (Malignant) vs Benigno (Benign).</li>
            <li><strong>Instancias:</strong> 569.</li>
            <li><strong>Atributos (30):</strong> Radio, textura, per√≠metro, √°rea, suavidad, etc. (media, error est√°ndar
                y peor caso).</li>
        </ul>

        <pre><code class="language-python">from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split

# Cargar datos
cancer = load_breast_cancer()

# Separar en Train/Test
X_train, X_test, y_train, y_test = train_test_split(
    cancer.data, cancer.target, stratify=cancer.target, random_state=42
)

print(f"Dimensiones de entrenamiento: {X_train.shape}")
# Salida: (426, 30)</code></pre>
    </section>

    <!-- SECCI√ìN 6: BOSTON HOUSING -->
    <section class="section">
        <h2 class="section-title">üè† Boston Housing: Regresi√≥n Cl√°sica</h2>
        <p>
            Publicado en 1978, contiene informaci√≥n sobre viviendas en el √°rea de Boston. El objetivo es predecir el
            <strong>valor mediano de las viviendas (MEDV)</strong> bas√°ndose en 13 atributos como la tasa de crimen,
            n√∫mero de habitaciones y antig√ºedad.
        </p>

        <div class="expert-quote">
            <p class="quote-text">
                "Advertencia √âtica: El dataset de Boston Housing contiene una variable ('B') que asume segregaci√≥n
                racial. Por esta raz√≥n, Scikit-learn ha deprecado su uso directo y recomienda alternativas como el
                dataset de California Housing."
            </p>
            <span class="quote-author">Documentaci√≥n de Scikit-learn</span>
        </div>
        <br>
        <h3>Alternativa Moderna: California Housing</h3>
        <p>
            Debido a los problemas √©ticos del dataset de Boston, hoy en d√≠a se prefiere el dataset de <strong>California
                Housing</strong> para ense√±ar regresi√≥n. Es m√°s grande (20,000 muestras) y m√°s moderno.
        </p>

        <pre><code class="language-python">from sklearn.datasets import fetch_california_housing

# Cargar dataset de California
housing = fetch_california_housing(as_frame=True)
data = housing.frame

# Ver correlaci√≥n entre Ingreso Medio y Valor de la Casa
print(data[['MedInc', 'MedHouseVal']].corr())</code></pre>
    </section>

    <footer>
        <h3>iLERNA</h3>
        <p class="footer-course">Curso de Especializaci√≥n en Inteligencia Artificial y Big Data</p>
        <a href="https://www.ilerna.es/" target="_blank">www.ilerna.es</a>
        <p class="footer-info">Centro oficial de FP online y presencial. Ciclos formativos de Grado Medio y Grado
            Superior.</p>
        <p class="footer-info">Titulaciones 100% oficiales. ¬°Sin pruebas libres!</p>

        <div class="penguin">
            <span>üêß</span>
        </div>
    </footer>

    <!-- Scripts -->
    <script src="../js/lecciones.js"></script>
    <script src="../js/copy-code.js"></script>
</body>

</html>